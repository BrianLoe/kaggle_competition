{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfabf302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e0d2536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>BertzCT</th>\n",
       "      <th>Chi1</th>\n",
       "      <th>Chi1n</th>\n",
       "      <th>Chi1v</th>\n",
       "      <th>Chi2n</th>\n",
       "      <th>Chi2v</th>\n",
       "      <th>Chi3v</th>\n",
       "      <th>Chi4n</th>\n",
       "      <th>EState_VSA1</th>\n",
       "      <th>...</th>\n",
       "      <th>SlogP_VSA3</th>\n",
       "      <th>VSA_EState9</th>\n",
       "      <th>fr_COO</th>\n",
       "      <th>fr_COO2</th>\n",
       "      <th>EC1</th>\n",
       "      <th>EC2</th>\n",
       "      <th>EC3</th>\n",
       "      <th>EC4</th>\n",
       "      <th>EC5</th>\n",
       "      <th>EC6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>323.390782</td>\n",
       "      <td>9.879918</td>\n",
       "      <td>5.875576</td>\n",
       "      <td>5.875576</td>\n",
       "      <td>4.304757</td>\n",
       "      <td>4.304757</td>\n",
       "      <td>2.754513</td>\n",
       "      <td>1.749203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.794537</td>\n",
       "      <td>35.527357</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>273.723798</td>\n",
       "      <td>7.259037</td>\n",
       "      <td>4.441467</td>\n",
       "      <td>5.834958</td>\n",
       "      <td>3.285046</td>\n",
       "      <td>4.485235</td>\n",
       "      <td>2.201375</td>\n",
       "      <td>1.289775</td>\n",
       "      <td>45.135471</td>\n",
       "      <td>...</td>\n",
       "      <td>13.825658</td>\n",
       "      <td>44.707310</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>521.643822</td>\n",
       "      <td>10.911303</td>\n",
       "      <td>8.527859</td>\n",
       "      <td>11.050864</td>\n",
       "      <td>6.665291</td>\n",
       "      <td>9.519706</td>\n",
       "      <td>5.824822</td>\n",
       "      <td>1.770579</td>\n",
       "      <td>15.645394</td>\n",
       "      <td>...</td>\n",
       "      <td>17.964475</td>\n",
       "      <td>45.660120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>567.431166</td>\n",
       "      <td>12.453343</td>\n",
       "      <td>7.089119</td>\n",
       "      <td>12.833709</td>\n",
       "      <td>6.478023</td>\n",
       "      <td>10.978151</td>\n",
       "      <td>7.914542</td>\n",
       "      <td>3.067181</td>\n",
       "      <td>95.639554</td>\n",
       "      <td>...</td>\n",
       "      <td>31.961948</td>\n",
       "      <td>87.509997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>112.770735</td>\n",
       "      <td>4.414719</td>\n",
       "      <td>2.866236</td>\n",
       "      <td>2.866236</td>\n",
       "      <td>1.875634</td>\n",
       "      <td>1.875634</td>\n",
       "      <td>1.036450</td>\n",
       "      <td>0.727664</td>\n",
       "      <td>17.980451</td>\n",
       "      <td>...</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14833</th>\n",
       "      <td>14833</td>\n",
       "      <td>632.207041</td>\n",
       "      <td>10.911303</td>\n",
       "      <td>6.579933</td>\n",
       "      <td>9.179964</td>\n",
       "      <td>4.653583</td>\n",
       "      <td>6.030052</td>\n",
       "      <td>3.670528</td>\n",
       "      <td>1.770579</td>\n",
       "      <td>32.971529</td>\n",
       "      <td>...</td>\n",
       "      <td>18.947452</td>\n",
       "      <td>61.376610</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14834</th>\n",
       "      <td>14834</td>\n",
       "      <td>62.568425</td>\n",
       "      <td>2.642734</td>\n",
       "      <td>1.446898</td>\n",
       "      <td>1.446898</td>\n",
       "      <td>0.879497</td>\n",
       "      <td>0.879497</td>\n",
       "      <td>0.174620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14835</th>\n",
       "      <td>14835</td>\n",
       "      <td>981.327476</td>\n",
       "      <td>10.363081</td>\n",
       "      <td>6.146219</td>\n",
       "      <td>6.146219</td>\n",
       "      <td>4.700576</td>\n",
       "      <td>4.700576</td>\n",
       "      <td>3.064846</td>\n",
       "      <td>2.133897</td>\n",
       "      <td>17.248535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14836</th>\n",
       "      <td>14836</td>\n",
       "      <td>299.171248</td>\n",
       "      <td>9.949161</td>\n",
       "      <td>6.589761</td>\n",
       "      <td>7.848913</td>\n",
       "      <td>5.276568</td>\n",
       "      <td>5.476436</td>\n",
       "      <td>3.978973</td>\n",
       "      <td>2.299833</td>\n",
       "      <td>45.623794</td>\n",
       "      <td>...</td>\n",
       "      <td>9.088795</td>\n",
       "      <td>45.583333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14837</th>\n",
       "      <td>14837</td>\n",
       "      <td>785.394062</td>\n",
       "      <td>15.671142</td>\n",
       "      <td>9.896164</td>\n",
       "      <td>10.234264</td>\n",
       "      <td>7.860296</td>\n",
       "      <td>8.522605</td>\n",
       "      <td>5.645502</td>\n",
       "      <td>3.312893</td>\n",
       "      <td>82.448246</td>\n",
       "      <td>...</td>\n",
       "      <td>22.701338</td>\n",
       "      <td>71.127044</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14838 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id     BertzCT       Chi1     Chi1n      Chi1v     Chi2n      Chi2v  \\\n",
       "0          0  323.390782   9.879918  5.875576   5.875576  4.304757   4.304757   \n",
       "1          1  273.723798   7.259037  4.441467   5.834958  3.285046   4.485235   \n",
       "2          2  521.643822  10.911303  8.527859  11.050864  6.665291   9.519706   \n",
       "3          3  567.431166  12.453343  7.089119  12.833709  6.478023  10.978151   \n",
       "4          4  112.770735   4.414719  2.866236   2.866236  1.875634   1.875634   \n",
       "...      ...         ...        ...       ...        ...       ...        ...   \n",
       "14833  14833  632.207041  10.911303  6.579933   9.179964  4.653583   6.030052   \n",
       "14834  14834   62.568425   2.642734  1.446898   1.446898  0.879497   0.879497   \n",
       "14835  14835  981.327476  10.363081  6.146219   6.146219  4.700576   4.700576   \n",
       "14836  14836  299.171248   9.949161  6.589761   7.848913  5.276568   5.476436   \n",
       "14837  14837  785.394062  15.671142  9.896164  10.234264  7.860296   8.522605   \n",
       "\n",
       "          Chi3v     Chi4n  EState_VSA1  ...  SlogP_VSA3  VSA_EState9  fr_COO  \\\n",
       "0      2.754513  1.749203     0.000000  ...    4.794537    35.527357       0   \n",
       "1      2.201375  1.289775    45.135471  ...   13.825658    44.707310       0   \n",
       "2      5.824822  1.770579    15.645394  ...   17.964475    45.660120       0   \n",
       "3      7.914542  3.067181    95.639554  ...   31.961948    87.509997       0   \n",
       "4      1.036450  0.727664    17.980451  ...    9.589074    33.333333       2   \n",
       "...         ...       ...          ...  ...         ...          ...     ...   \n",
       "14833  3.670528  1.770579    32.971529  ...   18.947452    61.376610       0   \n",
       "14834  0.174620  0.000000     0.000000  ...    0.000000    10.000000       0   \n",
       "14835  3.064846  2.133897    17.248535  ...    0.000000    66.666667       0   \n",
       "14836  3.978973  2.299833    45.623794  ...    9.088795    45.583333       0   \n",
       "14837  5.645502  3.312893    82.448246  ...   22.701338    71.127044       0   \n",
       "\n",
       "       fr_COO2  EC1  EC2  EC3  EC4  EC5  EC6  \n",
       "0            0    1    1    0    0    0    0  \n",
       "1            0    0    1    1    0    0    0  \n",
       "2            0    1    1    0    0    1    0  \n",
       "3            0    1    1    0    0    0    0  \n",
       "4            2    1    0    1    1    1    0  \n",
       "...        ...  ...  ...  ...  ...  ...  ...  \n",
       "14833        0    1    1    0    0    0    0  \n",
       "14834        0    0    1    0    1    0    0  \n",
       "14835        0    1    1    0    0    0    0  \n",
       "14836        0    0    1    1    0    0    0  \n",
       "14837        0    0    1    0    1    0    0  \n",
       "\n",
       "[14838 rows x 38 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aa48cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EC1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EC1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EC1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EC1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EC1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89023</th>\n",
       "      <td>EC6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89024</th>\n",
       "      <td>EC6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89025</th>\n",
       "      <td>EC6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89026</th>\n",
       "      <td>EC6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89027</th>\n",
       "      <td>EC6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89028 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      variable  value\n",
       "0          EC1      1\n",
       "1          EC1      0\n",
       "2          EC1      1\n",
       "3          EC1      1\n",
       "4          EC1      1\n",
       "...        ...    ...\n",
       "89023      EC6      0\n",
       "89024      EC6      0\n",
       "89025      EC6      0\n",
       "89026      EC6      0\n",
       "89027      EC6      0\n",
       "\n",
       "[89028 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = train_data.melt(value_vars=train_data.columns[-6:])\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63c7a241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.set_style('darkgrid')\n",
    "ax = sns.countplot(data=counts.loc[counts['value']!=0], x='variable')\n",
    "ax.set(xlabel='Class', title='Count of class')\n",
    "for bar in ax.patches:\n",
    "    ax.annotate(format(bar.get_height(), 'd'),\n",
    "                (bar.get_x() + bar.get_width() / 2,\n",
    "                    bar.get_height()), \n",
    "                ha='center', va='center', size=10, xytext=(0, 8), textcoords='offset points')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb7ac2a",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce5f89d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "BertzCT              0\n",
       "Chi1                 0\n",
       "Chi1n                0\n",
       "Chi1v                0\n",
       "Chi2n                0\n",
       "Chi2v                0\n",
       "Chi3v                0\n",
       "Chi4n                0\n",
       "EState_VSA1          0\n",
       "EState_VSA2          0\n",
       "ExactMolWt           0\n",
       "FpDensityMorgan1     0\n",
       "FpDensityMorgan2     0\n",
       "FpDensityMorgan3     0\n",
       "HallKierAlpha        0\n",
       "HeavyAtomMolWt       0\n",
       "Kappa3               0\n",
       "MaxAbsEStateIndex    0\n",
       "MinEStateIndex       0\n",
       "NumHeteroatoms       0\n",
       "PEOE_VSA10           0\n",
       "PEOE_VSA14           0\n",
       "PEOE_VSA6            0\n",
       "PEOE_VSA7            0\n",
       "PEOE_VSA8            0\n",
       "SMR_VSA10            0\n",
       "SMR_VSA5             0\n",
       "SlogP_VSA3           0\n",
       "VSA_EState9          0\n",
       "fr_COO               0\n",
       "fr_COO2              0\n",
       "EC1                  0\n",
       "EC2                  0\n",
       "EC3                  0\n",
       "EC4                  0\n",
       "EC5                  0\n",
       "EC6                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a896322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BertzCT</th>\n",
       "      <th>Chi1</th>\n",
       "      <th>Chi1n</th>\n",
       "      <th>Chi1v</th>\n",
       "      <th>Chi2n</th>\n",
       "      <th>Chi2v</th>\n",
       "      <th>Chi3v</th>\n",
       "      <th>Chi4n</th>\n",
       "      <th>EState_VSA1</th>\n",
       "      <th>EState_VSA2</th>\n",
       "      <th>...</th>\n",
       "      <th>SlogP_VSA3</th>\n",
       "      <th>VSA_EState9</th>\n",
       "      <th>fr_COO</th>\n",
       "      <th>fr_COO2</th>\n",
       "      <th>EC1</th>\n",
       "      <th>EC2</th>\n",
       "      <th>EC3</th>\n",
       "      <th>EC4</th>\n",
       "      <th>EC5</th>\n",
       "      <th>EC6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [BertzCT, Chi1, Chi1n, Chi1v, Chi2n, Chi2v, Chi3v, Chi4n, EState_VSA1, EState_VSA2, ExactMolWt, FpDensityMorgan1, FpDensityMorgan2, FpDensityMorgan3, HallKierAlpha, HeavyAtomMolWt, Kappa3, MaxAbsEStateIndex, MinEStateIndex, NumHeteroatoms, PEOE_VSA10, PEOE_VSA14, PEOE_VSA6, PEOE_VSA7, PEOE_VSA8, SMR_VSA10, SMR_VSA5, SlogP_VSA3, VSA_EState9, fr_COO, fr_COO2, EC1, EC2, EC3, EC4, EC5, EC6]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 37 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicated values  without id\n",
    "train_data.drop('id', axis=1).loc[train_data.drop('id', axis=1).duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da4b145d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     int64\n",
       "BertzCT              float64\n",
       "Chi1                 float64\n",
       "Chi1n                float64\n",
       "Chi1v                float64\n",
       "Chi2n                float64\n",
       "Chi2v                float64\n",
       "Chi3v                float64\n",
       "Chi4n                float64\n",
       "EState_VSA1          float64\n",
       "EState_VSA2          float64\n",
       "ExactMolWt           float64\n",
       "FpDensityMorgan1     float64\n",
       "FpDensityMorgan2     float64\n",
       "FpDensityMorgan3     float64\n",
       "HallKierAlpha        float64\n",
       "HeavyAtomMolWt       float64\n",
       "Kappa3               float64\n",
       "MaxAbsEStateIndex    float64\n",
       "MinEStateIndex       float64\n",
       "NumHeteroatoms         int64\n",
       "PEOE_VSA10           float64\n",
       "PEOE_VSA14           float64\n",
       "PEOE_VSA6            float64\n",
       "PEOE_VSA7            float64\n",
       "PEOE_VSA8            float64\n",
       "SMR_VSA10            float64\n",
       "SMR_VSA5             float64\n",
       "SlogP_VSA3           float64\n",
       "VSA_EState9          float64\n",
       "fr_COO                 int64\n",
       "fr_COO2                int64\n",
       "EC1                    int64\n",
       "EC2                    int64\n",
       "EC3                    int64\n",
       "EC4                    int64\n",
       "EC5                    int64\n",
       "EC6                    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da5069a",
   "metadata": {},
   "source": [
    "Looks like the features only consist of numerical features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3f459a",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ccebbcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BertzCT</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>515.153604</td>\n",
       "      <td>542.456370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>149.103601</td>\n",
       "      <td>290.987941</td>\n",
       "      <td>652.652585</td>\n",
       "      <td>4069.959780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chi1</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>9.135189</td>\n",
       "      <td>6.819989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.680739</td>\n",
       "      <td>6.485270</td>\n",
       "      <td>11.170477</td>\n",
       "      <td>69.551167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chi1n</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>5.854307</td>\n",
       "      <td>4.647064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.844556</td>\n",
       "      <td>4.052701</td>\n",
       "      <td>7.486791</td>\n",
       "      <td>50.174588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chi1v</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>6.738497</td>\n",
       "      <td>5.866444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.932842</td>\n",
       "      <td>4.392859</td>\n",
       "      <td>8.527859</td>\n",
       "      <td>53.431954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chi2n</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>4.432570</td>\n",
       "      <td>3.760516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.949719</td>\n",
       "      <td>2.970427</td>\n",
       "      <td>5.788793</td>\n",
       "      <td>32.195368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chi2v</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>5.253221</td>\n",
       "      <td>4.925065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.034468</td>\n",
       "      <td>3.242775</td>\n",
       "      <td>6.609350</td>\n",
       "      <td>34.579313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chi3v</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>3.418749</td>\n",
       "      <td>3.436208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.160763</td>\n",
       "      <td>1.948613</td>\n",
       "      <td>4.502070</td>\n",
       "      <td>22.880836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chi4n</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>1.773472</td>\n",
       "      <td>1.865898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.503897</td>\n",
       "      <td>1.073261</td>\n",
       "      <td>2.534281</td>\n",
       "      <td>16.072810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EState_VSA1</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>29.202823</td>\n",
       "      <td>31.728679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>17.353601</td>\n",
       "      <td>44.876559</td>\n",
       "      <td>363.705954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EState_VSA2</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>10.435316</td>\n",
       "      <td>13.651843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.420822</td>\n",
       "      <td>12.841643</td>\n",
       "      <td>99.936429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExactMolWt</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>292.623087</td>\n",
       "      <td>225.384140</td>\n",
       "      <td>1.007276</td>\n",
       "      <td>148.037173</td>\n",
       "      <td>206.042653</td>\n",
       "      <td>343.090331</td>\n",
       "      <td>2237.318490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FpDensityMorgan1</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>1.236774</td>\n",
       "      <td>5.491284</td>\n",
       "      <td>-666.000000</td>\n",
       "      <td>1.045455</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FpDensityMorgan2</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>1.812070</td>\n",
       "      <td>5.495565</td>\n",
       "      <td>-666.000000</td>\n",
       "      <td>1.690909</td>\n",
       "      <td>1.865152</td>\n",
       "      <td>2.062153</td>\n",
       "      <td>3.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FpDensityMorgan3</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>2.255470</td>\n",
       "      <td>5.501200</td>\n",
       "      <td>-666.000000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>2.358491</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HallKierAlpha</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>-1.207776</td>\n",
       "      <td>0.935314</td>\n",
       "      <td>-7.730000</td>\n",
       "      <td>-1.660000</td>\n",
       "      <td>-1.100000</td>\n",
       "      <td>-0.570000</td>\n",
       "      <td>0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HeavyAtomMolWt</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>274.950211</td>\n",
       "      <td>212.678755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>136.109000</td>\n",
       "      <td>194.276500</td>\n",
       "      <td>326.002000</td>\n",
       "      <td>2035.133000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kappa3</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>5.874372</td>\n",
       "      <td>45.730226</td>\n",
       "      <td>-104.040000</td>\n",
       "      <td>1.784008</td>\n",
       "      <td>3.261011</td>\n",
       "      <td>5.848400</td>\n",
       "      <td>1512.242231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxAbsEStateIndex</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>10.556443</td>\n",
       "      <td>1.559331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.926190</td>\n",
       "      <td>10.421334</td>\n",
       "      <td>11.539743</td>\n",
       "      <td>15.630251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MinEStateIndex</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>-2.119772</td>\n",
       "      <td>2.066415</td>\n",
       "      <td>-6.327514</td>\n",
       "      <td>-4.659604</td>\n",
       "      <td>-1.265370</td>\n",
       "      <td>-0.787037</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumHeteroatoms</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>8.584108</td>\n",
       "      <td>7.643769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEOE_VSA10</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>11.021644</td>\n",
       "      <td>13.958962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.041841</td>\n",
       "      <td>18.311899</td>\n",
       "      <td>97.663462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEOE_VSA14</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>17.790011</td>\n",
       "      <td>34.561655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>15.645394</td>\n",
       "      <td>482.434223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEOE_VSA6</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>8.962440</td>\n",
       "      <td>19.756727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.132734</td>\n",
       "      <td>375.425148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEOE_VSA7</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>11.318811</td>\n",
       "      <td>20.169745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.847474</td>\n",
       "      <td>211.501279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEOE_VSA8</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>6.704487</td>\n",
       "      <td>10.865415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.923737</td>\n",
       "      <td>100.348416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMR_VSA10</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>15.666766</td>\n",
       "      <td>18.080208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>11.752550</td>\n",
       "      <td>17.721856</td>\n",
       "      <td>80.742293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMR_VSA5</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>31.066423</td>\n",
       "      <td>33.896638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.420822</td>\n",
       "      <td>20.075376</td>\n",
       "      <td>42.727765</td>\n",
       "      <td>492.729739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlogP_VSA3</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>13.636941</td>\n",
       "      <td>14.598554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.794537</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>14.912664</td>\n",
       "      <td>115.406157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VSA_EState9</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>49.309959</td>\n",
       "      <td>29.174824</td>\n",
       "      <td>-5.430556</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>56.090650</td>\n",
       "      <td>384.450519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_COO</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>0.458215</td>\n",
       "      <td>0.667948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_COO2</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>0.459226</td>\n",
       "      <td>0.668111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC1</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>0.667745</td>\n",
       "      <td>0.471038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC2</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>0.798962</td>\n",
       "      <td>0.400790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC3</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>0.313789</td>\n",
       "      <td>0.464047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC4</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>0.279081</td>\n",
       "      <td>0.448562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC5</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>0.144831</td>\n",
       "      <td>0.351942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC6</th>\n",
       "      <td>14838.0</td>\n",
       "      <td>0.151570</td>\n",
       "      <td>0.358616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count        mean         std         min         25%  \\\n",
       "BertzCT            14838.0  515.153604  542.456370    0.000000  149.103601   \n",
       "Chi1               14838.0    9.135189    6.819989    0.000000    4.680739   \n",
       "Chi1n              14838.0    5.854307    4.647064    0.000000    2.844556   \n",
       "Chi1v              14838.0    6.738497    5.866444    0.000000    2.932842   \n",
       "Chi2n              14838.0    4.432570    3.760516    0.000000    1.949719   \n",
       "Chi2v              14838.0    5.253221    4.925065    0.000000    2.034468   \n",
       "Chi3v              14838.0    3.418749    3.436208    0.000000    1.160763   \n",
       "Chi4n              14838.0    1.773472    1.865898    0.000000    0.503897   \n",
       "EState_VSA1        14838.0   29.202823   31.728679    0.000000    5.969305   \n",
       "EState_VSA2        14838.0   10.435316   13.651843    0.000000    0.000000   \n",
       "ExactMolWt         14838.0  292.623087  225.384140    1.007276  148.037173   \n",
       "FpDensityMorgan1   14838.0    1.236774    5.491284 -666.000000    1.045455   \n",
       "FpDensityMorgan2   14838.0    1.812070    5.495565 -666.000000    1.690909   \n",
       "FpDensityMorgan3   14838.0    2.255470    5.501200 -666.000000    2.100000   \n",
       "HallKierAlpha      14838.0   -1.207776    0.935314   -7.730000   -1.660000   \n",
       "HeavyAtomMolWt     14838.0  274.950211  212.678755    0.000000  136.109000   \n",
       "Kappa3             14838.0    5.874372   45.730226 -104.040000    1.784008   \n",
       "MaxAbsEStateIndex  14838.0   10.556443    1.559331    0.000000    9.926190   \n",
       "MinEStateIndex     14838.0   -2.119772    2.066415   -6.327514   -4.659604   \n",
       "NumHeteroatoms     14838.0    8.584108    7.643769    0.000000    4.000000   \n",
       "PEOE_VSA10         14838.0   11.021644   13.958962    0.000000    0.000000   \n",
       "PEOE_VSA14         14838.0   17.790011   34.561655    0.000000    0.000000   \n",
       "PEOE_VSA6          14838.0    8.962440   19.756727    0.000000    0.000000   \n",
       "PEOE_VSA7          14838.0   11.318811   20.169745    0.000000    0.000000   \n",
       "PEOE_VSA8          14838.0    6.704487   10.865415    0.000000    0.000000   \n",
       "SMR_VSA10          14838.0   15.666766   18.080208    0.000000    5.969305   \n",
       "SMR_VSA5           14838.0   31.066423   33.896638    0.000000    6.420822   \n",
       "SlogP_VSA3         14838.0   13.636941   14.598554    0.000000    4.794537   \n",
       "VSA_EState9        14838.0   49.309959   29.174824   -5.430556   30.000000   \n",
       "fr_COO             14838.0    0.458215    0.667948    0.000000    0.000000   \n",
       "fr_COO2            14838.0    0.459226    0.668111    0.000000    0.000000   \n",
       "EC1                14838.0    0.667745    0.471038    0.000000    0.000000   \n",
       "EC2                14838.0    0.798962    0.400790    0.000000    1.000000   \n",
       "EC3                14838.0    0.313789    0.464047    0.000000    0.000000   \n",
       "EC4                14838.0    0.279081    0.448562    0.000000    0.000000   \n",
       "EC5                14838.0    0.144831    0.351942    0.000000    0.000000   \n",
       "EC6                14838.0    0.151570    0.358616    0.000000    0.000000   \n",
       "\n",
       "                          50%         75%          max  \n",
       "BertzCT            290.987941  652.652585  4069.959780  \n",
       "Chi1                 6.485270   11.170477    69.551167  \n",
       "Chi1n                4.052701    7.486791    50.174588  \n",
       "Chi1v                4.392859    8.527859    53.431954  \n",
       "Chi2n                2.970427    5.788793    32.195368  \n",
       "Chi2v                3.242775    6.609350    34.579313  \n",
       "Chi3v                1.948613    4.502070    22.880836  \n",
       "Chi4n                1.073261    2.534281    16.072810  \n",
       "EState_VSA1         17.353601   44.876559   363.705954  \n",
       "EState_VSA2          6.420822   12.841643    99.936429  \n",
       "ExactMolWt         206.042653  343.090331  2237.318490  \n",
       "FpDensityMorgan1     1.250000    1.500000     3.000000  \n",
       "FpDensityMorgan2     1.865152    2.062153     3.200000  \n",
       "FpDensityMorgan3     2.358491    2.500000     3.400000  \n",
       "HallKierAlpha       -1.100000   -0.570000     0.820000  \n",
       "HeavyAtomMolWt     194.276500  326.002000  2035.133000  \n",
       "Kappa3               3.261011    5.848400  1512.242231  \n",
       "MaxAbsEStateIndex   10.421334   11.539743    15.630251  \n",
       "MinEStateIndex      -1.265370   -0.787037     6.000000  \n",
       "NumHeteroatoms       6.000000   10.000000    42.000000  \n",
       "PEOE_VSA10           6.041841   18.311899    97.663462  \n",
       "PEOE_VSA14           5.969305   15.645394   482.434223  \n",
       "PEOE_VSA6            0.000000   12.132734   375.425148  \n",
       "PEOE_VSA7            0.000000   13.847474   211.501279  \n",
       "PEOE_VSA8            0.000000    6.923737   100.348416  \n",
       "SMR_VSA10           11.752550   17.721856    80.742293  \n",
       "SMR_VSA5            20.075376   42.727765   492.729739  \n",
       "SlogP_VSA3           9.589074   14.912664   115.406157  \n",
       "VSA_EState9         41.666667   56.090650   384.450519  \n",
       "fr_COO               0.000000    1.000000     8.000000  \n",
       "fr_COO2              0.000000    1.000000     8.000000  \n",
       "EC1                  1.000000    1.000000     1.000000  \n",
       "EC2                  1.000000    1.000000     1.000000  \n",
       "EC3                  0.000000    1.000000     1.000000  \n",
       "EC4                  0.000000    1.000000     1.000000  \n",
       "EC5                  0.000000    0.000000     1.000000  \n",
       "EC6                  0.000000    0.000000     1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.drop('id', axis=1).describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9183049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EC1    0.667745\n",
       "EC2    0.798962\n",
       "Name: mean, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.drop('id', axis=1).describe()[['EC1', 'EC2']].T['mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7658f845",
   "metadata": {},
   "source": [
    "67% of data is classified as EC1 while 80% of data is classified as EC2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e53ce9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1008 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,14))\n",
    "matrix = train_data.corr()\n",
    "mask = np.triu(matrix)\n",
    "sns.heatmap(matrix, cmap='BuPu', mask=mask, square=True, annot=True, fmt='.1f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c064649",
   "metadata": {},
   "source": [
    "There are only one or two variables that correlate with EC1 1 and those are also weak correlations. Meanwhile with EC2, it does not have any correlation with any variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da61ddaa",
   "metadata": {},
   "source": [
    "# Identifying and removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f95ea36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_outliers_zscore(dataframe, threshold=3):\n",
    "    # Compute the z-scores for each column\n",
    "    z_scores = np.abs((dataframe - dataframe.mean()) / dataframe.std())\n",
    "    \n",
    "    # Identify outliers based on the threshold\n",
    "    outliers = (z_scores > threshold).any(axis=1)\n",
    "    \n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "523b1c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2331"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers = identify_outliers_zscore(train_data)\n",
    "\n",
    "outliers.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af86c104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>BertzCT</th>\n",
       "      <th>Chi1</th>\n",
       "      <th>Chi1n</th>\n",
       "      <th>Chi1v</th>\n",
       "      <th>Chi2n</th>\n",
       "      <th>Chi2v</th>\n",
       "      <th>Chi3v</th>\n",
       "      <th>Chi4n</th>\n",
       "      <th>EState_VSA1</th>\n",
       "      <th>...</th>\n",
       "      <th>SlogP_VSA3</th>\n",
       "      <th>VSA_EState9</th>\n",
       "      <th>fr_COO</th>\n",
       "      <th>fr_COO2</th>\n",
       "      <th>EC1</th>\n",
       "      <th>EC2</th>\n",
       "      <th>EC3</th>\n",
       "      <th>EC4</th>\n",
       "      <th>EC5</th>\n",
       "      <th>EC6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "      <td>2331.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7574.867868</td>\n",
       "      <td>1145.146890</td>\n",
       "      <td>17.500511</td>\n",
       "      <td>11.845585</td>\n",
       "      <td>14.055023</td>\n",
       "      <td>9.316464</td>\n",
       "      <td>11.418295</td>\n",
       "      <td>7.779913</td>\n",
       "      <td>4.194270</td>\n",
       "      <td>52.109650</td>\n",
       "      <td>...</td>\n",
       "      <td>26.364508</td>\n",
       "      <td>80.631501</td>\n",
       "      <td>0.311454</td>\n",
       "      <td>0.312312</td>\n",
       "      <td>0.670957</td>\n",
       "      <td>0.780781</td>\n",
       "      <td>0.345774</td>\n",
       "      <td>0.211497</td>\n",
       "      <td>0.121836</td>\n",
       "      <td>0.118404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4328.493865</td>\n",
       "      <td>755.940792</td>\n",
       "      <td>9.456922</td>\n",
       "      <td>6.449813</td>\n",
       "      <td>8.206592</td>\n",
       "      <td>5.146011</td>\n",
       "      <td>6.808545</td>\n",
       "      <td>4.587534</td>\n",
       "      <td>2.616224</td>\n",
       "      <td>46.280385</td>\n",
       "      <td>...</td>\n",
       "      <td>22.031831</td>\n",
       "      <td>42.857247</td>\n",
       "      <td>0.787751</td>\n",
       "      <td>0.787956</td>\n",
       "      <td>0.469967</td>\n",
       "      <td>0.413806</td>\n",
       "      <td>0.475722</td>\n",
       "      <td>0.408458</td>\n",
       "      <td>0.327167</td>\n",
       "      <td>0.323155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3842.500000</td>\n",
       "      <td>569.405621</td>\n",
       "      <td>10.701907</td>\n",
       "      <td>7.561328</td>\n",
       "      <td>8.166523</td>\n",
       "      <td>5.579871</td>\n",
       "      <td>6.179601</td>\n",
       "      <td>4.211207</td>\n",
       "      <td>2.466346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.794537</td>\n",
       "      <td>49.527251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7712.000000</td>\n",
       "      <td>1038.977885</td>\n",
       "      <td>16.188780</td>\n",
       "      <td>11.812020</td>\n",
       "      <td>12.980835</td>\n",
       "      <td>9.391115</td>\n",
       "      <td>11.008637</td>\n",
       "      <td>8.159163</td>\n",
       "      <td>4.286873</td>\n",
       "      <td>54.993754</td>\n",
       "      <td>...</td>\n",
       "      <td>22.701338</td>\n",
       "      <td>79.916667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11388.000000</td>\n",
       "      <td>1827.878106</td>\n",
       "      <td>25.369507</td>\n",
       "      <td>16.051044</td>\n",
       "      <td>21.144665</td>\n",
       "      <td>12.543074</td>\n",
       "      <td>17.591681</td>\n",
       "      <td>11.414423</td>\n",
       "      <td>5.698768</td>\n",
       "      <td>86.771356</td>\n",
       "      <td>...</td>\n",
       "      <td>50.697492</td>\n",
       "      <td>112.878292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14834.000000</td>\n",
       "      <td>4069.959780</td>\n",
       "      <td>69.551167</td>\n",
       "      <td>50.174588</td>\n",
       "      <td>53.431954</td>\n",
       "      <td>32.195368</td>\n",
       "      <td>34.579313</td>\n",
       "      <td>22.880836</td>\n",
       "      <td>16.072810</td>\n",
       "      <td>363.705954</td>\n",
       "      <td>...</td>\n",
       "      <td>115.406157</td>\n",
       "      <td>384.450519</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id      BertzCT         Chi1        Chi1n        Chi1v  \\\n",
       "count   2331.000000  2331.000000  2331.000000  2331.000000  2331.000000   \n",
       "mean    7574.867868  1145.146890    17.500511    11.845585    14.055023   \n",
       "std     4328.493865   755.940792     9.456922     6.449813     8.206592   \n",
       "min       21.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%     3842.500000   569.405621    10.701907     7.561328     8.166523   \n",
       "50%     7712.000000  1038.977885    16.188780    11.812020    12.980835   \n",
       "75%    11388.000000  1827.878106    25.369507    16.051044    21.144665   \n",
       "max    14834.000000  4069.959780    69.551167    50.174588    53.431954   \n",
       "\n",
       "             Chi2n        Chi2v        Chi3v        Chi4n  EState_VSA1  ...  \\\n",
       "count  2331.000000  2331.000000  2331.000000  2331.000000  2331.000000  ...   \n",
       "mean      9.316464    11.418295     7.779913     4.194270    52.109650  ...   \n",
       "std       5.146011     6.808545     4.587534     2.616224    46.280385  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       5.579871     6.179601     4.211207     2.466346     0.000000  ...   \n",
       "50%       9.391115    11.008637     8.159163     4.286873    54.993754  ...   \n",
       "75%      12.543074    17.591681    11.414423     5.698768    86.771356  ...   \n",
       "max      32.195368    34.579313    22.880836    16.072810   363.705954  ...   \n",
       "\n",
       "        SlogP_VSA3  VSA_EState9       fr_COO      fr_COO2          EC1  \\\n",
       "count  2331.000000  2331.000000  2331.000000  2331.000000  2331.000000   \n",
       "mean     26.364508    80.631501     0.311454     0.312312     0.670957   \n",
       "std      22.031831    42.857247     0.787751     0.787956     0.469967   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       4.794537    49.527251     0.000000     0.000000     0.000000   \n",
       "50%      22.701338    79.916667     0.000000     0.000000     1.000000   \n",
       "75%      50.697492   112.878292     0.000000     0.000000     1.000000   \n",
       "max     115.406157   384.450519     8.000000     8.000000     1.000000   \n",
       "\n",
       "               EC2          EC3          EC4          EC5          EC6  \n",
       "count  2331.000000  2331.000000  2331.000000  2331.000000  2331.000000  \n",
       "mean      0.780781     0.345774     0.211497     0.121836     0.118404  \n",
       "std       0.413806     0.475722     0.408458     0.327167     0.323155  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       1.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       1.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       1.000000     1.000000     0.000000     0.000000     0.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[outliers].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdb1b5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>BertzCT</th>\n",
       "      <th>Chi1</th>\n",
       "      <th>Chi1n</th>\n",
       "      <th>Chi1v</th>\n",
       "      <th>Chi2n</th>\n",
       "      <th>Chi2v</th>\n",
       "      <th>Chi3v</th>\n",
       "      <th>Chi4n</th>\n",
       "      <th>EState_VSA1</th>\n",
       "      <th>...</th>\n",
       "      <th>SlogP_VSA3</th>\n",
       "      <th>VSA_EState9</th>\n",
       "      <th>fr_COO</th>\n",
       "      <th>fr_COO2</th>\n",
       "      <th>EC1</th>\n",
       "      <th>EC2</th>\n",
       "      <th>EC3</th>\n",
       "      <th>EC4</th>\n",
       "      <th>EC5</th>\n",
       "      <th>EC6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>323.390782</td>\n",
       "      <td>9.879918</td>\n",
       "      <td>5.875576</td>\n",
       "      <td>5.875576</td>\n",
       "      <td>4.304757</td>\n",
       "      <td>4.304757</td>\n",
       "      <td>2.754513</td>\n",
       "      <td>1.749203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.794537</td>\n",
       "      <td>35.527357</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>273.723798</td>\n",
       "      <td>7.259037</td>\n",
       "      <td>4.441467</td>\n",
       "      <td>5.834958</td>\n",
       "      <td>3.285046</td>\n",
       "      <td>4.485235</td>\n",
       "      <td>2.201375</td>\n",
       "      <td>1.289775</td>\n",
       "      <td>45.135471</td>\n",
       "      <td>...</td>\n",
       "      <td>13.825658</td>\n",
       "      <td>44.707310</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>521.643822</td>\n",
       "      <td>10.911303</td>\n",
       "      <td>8.527859</td>\n",
       "      <td>11.050864</td>\n",
       "      <td>6.665291</td>\n",
       "      <td>9.519706</td>\n",
       "      <td>5.824822</td>\n",
       "      <td>1.770579</td>\n",
       "      <td>15.645394</td>\n",
       "      <td>...</td>\n",
       "      <td>17.964475</td>\n",
       "      <td>45.660120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>567.431166</td>\n",
       "      <td>12.453343</td>\n",
       "      <td>7.089119</td>\n",
       "      <td>12.833709</td>\n",
       "      <td>6.478023</td>\n",
       "      <td>10.978151</td>\n",
       "      <td>7.914542</td>\n",
       "      <td>3.067181</td>\n",
       "      <td>95.639554</td>\n",
       "      <td>...</td>\n",
       "      <td>31.961948</td>\n",
       "      <td>87.509997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>112.770735</td>\n",
       "      <td>4.414719</td>\n",
       "      <td>2.866236</td>\n",
       "      <td>2.866236</td>\n",
       "      <td>1.875634</td>\n",
       "      <td>1.875634</td>\n",
       "      <td>1.036450</td>\n",
       "      <td>0.727664</td>\n",
       "      <td>17.980451</td>\n",
       "      <td>...</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14832</th>\n",
       "      <td>14832</td>\n",
       "      <td>83.690584</td>\n",
       "      <td>3.560660</td>\n",
       "      <td>1.689533</td>\n",
       "      <td>1.689533</td>\n",
       "      <td>0.924069</td>\n",
       "      <td>0.924069</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.794537</td>\n",
       "      <td>16.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14833</th>\n",
       "      <td>14833</td>\n",
       "      <td>632.207041</td>\n",
       "      <td>10.911303</td>\n",
       "      <td>6.579933</td>\n",
       "      <td>9.179964</td>\n",
       "      <td>4.653583</td>\n",
       "      <td>6.030052</td>\n",
       "      <td>3.670528</td>\n",
       "      <td>1.770579</td>\n",
       "      <td>32.971529</td>\n",
       "      <td>...</td>\n",
       "      <td>18.947452</td>\n",
       "      <td>61.376610</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14835</th>\n",
       "      <td>14835</td>\n",
       "      <td>981.327476</td>\n",
       "      <td>10.363081</td>\n",
       "      <td>6.146219</td>\n",
       "      <td>6.146219</td>\n",
       "      <td>4.700576</td>\n",
       "      <td>4.700576</td>\n",
       "      <td>3.064846</td>\n",
       "      <td>2.133897</td>\n",
       "      <td>17.248535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14836</th>\n",
       "      <td>14836</td>\n",
       "      <td>299.171248</td>\n",
       "      <td>9.949161</td>\n",
       "      <td>6.589761</td>\n",
       "      <td>7.848913</td>\n",
       "      <td>5.276568</td>\n",
       "      <td>5.476436</td>\n",
       "      <td>3.978973</td>\n",
       "      <td>2.299833</td>\n",
       "      <td>45.623794</td>\n",
       "      <td>...</td>\n",
       "      <td>9.088795</td>\n",
       "      <td>45.583333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14837</th>\n",
       "      <td>14837</td>\n",
       "      <td>785.394062</td>\n",
       "      <td>15.671142</td>\n",
       "      <td>9.896164</td>\n",
       "      <td>10.234264</td>\n",
       "      <td>7.860296</td>\n",
       "      <td>8.522605</td>\n",
       "      <td>5.645502</td>\n",
       "      <td>3.312893</td>\n",
       "      <td>82.448246</td>\n",
       "      <td>...</td>\n",
       "      <td>22.701338</td>\n",
       "      <td>71.127044</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12507 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id     BertzCT       Chi1     Chi1n      Chi1v     Chi2n      Chi2v  \\\n",
       "0          0  323.390782   9.879918  5.875576   5.875576  4.304757   4.304757   \n",
       "1          1  273.723798   7.259037  4.441467   5.834958  3.285046   4.485235   \n",
       "2          2  521.643822  10.911303  8.527859  11.050864  6.665291   9.519706   \n",
       "3          3  567.431166  12.453343  7.089119  12.833709  6.478023  10.978151   \n",
       "4          4  112.770735   4.414719  2.866236   2.866236  1.875634   1.875634   \n",
       "...      ...         ...        ...       ...        ...       ...        ...   \n",
       "14832  14832   83.690584   3.560660  1.689533   1.689533  0.924069   0.924069   \n",
       "14833  14833  632.207041  10.911303  6.579933   9.179964  4.653583   6.030052   \n",
       "14835  14835  981.327476  10.363081  6.146219   6.146219  4.700576   4.700576   \n",
       "14836  14836  299.171248   9.949161  6.589761   7.848913  5.276568   5.476436   \n",
       "14837  14837  785.394062  15.671142  9.896164  10.234264  7.860296   8.522605   \n",
       "\n",
       "          Chi3v     Chi4n  EState_VSA1  ...  SlogP_VSA3  VSA_EState9  fr_COO  \\\n",
       "0      2.754513  1.749203     0.000000  ...    4.794537    35.527357       0   \n",
       "1      2.201375  1.289775    45.135471  ...   13.825658    44.707310       0   \n",
       "2      5.824822  1.770579    15.645394  ...   17.964475    45.660120       0   \n",
       "3      7.914542  3.067181    95.639554  ...   31.961948    87.509997       0   \n",
       "4      1.036450  0.727664    17.980451  ...    9.589074    33.333333       2   \n",
       "...         ...       ...          ...  ...         ...          ...     ...   \n",
       "14832  0.408248  0.000000     0.000000  ...    4.794537    16.833333       0   \n",
       "14833  3.670528  1.770579    32.971529  ...   18.947452    61.376610       0   \n",
       "14835  3.064846  2.133897    17.248535  ...    0.000000    66.666667       0   \n",
       "14836  3.978973  2.299833    45.623794  ...    9.088795    45.583333       0   \n",
       "14837  5.645502  3.312893    82.448246  ...   22.701338    71.127044       0   \n",
       "\n",
       "       fr_COO2  EC1  EC2  EC3  EC4  EC5  EC6  \n",
       "0            0    1    1    0    0    0    0  \n",
       "1            0    0    1    1    0    0    0  \n",
       "2            0    1    1    0    0    1    0  \n",
       "3            0    1    1    0    0    0    0  \n",
       "4            2    1    0    1    1    1    0  \n",
       "...        ...  ...  ...  ...  ...  ...  ...  \n",
       "14832        0    1    1    0    0    0    0  \n",
       "14833        0    1    1    0    0    0    0  \n",
       "14835        0    1    1    0    0    0    0  \n",
       "14836        0    0    1    1    0    0    0  \n",
       "14837        0    0    1    0    1    0    0  \n",
       "\n",
       "[12507 rows x 38 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sliced_df = train_data[~outliers]\n",
    "sliced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1a505aad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BertzCT</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>397.738208</td>\n",
       "      <td>393.541823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>144.973737</td>\n",
       "      <td>268.039723</td>\n",
       "      <td>527.123303</td>\n",
       "      <td>2105.774488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chi1</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>7.576097</td>\n",
       "      <td>4.800521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.464102</td>\n",
       "      <td>5.947265</td>\n",
       "      <td>9.593172</td>\n",
       "      <td>29.555098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chi1n</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>4.737679</td>\n",
       "      <td>3.151553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.786883</td>\n",
       "      <td>3.675670</td>\n",
       "      <td>5.953693</td>\n",
       "      <td>19.601189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chi1v</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>5.374875</td>\n",
       "      <td>4.055215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.841578</td>\n",
       "      <td>3.876105</td>\n",
       "      <td>6.706705</td>\n",
       "      <td>24.182670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chi2n</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>3.522331</td>\n",
       "      <td>2.563022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.875634</td>\n",
       "      <td>2.719449</td>\n",
       "      <td>4.572206</td>\n",
       "      <td>15.671142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chi2v</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>4.104202</td>\n",
       "      <td>3.425789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.949719</td>\n",
       "      <td>2.834676</td>\n",
       "      <td>5.330448</td>\n",
       "      <td>19.746226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chi3v</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>2.605935</td>\n",
       "      <td>2.425186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.073604</td>\n",
       "      <td>1.749075</td>\n",
       "      <td>3.319399</td>\n",
       "      <td>12.991234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chi4n</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>1.322295</td>\n",
       "      <td>1.248762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.438129</td>\n",
       "      <td>0.921246</td>\n",
       "      <td>1.923139</td>\n",
       "      <td>7.361430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EState_VSA1</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>24.933549</td>\n",
       "      <td>26.062710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>15.645394</td>\n",
       "      <td>37.250649</td>\n",
       "      <td>123.355843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EState_VSA2</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>8.115131</td>\n",
       "      <td>9.989613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.917906</td>\n",
       "      <td>12.238684</td>\n",
       "      <td>51.366573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExactMolWt</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>243.015583</td>\n",
       "      <td>161.449853</td>\n",
       "      <td>12.021872</td>\n",
       "      <td>142.078250</td>\n",
       "      <td>185.992939</td>\n",
       "      <td>290.040283</td>\n",
       "      <td>959.157468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FpDensityMorgan1</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>1.324855</td>\n",
       "      <td>0.342419</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>1.078947</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FpDensityMorgan2</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>1.895854</td>\n",
       "      <td>0.333790</td>\n",
       "      <td>-5.111111</td>\n",
       "      <td>1.722222</td>\n",
       "      <td>1.909091</td>\n",
       "      <td>2.090909</td>\n",
       "      <td>3.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FpDensityMorgan3</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>2.317235</td>\n",
       "      <td>0.367822</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>2.363636</td>\n",
       "      <td>2.545455</td>\n",
       "      <td>3.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HallKierAlpha</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>-1.066726</td>\n",
       "      <td>0.735629</td>\n",
       "      <td>-3.980000</td>\n",
       "      <td>-1.520000</td>\n",
       "      <td>-1.100000</td>\n",
       "      <td>-0.560000</td>\n",
       "      <td>0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HeavyAtomMolWt</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>228.561694</td>\n",
       "      <td>153.123665</td>\n",
       "      <td>12.018000</td>\n",
       "      <td>132.078000</td>\n",
       "      <td>172.103000</td>\n",
       "      <td>272.132000</td>\n",
       "      <td>907.383000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kappa3</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>3.492298</td>\n",
       "      <td>6.547020</td>\n",
       "      <td>-104.040000</td>\n",
       "      <td>1.724820</td>\n",
       "      <td>3.054021</td>\n",
       "      <td>5.171075</td>\n",
       "      <td>134.391519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxAbsEStateIndex</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>10.496570</td>\n",
       "      <td>1.094146</td>\n",
       "      <td>5.912131</td>\n",
       "      <td>9.873333</td>\n",
       "      <td>10.367703</td>\n",
       "      <td>11.129428</td>\n",
       "      <td>14.632511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MinEStateIndex</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>-1.976576</td>\n",
       "      <td>1.913776</td>\n",
       "      <td>-6.117075</td>\n",
       "      <td>-4.264713</td>\n",
       "      <td>-1.196433</td>\n",
       "      <td>-0.820245</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumHeteroatoms</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>7.370433</td>\n",
       "      <td>5.948247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEOE_VSA10</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>9.689859</td>\n",
       "      <td>12.138339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.041841</td>\n",
       "      <td>17.771384</td>\n",
       "      <td>50.340478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEOE_VSA14</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>13.770812</td>\n",
       "      <td>22.318369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>13.792002</td>\n",
       "      <td>119.568389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEOE_VSA6</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>5.102547</td>\n",
       "      <td>10.326299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.066367</td>\n",
       "      <td>67.022909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEOE_VSA7</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>7.907044</td>\n",
       "      <td>11.613757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.841643</td>\n",
       "      <td>70.190898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEOE_VSA8</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>5.123218</td>\n",
       "      <td>8.332289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.420822</td>\n",
       "      <td>37.601916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMR_VSA10</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>12.636618</td>\n",
       "      <td>12.786773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>11.656692</td>\n",
       "      <td>15.645394</td>\n",
       "      <td>69.644269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMR_VSA5</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>23.207891</td>\n",
       "      <td>22.295830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.420822</td>\n",
       "      <td>18.883484</td>\n",
       "      <td>30.705892</td>\n",
       "      <td>130.035710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlogP_VSA3</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>11.264833</td>\n",
       "      <td>11.250979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.794537</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>14.210589</td>\n",
       "      <td>57.118314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VSA_EState9</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>43.472387</td>\n",
       "      <td>21.229211</td>\n",
       "      <td>-5.430556</td>\n",
       "      <td>29.333333</td>\n",
       "      <td>39.166667</td>\n",
       "      <td>51.833333</td>\n",
       "      <td>134.757698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_COO</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>0.485568</td>\n",
       "      <td>0.639481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr_COO2</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>0.486607</td>\n",
       "      <td>0.639628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC1</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>0.667146</td>\n",
       "      <td>0.471253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC2</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>0.802351</td>\n",
       "      <td>0.398242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC3</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>0.307828</td>\n",
       "      <td>0.461613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC4</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>0.291677</td>\n",
       "      <td>0.454552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC5</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>0.149116</td>\n",
       "      <td>0.356218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC6</th>\n",
       "      <td>12507.0</td>\n",
       "      <td>0.157752</td>\n",
       "      <td>0.364523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count        mean         std         min         25%  \\\n",
       "BertzCT            12507.0  397.738208  393.541823    0.000000  144.973737   \n",
       "Chi1               12507.0    7.576097    4.800521    0.000000    4.464102   \n",
       "Chi1n              12507.0    4.737679    3.151553    0.000000    2.786883   \n",
       "Chi1v              12507.0    5.374875    4.055215    0.000000    2.841578   \n",
       "Chi2n              12507.0    3.522331    2.563022    0.000000    1.875634   \n",
       "Chi2v              12507.0    4.104202    3.425789    0.000000    1.949719   \n",
       "Chi3v              12507.0    2.605935    2.425186    0.000000    1.073604   \n",
       "Chi4n              12507.0    1.322295    1.248762    0.000000    0.438129   \n",
       "EState_VSA1        12507.0   24.933549   26.062710    0.000000    5.969305   \n",
       "EState_VSA2        12507.0    8.115131    9.989613    0.000000    0.000000   \n",
       "ExactMolWt         12507.0  243.015583  161.449853   12.021872  142.078250   \n",
       "FpDensityMorgan1   12507.0    1.324855    0.342419   -1.250000    1.078947   \n",
       "FpDensityMorgan2   12507.0    1.895854    0.333790   -5.111111    1.722222   \n",
       "FpDensityMorgan3   12507.0    2.317235    0.367822    0.500000    2.100000   \n",
       "HallKierAlpha      12507.0   -1.066726    0.735629   -3.980000   -1.520000   \n",
       "HeavyAtomMolWt     12507.0  228.561694  153.123665   12.018000  132.078000   \n",
       "Kappa3             12507.0    3.492298    6.547020 -104.040000    1.724820   \n",
       "MaxAbsEStateIndex  12507.0   10.496570    1.094146    5.912131    9.873333   \n",
       "MinEStateIndex     12507.0   -1.976576    1.913776   -6.117075   -4.264713   \n",
       "NumHeteroatoms     12507.0    7.370433    5.948247    0.000000    4.000000   \n",
       "PEOE_VSA10         12507.0    9.689859   12.138339    0.000000    0.000000   \n",
       "PEOE_VSA14         12507.0   13.770812   22.318369    0.000000    0.000000   \n",
       "PEOE_VSA6          12507.0    5.102547   10.326299    0.000000    0.000000   \n",
       "PEOE_VSA7          12507.0    7.907044   11.613757    0.000000    0.000000   \n",
       "PEOE_VSA8          12507.0    5.123218    8.332289    0.000000    0.000000   \n",
       "SMR_VSA10          12507.0   12.636618   12.786773    0.000000    5.969305   \n",
       "SMR_VSA5           12507.0   23.207891   22.295830    0.000000    6.420822   \n",
       "SlogP_VSA3         12507.0   11.264833   11.250979    0.000000    4.794537   \n",
       "VSA_EState9        12507.0   43.472387   21.229211   -5.430556   29.333333   \n",
       "fr_COO             12507.0    0.485568    0.639481    0.000000    0.000000   \n",
       "fr_COO2            12507.0    0.486607    0.639628    0.000000    0.000000   \n",
       "EC1                12507.0    0.667146    0.471253    0.000000    0.000000   \n",
       "EC2                12507.0    0.802351    0.398242    0.000000    1.000000   \n",
       "EC3                12507.0    0.307828    0.461613    0.000000    0.000000   \n",
       "EC4                12507.0    0.291677    0.454552    0.000000    0.000000   \n",
       "EC5                12507.0    0.149116    0.356218    0.000000    0.000000   \n",
       "EC6                12507.0    0.157752    0.364523    0.000000    0.000000   \n",
       "\n",
       "                          50%         75%          max  \n",
       "BertzCT            268.039723  527.123303  2105.774488  \n",
       "Chi1                 5.947265    9.593172    29.555098  \n",
       "Chi1n                3.675670    5.953693    19.601189  \n",
       "Chi1v                3.876105    6.706705    24.182670  \n",
       "Chi2n                2.719449    4.572206    15.671142  \n",
       "Chi2v                2.834676    5.330448    19.746226  \n",
       "Chi3v                1.749075    3.319399    12.991234  \n",
       "Chi4n                0.921246    1.923139     7.361430  \n",
       "EState_VSA1         15.645394   37.250649   123.355843  \n",
       "EState_VSA2          5.917906   12.238684    51.366573  \n",
       "ExactMolWt         185.992939  290.040283   959.157468  \n",
       "FpDensityMorgan1     1.300000    1.500000     3.000000  \n",
       "FpDensityMorgan2     1.909091    2.090909     3.200000  \n",
       "FpDensityMorgan3     2.363636    2.545455     3.400000  \n",
       "HallKierAlpha       -1.100000   -0.560000     0.820000  \n",
       "HeavyAtomMolWt     172.103000  272.132000   907.383000  \n",
       "Kappa3               3.054021    5.171075   134.391519  \n",
       "MaxAbsEStateIndex   10.367703   11.129428    14.632511  \n",
       "MinEStateIndex      -1.196433   -0.820245     4.000000  \n",
       "NumHeteroatoms       5.000000    9.000000    31.000000  \n",
       "PEOE_VSA10           6.041841   17.771384    50.340478  \n",
       "PEOE_VSA14           5.969305   13.792002   119.568389  \n",
       "PEOE_VSA6            0.000000    6.066367    67.022909  \n",
       "PEOE_VSA7            0.000000   12.841643    70.190898  \n",
       "PEOE_VSA8            0.000000    6.420822    37.601916  \n",
       "SMR_VSA10           11.656692   15.645394    69.644269  \n",
       "SMR_VSA5            18.883484   30.705892   130.035710  \n",
       "SlogP_VSA3           9.589074   14.210589    57.118314  \n",
       "VSA_EState9         39.166667   51.833333   134.757698  \n",
       "fr_COO               0.000000    1.000000     2.000000  \n",
       "fr_COO2              0.000000    1.000000     2.000000  \n",
       "EC1                  1.000000    1.000000     1.000000  \n",
       "EC2                  1.000000    1.000000     1.000000  \n",
       "EC3                  0.000000    1.000000     1.000000  \n",
       "EC4                  0.000000    1.000000     1.000000  \n",
       "EC5                  0.000000    0.000000     1.000000  \n",
       "EC6                  0.000000    0.000000     1.000000  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sliced_df.drop('id',axis=1).describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6be8b6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_value_cols = ['BertzCT', 'ExactMolWt', 'HeavyAtomMolWt']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1908b08b",
   "metadata": {},
   "source": [
    "# Splitting features and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5afd04a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a2c78957",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(['id','EC1', 'EC2', 'EC3', 'EC4', 'EC5', 'EC6'], axis=1)\n",
    "y = train_data[['EC1', 'EC2']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51180ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X,y, test_size=.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6e86743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BertzCT</th>\n",
       "      <th>Chi1</th>\n",
       "      <th>Chi1n</th>\n",
       "      <th>Chi1v</th>\n",
       "      <th>Chi2n</th>\n",
       "      <th>Chi2v</th>\n",
       "      <th>Chi3v</th>\n",
       "      <th>Chi4n</th>\n",
       "      <th>EState_VSA1</th>\n",
       "      <th>EState_VSA2</th>\n",
       "      <th>...</th>\n",
       "      <th>PEOE_VSA14</th>\n",
       "      <th>PEOE_VSA6</th>\n",
       "      <th>PEOE_VSA7</th>\n",
       "      <th>PEOE_VSA8</th>\n",
       "      <th>SMR_VSA10</th>\n",
       "      <th>SMR_VSA5</th>\n",
       "      <th>SlogP_VSA3</th>\n",
       "      <th>VSA_EState9</th>\n",
       "      <th>fr_COO</th>\n",
       "      <th>fr_COO2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6788</th>\n",
       "      <td>254.583169</td>\n",
       "      <td>4.825699</td>\n",
       "      <td>2.793756</td>\n",
       "      <td>2.793756</td>\n",
       "      <td>1.932542</td>\n",
       "      <td>1.932542</td>\n",
       "      <td>1.438134</td>\n",
       "      <td>0.895230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.749512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.393687</td>\n",
       "      <td>5.687386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>170.977545</td>\n",
       "      <td>5.947265</td>\n",
       "      <td>3.675670</td>\n",
       "      <td>3.675670</td>\n",
       "      <td>2.757262</td>\n",
       "      <td>2.757262</td>\n",
       "      <td>1.708684</td>\n",
       "      <td>0.955337</td>\n",
       "      <td>18.359432</td>\n",
       "      <td>11.949021</td>\n",
       "      <td>...</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.938611</td>\n",
       "      <td>25.304306</td>\n",
       "      <td>9.531400</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3551</th>\n",
       "      <td>236.164996</td>\n",
       "      <td>5.036581</td>\n",
       "      <td>3.414884</td>\n",
       "      <td>3.414884</td>\n",
       "      <td>2.703542</td>\n",
       "      <td>2.703542</td>\n",
       "      <td>1.827002</td>\n",
       "      <td>1.029291</td>\n",
       "      <td>6.103966</td>\n",
       "      <td>12.356394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.152040</td>\n",
       "      <td>17.696186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.103966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8301</th>\n",
       "      <td>170.034424</td>\n",
       "      <td>5.092224</td>\n",
       "      <td>2.925131</td>\n",
       "      <td>2.925131</td>\n",
       "      <td>2.116586</td>\n",
       "      <td>2.116586</td>\n",
       "      <td>1.611120</td>\n",
       "      <td>0.757462</td>\n",
       "      <td>24.401273</td>\n",
       "      <td>6.420822</td>\n",
       "      <td>...</td>\n",
       "      <td>12.062229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.907600</td>\n",
       "      <td>12.462662</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>83.108030</td>\n",
       "      <td>2.642734</td>\n",
       "      <td>1.049739</td>\n",
       "      <td>1.049739</td>\n",
       "      <td>0.504904</td>\n",
       "      <td>0.504904</td>\n",
       "      <td>0.142577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.359432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.752550</td>\n",
       "      <td>6.544756</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>29.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11798</th>\n",
       "      <td>146.218849</td>\n",
       "      <td>5.163902</td>\n",
       "      <td>3.722225</td>\n",
       "      <td>3.722225</td>\n",
       "      <td>2.229188</td>\n",
       "      <td>2.229188</td>\n",
       "      <td>1.749075</td>\n",
       "      <td>0.933119</td>\n",
       "      <td>19.968504</td>\n",
       "      <td>13.016977</td>\n",
       "      <td>...</td>\n",
       "      <td>86.057216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.822697</td>\n",
       "      <td>25.235636</td>\n",
       "      <td>9.088795</td>\n",
       "      <td>35.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13896</th>\n",
       "      <td>104.605938</td>\n",
       "      <td>3.553418</td>\n",
       "      <td>2.189533</td>\n",
       "      <td>2.189533</td>\n",
       "      <td>1.477829</td>\n",
       "      <td>1.477829</td>\n",
       "      <td>0.711731</td>\n",
       "      <td>0.182919</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.132734</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6637</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>1.341641</td>\n",
       "      <td>1.341641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.495693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.027704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.180556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>196.732729</td>\n",
       "      <td>3.931852</td>\n",
       "      <td>2.786883</td>\n",
       "      <td>2.786883</td>\n",
       "      <td>1.927161</td>\n",
       "      <td>1.927161</td>\n",
       "      <td>0.962617</td>\n",
       "      <td>0.350229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.499024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.199101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7336</th>\n",
       "      <td>221.263866</td>\n",
       "      <td>6.270857</td>\n",
       "      <td>3.876105</td>\n",
       "      <td>3.876105</td>\n",
       "      <td>2.719449</td>\n",
       "      <td>2.719449</td>\n",
       "      <td>1.749075</td>\n",
       "      <td>1.002679</td>\n",
       "      <td>37.312774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.705892</td>\n",
       "      <td>4.736863</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11870 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          BertzCT      Chi1     Chi1n     Chi1v     Chi2n     Chi2v     Chi3v  \\\n",
       "6788   254.583169  4.825699  2.793756  2.793756  1.932542  1.932542  1.438134   \n",
       "1962   170.977545  5.947265  3.675670  3.675670  2.757262  2.757262  1.708684   \n",
       "3551   236.164996  5.036581  3.414884  3.414884  2.703542  2.703542  1.827002   \n",
       "8301   170.034424  5.092224  2.925131  2.925131  2.116586  2.116586  1.611120   \n",
       "281     83.108030  2.642734  1.049739  1.049739  0.504904  0.504904  0.142577   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "11798  146.218849  5.163902  3.722225  3.722225  2.229188  2.229188  1.749075   \n",
       "13896  104.605938  3.553418  2.189533  2.189533  1.477829  1.477829  0.711731   \n",
       "6637     2.000000  1.732051  1.341641  1.341641  0.000000  0.000000  0.000000   \n",
       "2575   196.732729  3.931852  2.786883  2.786883  1.927161  1.927161  0.962617   \n",
       "7336   221.263866  6.270857  3.876105  3.876105  2.719449  2.719449  1.749075   \n",
       "\n",
       "          Chi4n  EState_VSA1  EState_VSA2  ...  PEOE_VSA14  PEOE_VSA6  \\\n",
       "6788   0.895230     0.000000     5.749512  ...    0.000000   0.000000   \n",
       "1962   0.955337    18.359432    11.949021  ...    5.969305   0.000000   \n",
       "3551   1.029291     6.103966    12.356394  ...    0.000000  12.152040   \n",
       "8301   0.757462    24.401273     6.420822  ...   12.062229   0.000000   \n",
       "281    0.000000    18.359432     0.000000  ...    5.969305   0.000000   \n",
       "...         ...          ...          ...  ...         ...        ...   \n",
       "11798  0.933119    19.968504    13.016977  ...   86.057216   0.000000   \n",
       "13896  0.182919     5.969305     0.000000  ...    5.969305   0.000000   \n",
       "6637   0.000000     0.000000     0.000000  ...   13.495693   0.000000   \n",
       "2575   0.350229     0.000000    11.499024  ...    0.000000  18.199101   \n",
       "7336   1.002679    37.312774     0.000000  ...    0.000000   0.000000   \n",
       "\n",
       "       PEOE_VSA7  PEOE_VSA8  SMR_VSA10   SMR_VSA5  SlogP_VSA3  VSA_EState9  \\\n",
       "6788    0.000000  12.393687   5.687386   0.000000    0.000000    30.000000   \n",
       "1962    0.000000   0.000000  11.938611  25.304306    9.531400    47.000000   \n",
       "3551   17.696186   0.000000   0.000000   6.103966    0.000000    36.166667   \n",
       "8301    0.000000   0.000000  17.907600  12.462662    9.589074    39.500000   \n",
       "281     0.000000   0.000000  11.752550   6.544756    9.589074    29.666667   \n",
       "...          ...        ...        ...        ...         ...          ...   \n",
       "11798   0.000000   0.000000   7.822697  25.235636    9.088795    35.166667   \n",
       "13896  12.132734   0.000000   5.969305   0.000000    0.000000    23.166667   \n",
       "6637    0.000000   0.000000   0.000000  13.027704    0.000000     8.180556   \n",
       "2575    0.000000   0.000000   0.000000   0.000000    0.000000    23.333333   \n",
       "7336    0.000000   0.000000   0.000000  30.705892    4.736863    41.666667   \n",
       "\n",
       "       fr_COO  fr_COO2  \n",
       "6788        0        0  \n",
       "1962        1        1  \n",
       "3551        0        0  \n",
       "8301        1        1  \n",
       "281         1        1  \n",
       "...       ...      ...  \n",
       "11798       0        0  \n",
       "13896       1        1  \n",
       "6637        0        0  \n",
       "2575        0        0  \n",
       "7336        0        0  \n",
       "\n",
       "[11870 rows x 31 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78c4c7d",
   "metadata": {},
   "source": [
    "## Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f75cb211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BertzCT</th>\n",
       "      <th>Chi1</th>\n",
       "      <th>Chi1n</th>\n",
       "      <th>Chi1v</th>\n",
       "      <th>Chi2n</th>\n",
       "      <th>Chi2v</th>\n",
       "      <th>Chi3v</th>\n",
       "      <th>Chi4n</th>\n",
       "      <th>EState_VSA1</th>\n",
       "      <th>EState_VSA2</th>\n",
       "      <th>...</th>\n",
       "      <th>PEOE_VSA14</th>\n",
       "      <th>PEOE_VSA6</th>\n",
       "      <th>PEOE_VSA7</th>\n",
       "      <th>PEOE_VSA8</th>\n",
       "      <th>SMR_VSA10</th>\n",
       "      <th>SMR_VSA5</th>\n",
       "      <th>SlogP_VSA3</th>\n",
       "      <th>VSA_EState9</th>\n",
       "      <th>fr_COO</th>\n",
       "      <th>fr_COO2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6788</th>\n",
       "      <td>254.583169</td>\n",
       "      <td>4.825699</td>\n",
       "      <td>2.793756</td>\n",
       "      <td>2.793756</td>\n",
       "      <td>1.932542</td>\n",
       "      <td>1.932542</td>\n",
       "      <td>1.438134</td>\n",
       "      <td>0.895230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.749512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.393687</td>\n",
       "      <td>5.687386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>170.977545</td>\n",
       "      <td>5.947265</td>\n",
       "      <td>3.675670</td>\n",
       "      <td>3.675670</td>\n",
       "      <td>2.757262</td>\n",
       "      <td>2.757262</td>\n",
       "      <td>1.708684</td>\n",
       "      <td>0.955337</td>\n",
       "      <td>18.359432</td>\n",
       "      <td>11.949021</td>\n",
       "      <td>...</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.938611</td>\n",
       "      <td>25.304306</td>\n",
       "      <td>9.531400</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3551</th>\n",
       "      <td>236.164996</td>\n",
       "      <td>5.036581</td>\n",
       "      <td>3.414884</td>\n",
       "      <td>3.414884</td>\n",
       "      <td>2.703542</td>\n",
       "      <td>2.703542</td>\n",
       "      <td>1.827002</td>\n",
       "      <td>1.029291</td>\n",
       "      <td>6.103966</td>\n",
       "      <td>12.356394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.15204</td>\n",
       "      <td>17.696186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.103966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8301</th>\n",
       "      <td>170.034424</td>\n",
       "      <td>5.092224</td>\n",
       "      <td>2.925131</td>\n",
       "      <td>2.925131</td>\n",
       "      <td>2.116586</td>\n",
       "      <td>2.116586</td>\n",
       "      <td>1.611120</td>\n",
       "      <td>0.757462</td>\n",
       "      <td>24.401273</td>\n",
       "      <td>6.420822</td>\n",
       "      <td>...</td>\n",
       "      <td>12.062229</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.907600</td>\n",
       "      <td>12.462662</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>83.108030</td>\n",
       "      <td>2.642734</td>\n",
       "      <td>1.049739</td>\n",
       "      <td>1.049739</td>\n",
       "      <td>0.504904</td>\n",
       "      <td>0.504904</td>\n",
       "      <td>0.142577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.359432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.752550</td>\n",
       "      <td>6.544756</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>29.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         BertzCT      Chi1     Chi1n     Chi1v     Chi2n     Chi2v     Chi3v  \\\n",
       "6788  254.583169  4.825699  2.793756  2.793756  1.932542  1.932542  1.438134   \n",
       "1962  170.977545  5.947265  3.675670  3.675670  2.757262  2.757262  1.708684   \n",
       "3551  236.164996  5.036581  3.414884  3.414884  2.703542  2.703542  1.827002   \n",
       "8301  170.034424  5.092224  2.925131  2.925131  2.116586  2.116586  1.611120   \n",
       "281    83.108030  2.642734  1.049739  1.049739  0.504904  0.504904  0.142577   \n",
       "\n",
       "         Chi4n  EState_VSA1  EState_VSA2  ...  PEOE_VSA14  PEOE_VSA6  \\\n",
       "6788  0.895230     0.000000     5.749512  ...    0.000000    0.00000   \n",
       "1962  0.955337    18.359432    11.949021  ...    5.969305    0.00000   \n",
       "3551  1.029291     6.103966    12.356394  ...    0.000000   12.15204   \n",
       "8301  0.757462    24.401273     6.420822  ...   12.062229    0.00000   \n",
       "281   0.000000    18.359432     0.000000  ...    5.969305    0.00000   \n",
       "\n",
       "      PEOE_VSA7  PEOE_VSA8  SMR_VSA10   SMR_VSA5  SlogP_VSA3  VSA_EState9  \\\n",
       "6788   0.000000  12.393687   5.687386   0.000000    0.000000    30.000000   \n",
       "1962   0.000000   0.000000  11.938611  25.304306    9.531400    47.000000   \n",
       "3551  17.696186   0.000000   0.000000   6.103966    0.000000    36.166667   \n",
       "8301   0.000000   0.000000  17.907600  12.462662    9.589074    39.500000   \n",
       "281    0.000000   0.000000  11.752550   6.544756    9.589074    29.666667   \n",
       "\n",
       "      fr_COO  fr_COO2  \n",
       "6788       0        0  \n",
       "1962       1        1  \n",
       "3551       0        0  \n",
       "8301       1        1  \n",
       "281        1        1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# X_train=pd.DataFrame(scaler.fit_transform(X_train),index=X_train.index,columns=X_train.columns)\n",
    "# X_val=pd.DataFrame(scaler.fit_transform(X_val),index=X_val.index,columns=X_val.columns)\n",
    "\n",
    "# X_train = pd.concat([X_train_num_f, X_train[X_train.columns[-4:]]], axis=1)\n",
    "# X_val = pd.concat([X_val_num_f, X_val[X_val.columns[-4:]]], axis=1)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2aec026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d21fde",
   "metadata": {},
   "source": [
    "## Building Models with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c61e024a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "471e3429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(y_hat):\n",
    "    matrix = multilabel_confusion_matrix(y_val, y_hat)\n",
    "    num_labels = matrix.shape[0]\n",
    "\n",
    "    fig, axes = plt.subplots(num_labels, figsize=(8, 4 * num_labels))\n",
    "\n",
    "    for i in range(num_labels):\n",
    "        ax = axes[i] if num_labels > 1 else axes\n",
    "        ax.imshow(matrix[i], cmap='BuPu')\n",
    "\n",
    "        ax.set_xticks([0, 1])\n",
    "        ax.set_yticks([0, 1])\n",
    "\n",
    "        ax.set_xticklabels(['Predicted False', 'Predicted True'])\n",
    "        ax.set_yticklabels(['Actual False', 'Actual True'])\n",
    "\n",
    "        ax.set_xlabel('Predicted values')\n",
    "        ax.set_ylabel('Actual values')\n",
    "\n",
    "        for j in range(2):\n",
    "            for k in range(2):\n",
    "                ax.text(k, j, matrix[i][j, k],\n",
    "                        ha='center', va='center', color='black')\n",
    "\n",
    "        ax.set_title(f'EC{i + 1} Confusion Matrix')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e1a83a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(clf):\n",
    "    y_hat = clf.predict(X_val)\n",
    "    train_hat = clf.predict(X_train)\n",
    "    train_acc = accuracy_score(y_train, train_hat)\n",
    "    acc = accuracy_score(y_val, y_hat)\n",
    "    print(f'Train Accuracy score is: {train_acc}')\n",
    "    print(f'Test Accuracy score is: {acc}')\n",
    "    plot_cm(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565058de",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9158d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    class_weight_1_0 = trial.suggest_float(\"class_weight_1_0\", 1, 2)\n",
    "    class_weight_2_0 = trial.suggest_float(\"class_weight_2_0\", 1, 3)\n",
    "    parameters = {\n",
    "        'n_estimators':trial.suggest_int('n_estimators', 100, 400, step=100),\n",
    "        'max_depth':trial.suggest_int('max_depth', 3, 10),\n",
    "        'min_samples_split':trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf':trial.suggest_int('min_samples_leaf', 1, 5),\n",
    "        'max_features':trial.suggest_int('max_features', 1, 31, step=2),\n",
    "        'bootstrap':trial.suggest_categorical('bootstrap', [True, False]),\n",
    "    }\n",
    "    class_weights = [{0: class_weight_1_0, 1:1}, {0:class_weight_2_0, 1:1}]\n",
    "\n",
    "    model = RandomForestClassifier(**parameters, class_weight=class_weights, random_state=2)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_hat = model.predict(X_val)\n",
    "    score = accuracy_score(y_val, y_hat)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "042690d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 15:36:30,244] A new study created in memory with name: no-name-63b6cbae-d656-4306-82c9-3b16b0aeb8dd\n",
      "[I 2023-07-05 15:37:18,594] Trial 0 finished with value: 0.477088948787062 and parameters: {'class_weight_1_0': 1.0523372301378335, 'class_weight_2_0': 2.893818291306569, 'n_estimators': 400, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 25, 'bootstrap': False}. Best is trial 0 with value: 0.477088948787062.\n",
      "[I 2023-07-05 15:37:42,516] Trial 1 finished with value: 0.4784366576819407 and parameters: {'class_weight_1_0': 1.8587836423844046, 'class_weight_2_0': 2.986006027362227, 'n_estimators': 200, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 5, 'max_features': 25, 'bootstrap': False}. Best is trial 1 with value: 0.4784366576819407.\n",
      "[I 2023-07-05 15:37:57,443] Trial 2 finished with value: 0.5630053908355795 and parameters: {'class_weight_1_0': 1.4587939891232669, 'class_weight_2_0': 2.595882196883642, 'n_estimators': 400, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 5, 'bootstrap': False}. Best is trial 2 with value: 0.5630053908355795.\n",
      "[I 2023-07-05 15:38:18,331] Trial 3 finished with value: 0.5033692722371967 and parameters: {'class_weight_1_0': 1.9857418651824723, 'class_weight_2_0': 2.94234007094376, 'n_estimators': 300, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 17, 'bootstrap': False}. Best is trial 2 with value: 0.5630053908355795.\n",
      "[I 2023-07-05 15:38:34,798] Trial 4 finished with value: 0.5579514824797843 and parameters: {'class_weight_1_0': 1.902071513679864, 'class_weight_2_0': 2.5451847994817207, 'n_estimators': 400, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 25, 'bootstrap': True}. Best is trial 2 with value: 0.5630053908355795.\n",
      "[I 2023-07-05 15:38:44,089] Trial 5 finished with value: 0.569743935309973 and parameters: {'class_weight_1_0': 1.3309041289538777, 'class_weight_2_0': 1.7214434542142536, 'n_estimators': 400, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 5, 'bootstrap': True}. Best is trial 5 with value: 0.569743935309973.\n",
      "[I 2023-07-05 15:39:15,739] Trial 6 finished with value: 0.5626684636118598 and parameters: {'class_weight_1_0': 1.1994521422442952, 'class_weight_2_0': 1.9813291235839183, 'n_estimators': 300, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 23, 'bootstrap': True}. Best is trial 5 with value: 0.569743935309973.\n",
      "[I 2023-07-05 15:39:18,601] Trial 7 finished with value: 0.567722371967655 and parameters: {'class_weight_1_0': 1.5607540370195938, 'class_weight_2_0': 1.5283299974386846, 'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 11, 'bootstrap': False}. Best is trial 5 with value: 0.569743935309973.\n",
      "[I 2023-07-05 15:39:22,139] Trial 8 finished with value: 0.5616576819407008 and parameters: {'class_weight_1_0': 1.051888093097284, 'class_weight_2_0': 2.30699414229366, 'n_estimators': 100, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 7, 'bootstrap': True}. Best is trial 5 with value: 0.569743935309973.\n",
      "[I 2023-07-05 15:39:29,258] Trial 9 finished with value: 0.5539083557951483 and parameters: {'class_weight_1_0': 1.9398818508275588, 'class_weight_2_0': 1.519920963309228, 'n_estimators': 300, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 7, 'bootstrap': True}. Best is trial 5 with value: 0.569743935309973.\n",
      "[I 2023-07-05 15:39:31,443] Trial 10 finished with value: 0.5694070080862533 and parameters: {'class_weight_1_0': 1.3382036330597091, 'class_weight_2_0': 1.0330730819365268, 'n_estimators': 200, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 1, 'bootstrap': True}. Best is trial 5 with value: 0.569743935309973.\n",
      "[I 2023-07-05 15:39:33,835] Trial 11 finished with value: 0.5683962264150944 and parameters: {'class_weight_1_0': 1.3535048174095257, 'class_weight_2_0': 1.0403942987837538, 'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 1, 'bootstrap': True}. Best is trial 5 with value: 0.569743935309973.\n",
      "[I 2023-07-05 15:39:36,101] Trial 12 finished with value: 0.5690700808625337 and parameters: {'class_weight_1_0': 1.3165562722924633, 'class_weight_2_0': 1.035253911436906, 'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 1, 'bootstrap': True}. Best is trial 5 with value: 0.569743935309973.\n",
      "[I 2023-07-05 15:39:52,028] Trial 13 finished with value: 0.5683962264150944 and parameters: {'class_weight_1_0': 1.5799753511150514, 'class_weight_2_0': 1.44760969918423, 'n_estimators': 200, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 15, 'bootstrap': True}. Best is trial 5 with value: 0.569743935309973.\n",
      "[I 2023-07-05 15:40:29,194] Trial 14 finished with value: 0.5633423180592992 and parameters: {'class_weight_1_0': 1.2322613663023583, 'class_weight_2_0': 1.7900158713739767, 'n_estimators': 300, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 31, 'bootstrap': True}. Best is trial 5 with value: 0.569743935309973.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=15)\n",
    "best_params = study.best_params\n",
    "best_score = study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bea78160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best parameters are:  {'class_weight_1_0': 1.3309041289538777, 'class_weight_2_0': 1.7214434542142536, 'n_estimators': 400, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 5, 'bootstrap': True}\n",
      "The best score is:  0.569743935309973\n"
     ]
    }
   ],
   "source": [
    "print('the best parameters are: ', best_params)\n",
    "print('The best score is: ', best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d376cc",
   "metadata": {},
   "source": [
    "Past params:\n",
    "- the best parameters are:  {'n_estimators': 200, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 2, 'bootstrap': True}|The best score is:  0.5690700808625337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "264affdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight_1_0=1.3309041289538777\n",
    "class_weight_2_0=1.7214434542142536\n",
    "class_weights = [{0: class_weight_1_0, 1:1},{0: class_weight_2_0, 1:1}]\n",
    "# del best_params['class_weight_1_0']\n",
    "# del best_params['class_weight_2_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bb892b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy score is: 0.5692502106149958\n",
      "Test Accuracy score is: 0.569743935309973\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(**best_params, class_weight=class_weights, random_state=2)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "evaluate_model(rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb740a8",
   "metadata": {},
   "source": [
    "# Experimenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a77aa172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7c4a72de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(y_hat):\n",
    "    matrix = confusion_matrix(y_val, y_hat)\n",
    "    ax = sns.heatmap(matrix, annot=True, fmt='d', cmap='crest')\n",
    "    ax.set(ylabel='Predicted values', xlabel='Actual values')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6bfcc327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(positive_probs):\n",
    "    fpr, tpr, _ = roc_curve(y_val.astype('float'), positive_probs)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', label='No Algorithm')\n",
    "    plt.plot(fpr, tpr, marker='.', label='With Algorithm')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9074df9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(clf):\n",
    "    y_hat = clf.predict(X_val)\n",
    "    train_hat = clf.predict(X_train)\n",
    "    train_acc = accuracy_score(y_train, train_hat)\n",
    "    acc = accuracy_score(y_val, y_hat)\n",
    "    pos_probs = clf.predict_proba(X_val)[:,1]\n",
    "    roc = roc_auc_score(y_val, pos_probs)\n",
    "    print(f'Train Accuracy score is: {train_acc}')\n",
    "    print(f'Test Accuracy score is: {acc}')\n",
    "    print(f'ROCAUC score is: {roc}')\n",
    "    print(classification_report(y_val, y_hat))\n",
    "    plot_cm(y_hat)\n",
    "    plot_roc_curve(pos_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20675d0",
   "metadata": {},
   "source": [
    "## Trying to predict EC1 class and EC2 class separately as a binary problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "205abfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c9cadb",
   "metadata": {},
   "source": [
    "# EC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "69892d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BertzCT</th>\n",
       "      <th>ExactMolWt</th>\n",
       "      <th>HeavyAtomMolWt</th>\n",
       "      <th>Chi1</th>\n",
       "      <th>Chi1n</th>\n",
       "      <th>Chi1v</th>\n",
       "      <th>Chi2n</th>\n",
       "      <th>Chi2v</th>\n",
       "      <th>Chi3v</th>\n",
       "      <th>Chi4n</th>\n",
       "      <th>...</th>\n",
       "      <th>PEOE_VSA14</th>\n",
       "      <th>PEOE_VSA6</th>\n",
       "      <th>PEOE_VSA7</th>\n",
       "      <th>PEOE_VSA8</th>\n",
       "      <th>SMR_VSA10</th>\n",
       "      <th>SMR_VSA5</th>\n",
       "      <th>SlogP_VSA3</th>\n",
       "      <th>VSA_EState9</th>\n",
       "      <th>fr_COO</th>\n",
       "      <th>fr_COO2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6788</th>\n",
       "      <td>-0.479488</td>\n",
       "      <td>-0.631739</td>\n",
       "      <td>-0.633457</td>\n",
       "      <td>4.825699</td>\n",
       "      <td>2.793756</td>\n",
       "      <td>2.793756</td>\n",
       "      <td>1.932542</td>\n",
       "      <td>1.932542</td>\n",
       "      <td>1.438134</td>\n",
       "      <td>0.895230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.393687</td>\n",
       "      <td>5.687386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>-0.633683</td>\n",
       "      <td>-0.596321</td>\n",
       "      <td>-0.577001</td>\n",
       "      <td>5.947265</td>\n",
       "      <td>3.675670</td>\n",
       "      <td>3.675670</td>\n",
       "      <td>2.757262</td>\n",
       "      <td>2.757262</td>\n",
       "      <td>1.708684</td>\n",
       "      <td>0.955337</td>\n",
       "      <td>...</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.938611</td>\n",
       "      <td>25.304306</td>\n",
       "      <td>9.531400</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3551</th>\n",
       "      <td>-0.513457</td>\n",
       "      <td>-0.613643</td>\n",
       "      <td>-0.651981</td>\n",
       "      <td>5.036581</td>\n",
       "      <td>3.414884</td>\n",
       "      <td>3.414884</td>\n",
       "      <td>2.703542</td>\n",
       "      <td>2.703542</td>\n",
       "      <td>1.827002</td>\n",
       "      <td>1.029291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.15204</td>\n",
       "      <td>17.696186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.103966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8301</th>\n",
       "      <td>-0.635423</td>\n",
       "      <td>-0.538873</td>\n",
       "      <td>-0.525580</td>\n",
       "      <td>5.092224</td>\n",
       "      <td>2.925131</td>\n",
       "      <td>2.925131</td>\n",
       "      <td>2.116586</td>\n",
       "      <td>2.116586</td>\n",
       "      <td>1.611120</td>\n",
       "      <td>0.757462</td>\n",
       "      <td>...</td>\n",
       "      <td>12.062229</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.907600</td>\n",
       "      <td>12.462662</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>-0.795743</td>\n",
       "      <td>-0.835799</td>\n",
       "      <td>-0.821568</td>\n",
       "      <td>2.642734</td>\n",
       "      <td>1.049739</td>\n",
       "      <td>1.049739</td>\n",
       "      <td>0.504904</td>\n",
       "      <td>0.504904</td>\n",
       "      <td>0.142577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.752550</td>\n",
       "      <td>6.544756</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>29.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       BertzCT  ExactMolWt  HeavyAtomMolWt      Chi1     Chi1n     Chi1v  \\\n",
       "6788 -0.479488   -0.631739       -0.633457  4.825699  2.793756  2.793756   \n",
       "1962 -0.633683   -0.596321       -0.577001  5.947265  3.675670  3.675670   \n",
       "3551 -0.513457   -0.613643       -0.651981  5.036581  3.414884  3.414884   \n",
       "8301 -0.635423   -0.538873       -0.525580  5.092224  2.925131  2.925131   \n",
       "281  -0.795743   -0.835799       -0.821568  2.642734  1.049739  1.049739   \n",
       "\n",
       "         Chi2n     Chi2v     Chi3v     Chi4n  ...  PEOE_VSA14  PEOE_VSA6  \\\n",
       "6788  1.932542  1.932542  1.438134  0.895230  ...    0.000000    0.00000   \n",
       "1962  2.757262  2.757262  1.708684  0.955337  ...    5.969305    0.00000   \n",
       "3551  2.703542  2.703542  1.827002  1.029291  ...    0.000000   12.15204   \n",
       "8301  2.116586  2.116586  1.611120  0.757462  ...   12.062229    0.00000   \n",
       "281   0.504904  0.504904  0.142577  0.000000  ...    5.969305    0.00000   \n",
       "\n",
       "      PEOE_VSA7  PEOE_VSA8  SMR_VSA10   SMR_VSA5  SlogP_VSA3  VSA_EState9  \\\n",
       "6788   0.000000  12.393687   5.687386   0.000000    0.000000    30.000000   \n",
       "1962   0.000000   0.000000  11.938611  25.304306    9.531400    47.000000   \n",
       "3551  17.696186   0.000000   0.000000   6.103966    0.000000    36.166667   \n",
       "8301   0.000000   0.000000  17.907600  12.462662    9.589074    39.500000   \n",
       "281    0.000000   0.000000  11.752550   6.544756    9.589074    29.666667   \n",
       "\n",
       "      fr_COO  fr_COO2  \n",
       "6788       0        0  \n",
       "1962       1        1  \n",
       "3551       0        0  \n",
       "8301       1        1  \n",
       "281        1        1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_data.drop(['id','EC1', 'EC2', 'EC3', 'EC4', 'EC5', 'EC6'], axis=1)\n",
    "y = train_data['EC1']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y, test_size=.2, random_state=2)\n",
    "cols_not = [i for i in X_train.columns if i not in high_value_cols]\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_sc=pd.DataFrame(scaler.fit_transform(X_train[high_value_cols]),index=X_train.index,columns=high_value_cols)\n",
    "val_sc=pd.DataFrame(scaler.fit_transform(X_val[high_value_cols]),index=X_val.index,columns=high_value_cols)\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# X_train=pd.DataFrame(scaler.fit_transform(X_train),index=X_train.index,columns=X_train.columns)\n",
    "# X_val=pd.DataFrame(scaler.fit_transform(X_val),index=X_val.index,columns=X_val.columns)\n",
    "\n",
    "X_train = pd.concat([train_sc, X_train[cols_not]], axis=1)\n",
    "X_val = pd.concat([val_sc, X_val[cols_not]], axis=1)\n",
    "\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6252bd98",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e4bde2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    class_weight_0 = trial.suggest_float(\"class_weight_1_0\", 1, 2)\n",
    "    parameters = {\n",
    "        'n_estimators':trial.suggest_int('n_estimators', 100, 400, step=100),\n",
    "        'max_depth':trial.suggest_int('max_depth', 3, 10),\n",
    "        'min_samples_split':trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf':trial.suggest_int('min_samples_leaf', 1, 5),\n",
    "        'max_features':trial.suggest_int('max_features', 2, 31, step=2),\n",
    "        'bootstrap':trial.suggest_categorical('bootstrap', [True, False]),\n",
    "#         'class_weight':trial.suggest_categorical('class_weight', [{0:1,1:1}, {0:2,1:1}]),\n",
    "    }\n",
    "    class_weights = {0:class_weight_0,1:1}\n",
    "    \n",
    "    model = RandomForestClassifier(**parameters, class_weight=class_weights, random_state=2)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_hat = model.predict(X_val)\n",
    "    pos_probs = model.predict_proba(X_val)[:,1]\n",
    "    score = roc_auc_score(y_val, pos_probs)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "26b6e755",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:08:26,124] A new study created in memory with name: no-name-ff48a9ae-9c12-4bba-b923-48d44df6de07\n",
      "[I 2023-07-05 16:08:36,419] Trial 0 finished with value: 0.7102033088888717 and parameters: {'class_weight_1_0': 1.8671478671483972, 'n_estimators': 100, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 16, 'bootstrap': False}. Best is trial 0 with value: 0.7102033088888717.\n",
      "[I 2023-07-05 16:08:41,093] Trial 1 finished with value: 0.7152944025016292 and parameters: {'class_weight_1_0': 1.8753492868647414, 'n_estimators': 200, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 8, 'bootstrap': True}. Best is trial 1 with value: 0.7152944025016292.\n",
      "[I 2023-07-05 16:09:05,048] Trial 2 finished with value: 0.6627792502839833 and parameters: {'class_weight_1_0': 1.6066407645627856, 'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 30, 'bootstrap': False}. Best is trial 1 with value: 0.7152944025016292.\n",
      "[I 2023-07-05 16:09:18,152] Trial 3 finished with value: 0.7099145602959094 and parameters: {'class_weight_1_0': 1.8444068184363138, 'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 12, 'bootstrap': True}. Best is trial 1 with value: 0.7152944025016292.\n",
      "[I 2023-07-05 16:09:31,666] Trial 4 finished with value: 0.7052621275696951 and parameters: {'class_weight_1_0': 1.7177581998932885, 'n_estimators': 300, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 20, 'bootstrap': False}. Best is trial 1 with value: 0.7152944025016292.\n",
      "[I 2023-07-05 16:09:34,189] Trial 5 finished with value: 0.7169096945858995 and parameters: {'class_weight_1_0': 1.025982733308613, 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 4, 'bootstrap': False}. Best is trial 5 with value: 0.7169096945858995.\n",
      "[I 2023-07-05 16:10:07,435] Trial 6 finished with value: 0.7050439562420955 and parameters: {'class_weight_1_0': 1.1939523182692828, 'n_estimators': 300, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 24, 'bootstrap': False}. Best is trial 5 with value: 0.7169096945858995.\n",
      "[I 2023-07-05 16:10:47,701] Trial 7 finished with value: 0.6978154533301393 and parameters: {'class_weight_1_0': 1.767731688062067, 'n_estimators': 300, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 28, 'bootstrap': False}. Best is trial 5 with value: 0.7169096945858995.\n",
      "[I 2023-07-05 16:11:18,027] Trial 8 finished with value: 0.7040195555692932 and parameters: {'class_weight_1_0': 1.3981850470637043, 'n_estimators': 400, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 24, 'bootstrap': False}. Best is trial 5 with value: 0.7169096945858995.\n",
      "[I 2023-07-05 16:11:22,309] Trial 9 finished with value: 0.7137589606080978 and parameters: {'class_weight_1_0': 1.3498243734757036, 'n_estimators': 100, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 6, 'bootstrap': False}. Best is trial 5 with value: 0.7169096945858995.\n",
      "[I 2023-07-05 16:11:25,081] Trial 10 finished with value: 0.7153989804933711 and parameters: {'class_weight_1_0': 1.0173551478056015, 'n_estimators': 200, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 2, 'bootstrap': True}. Best is trial 5 with value: 0.7169096945858995.\n",
      "[I 2023-07-05 16:11:27,810] Trial 11 finished with value: 0.7157116841435552 and parameters: {'class_weight_1_0': 1.0076550607307464, 'n_estimators': 200, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 2, 'bootstrap': True}. Best is trial 5 with value: 0.7169096945858995.\n",
      "[I 2023-07-05 16:11:29,008] Trial 12 finished with value: 0.7156740772795297 and parameters: {'class_weight_1_0': 1.0199137976346258, 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 2, 'bootstrap': True}. Best is trial 5 with value: 0.7169096945858995.\n",
      "[I 2023-07-05 16:11:39,874] Trial 13 finished with value: 0.7150445486789945 and parameters: {'class_weight_1_0': 1.1351007957638088, 'n_estimators': 200, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 10, 'bootstrap': True}. Best is trial 5 with value: 0.7169096945858995.\n",
      "[I 2023-07-05 16:11:41,876] Trial 14 finished with value: 0.7162989694173769 and parameters: {'class_weight_1_0': 1.1875973317412953, 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 4, 'bootstrap': True}. Best is trial 5 with value: 0.7169096945858995.\n",
      "[I 2023-07-05 16:11:44,569] Trial 15 finished with value: 0.7157106538185134 and parameters: {'class_weight_1_0': 1.2282569191561472, 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5, 'max_features': 6, 'bootstrap': True}. Best is trial 5 with value: 0.7169096945858995.\n",
      "[I 2023-07-05 16:12:00,594] Trial 16 finished with value: 0.7139451918594019 and parameters: {'class_weight_1_0': 1.2877263714224714, 'n_estimators': 400, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 14, 'bootstrap': True}. Best is trial 5 with value: 0.7169096945858995.\n",
      "[I 2023-07-05 16:12:03,430] Trial 17 finished with value: 0.7142068944200172 and parameters: {'class_weight_1_0': 1.4644174609761842, 'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 6, 'bootstrap': False}. Best is trial 5 with value: 0.7169096945858995.\n",
      "[I 2023-07-05 16:12:07,608] Trial 18 finished with value: 0.7137726124149015 and parameters: {'class_weight_1_0': 1.1361986562275705, 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 10, 'bootstrap': True}. Best is trial 5 with value: 0.7169096945858995.\n",
      "[I 2023-07-05 16:12:14,414] Trial 19 finished with value: 0.7145942966357312 and parameters: {'class_weight_1_0': 1.3070707863468611, 'n_estimators': 200, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 4, 'bootstrap': False}. Best is trial 5 with value: 0.7169096945858995.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=15)\n",
    "best_params = study.best_params\n",
    "best_score = study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "40a5d101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best parameters are:  {'class_weight_1_0': 1.025982733308613, 'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 4, 'bootstrap': False}\n",
      "The best score is:  0.7169096945858995\n"
     ]
    }
   ],
   "source": [
    "print('the best parameters are: ', best_params)\n",
    "print('The best score is: ', best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cc0681",
   "metadata": {},
   "source": [
    "Past params:\n",
    "- the best parameters are:  {'n_estimators': 300, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 8, 'bootstrap': True, 'class_weight': {0: 2, 1: 1}}|The best score is:  0.709069436180379"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "aa649fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params['class_weight']={0:best_params['class_weight_1_0'], 1:1}\n",
    "del best_params['class_weight_1_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "12ba9d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy score is: 0.7394271272114574\n",
      "Test Accuracy score is: 0.7115902964959568\n",
      "ROCAUC score is: 0.7169096945858995\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.40      0.47       973\n",
      "           1       0.75      0.86      0.80      1995\n",
      "\n",
      "    accuracy                           0.71      2968\n",
      "   macro avg       0.67      0.63      0.64      2968\n",
      "weighted avg       0.69      0.71      0.69      2968\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(**best_params, random_state=2)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "evaluate_model(rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3839040",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d000df10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lgbm(clf):\n",
    "    y_hat = clf.predict(X_val)\n",
    "    y_hat_binary = (y_hat >= 0.5).astype(int)\n",
    "    train_hat = clf.predict(X_train)\n",
    "    train_hat_binary = (train_hat >= 0.5).astype(int)\n",
    "    train_acc = accuracy_score(y_train, train_hat_binary)\n",
    "    acc = accuracy_score(y_val, y_hat_binary)\n",
    "    roc = roc_auc_score(y_val, y_hat)\n",
    "    print(f'Train Accuracy score is: {train_acc}')\n",
    "    print(f'Test Accuracy score is: {acc}')\n",
    "    print(f'ROCAUC score is: {roc}')\n",
    "    print(classification_report(y_val, y_hat_binary))\n",
    "    plot_cm(y_hat_binary)\n",
    "    plot_roc_curve(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5059c250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    parameters = {\n",
    "        'num_leaves':trial.suggest_int('num_leaves', 10, 70, step=5),\n",
    "        'learning_rate':trial.suggest_loguniform('learning_rate', 0.001, 0.01),\n",
    "        'max_depth':trial.suggest_int('max_depth', 2, 10),\n",
    "        'min_data_in_leaf':trial.suggest_int('min_data_in_leaf', 1, 100, step=5),\n",
    "        'subsample':trial.suggest_float('subsample', 0.5, 1),\n",
    "        'feature_fraction':trial.suggest_uniform('feature_fraction', 0.5, 1),\n",
    "        'lambda_l1 ':trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'n_estimators ':trial.suggest_int('n_estimators ', 100, 1000, step=100),\n",
    "        'bagging_fraction ':trial.suggest_uniform('bagging_fraction ', 0.5,1),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        'class_weight': trial.suggest_uniform('class_weight', 1.0,2.0),\n",
    "    }\n",
    "#     class_weights = trial.suggest_categorical('class_weights', [np.array([2,1.0]), np.array([1.5,1.0])])\n",
    "#     train = lgb.Dataset(X_train, label=y_train, weight=class_weights[y_train])\n",
    "    train = lgb.Dataset(X_train, label=y_train)\n",
    "    val = lgb.Dataset(X_val, label=y_val)\n",
    "    \n",
    "#     model = LGBMClassifier(**parameters, random_state=2, objective='binary', metric='binary_logloss')\n",
    "    model = lgb.train(parameters, train, valid_sets=val, early_stopping_rounds=100, verbose_eval=False)\n",
    "\n",
    "#     model.fit(X_train, y_train)\n",
    "    y_hat = model.predict(X_val)\n",
    "#     pos_probs = model.predict_proba(X_val)[:,1]\n",
    "    score = roc_auc_score(y_val, y_hat)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ecf4314d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:16,654] A new study created in memory with name: no-name-82fb061e-b235-4f4b-a1a3-635d36737f93\n",
      "[I 2023-07-05 16:17:16,822] Trial 0 finished with value: 0.7098385738240772 and parameters: {'num_leaves': 50, 'learning_rate': 0.0018870353603277616, 'max_depth': 4, 'min_data_in_leaf': 11, 'subsample': 0.7696950644984244, 'feature_fraction': 0.6508834694086827, 'lambda_l1': 5.0888794388238665, 'lambda_l2': 0.1539290239095949, 'n_estimators ': 200, 'bagging_fraction ': 0.9606153170490511, 'bagging_freq': 1, 'class_weight': 1.1530426095929767}. Best is trial 0 with value: 0.7098385738240772.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 5.0888794388238665\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9606153170490511\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7696950644984244 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 5.0888794388238665\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9606153170490511\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7696950644984244 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 5.0888794388238665\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9606153170490511\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7696950644984244 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 3.041125711757915e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8248681941788604\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9748811984563951 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 3.041125711757915e-07"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:16,990] Trial 1 finished with value: 0.7010643257681717 and parameters: {'num_leaves': 10, 'learning_rate': 0.0012762133020178474, 'max_depth': 10, 'min_data_in_leaf': 66, 'subsample': 0.9748811984563951, 'feature_fraction': 0.915476269758129, 'lambda_l1': 3.041125711757915e-07, 'lambda_l2': 0.000437348979550915, 'n_estimators ': 200, 'bagging_fraction ': 0.8248681941788604, 'bagging_freq': 4, 'class_weight': 1.2306795671478987}. Best is trial 0 with value: 0.7098385738240772.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8248681941788604\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9748811984563951 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 3.041125711757915e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8248681941788604\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9748811984563951 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] Unknown parameter: 9.588791107857887e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8309188678880137\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9305119874818102 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 9.588791107857887e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8309188678880137\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9305119874818102 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 9.588791107857887e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8309188678880137\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9305119874818102 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:17,307] Trial 2 finished with value: 0.7076805580240426 and parameters: {'num_leaves': 55, 'learning_rate': 0.001347199742850943, 'max_depth': 7, 'min_data_in_leaf': 11, 'subsample': 0.9305119874818102, 'feature_fraction': 0.8568089222122766, 'lambda_l1': 9.588791107857887e-05, 'lambda_l2': 1.2174160485245022e-07, 'n_estimators ': 100, 'bagging_fraction ': 0.8309188678880137, 'bagging_freq': 6, 'class_weight': 1.3699835385920145}. Best is trial 0 with value: 0.7098385738240772.\n",
      "[I 2023-07-05 16:17:17,496] Trial 3 finished with value: 0.7043585325080429 and parameters: {'num_leaves': 15, 'learning_rate': 0.0013181731400743319, 'max_depth': 9, 'min_data_in_leaf': 36, 'subsample': 0.9273338214437341, 'feature_fraction': 0.9528823366539092, 'lambda_l1': 4.993965253029736e-05, 'lambda_l2': 0.00016418633122453706, 'n_estimators ': 400, 'bagging_fraction ': 0.929819980838798, 'bagging_freq': 7, 'class_weight': 1.6203146004501798}. Best is trial 0 with value: 0.7098385738240772.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 4.993965253029736e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.929819980838798\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9273338214437341 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 4.993965253029736e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.929819980838798\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9273338214437341 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 4.993965253029736e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.929819980838798\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9273338214437341 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:17,709] Trial 4 finished with value: 0.7129125485862653 and parameters: {'num_leaves': 65, 'learning_rate': 0.0027246762736836813, 'max_depth': 5, 'min_data_in_leaf': 41, 'subsample': 0.7978277625522336, 'feature_fraction': 0.6545329373078393, 'lambda_l1': 0.0020341309504584406, 'lambda_l2': 0.07145835616426267, 'n_estimators ': 100, 'bagging_fraction ': 0.658075817923703, 'bagging_freq': 5, 'class_weight': 1.726195326620224}. Best is trial 4 with value: 0.7129125485862653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.0020341309504584406\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.658075817923703\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7978277625522336 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0020341309504584406\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.658075817923703\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7978277625522336 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0020341309504584406\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.658075817923703\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7978277625522336 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 1.698397826274092\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5724007588865242\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9752470089045386 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.698397826274092\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5724007588865242\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9752470089045386 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 1.698397826274092\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5724007588865242\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9752470089045386 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:17,920] Trial 5 finished with value: 0.7139627073851124 and parameters: {'num_leaves': 25, 'learning_rate': 0.0014622766501973586, 'max_depth': 7, 'min_data_in_leaf': 86, 'subsample': 0.9752470089045386, 'feature_fraction': 0.6222824727204801, 'lambda_l1': 1.698397826274092, 'lambda_l2': 2.6344589136170686e-07, 'n_estimators ': 400, 'bagging_fraction ': 0.5724007588865242, 'bagging_freq': 7, 'class_weight': 1.4662225047908843}. Best is trial 5 with value: 0.7139627073851124.\n",
      "[I 2023-07-05 16:17:18,098] Trial 6 finished with value: 0.7132152065672919 and parameters: {'num_leaves': 15, 'learning_rate': 0.0040883563095445085, 'max_depth': 10, 'min_data_in_leaf': 76, 'subsample': 0.8656562385943094, 'feature_fraction': 0.5611720894306039, 'lambda_l1': 3.76724307733524e-05, 'lambda_l2': 0.7141003382097478, 'n_estimators ': 700, 'bagging_fraction ': 0.9637928952769743, 'bagging_freq': 5, 'class_weight': 1.6182799185561851}. Best is trial 5 with value: 0.7139627073851124.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 3.76724307733524e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9637928952769743\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8656562385943094 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 3.76724307733524e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9637928952769743\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8656562385943094 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 3.76724307733524e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9637928952769743\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8656562385943094 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] Unknown parameter: 0.01682537715070843\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7973355937992403\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8226369058393255 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.01682537715070843\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7973355937992403\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8226369058393255 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.01682537715070843\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7973355937992403\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8226369058393255 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:18,430] Trial 7 finished with value: 0.7089357515062065 and parameters: {'num_leaves': 50, 'learning_rate': 0.0020845896379998404, 'max_depth': 9, 'min_data_in_leaf': 96, 'subsample': 0.8226369058393255, 'feature_fraction': 0.9776988368130994, 'lambda_l1': 0.01682537715070843, 'lambda_l2': 3.803501414650883e-05, 'n_estimators ': 200, 'bagging_fraction ': 0.7973355937992403, 'bagging_freq': 5, 'class_weight': 1.640488993166785}. Best is trial 5 with value: 0.7139627073851124.\n",
      "[I 2023-07-05 16:17:18,557] Trial 8 finished with value: 0.7117554935643321 and parameters: {'num_leaves': 15, 'learning_rate': 0.001533552570383694, 'max_depth': 4, 'min_data_in_leaf': 46, 'subsample': 0.9448499330554294, 'feature_fraction': 0.5263098052267847, 'lambda_l1': 3.207986648791043e-05, 'lambda_l2': 1.3336992911743771e-08, 'n_estimators ': 500, 'bagging_fraction ': 0.8246531028938913, 'bagging_freq': 8, 'class_weight': 1.9565665924896802}. Best is trial 5 with value: 0.7139627073851124.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 3.207986648791043e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8246531028938913\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9448499330554294 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 3.207986648791043e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8246531028938913\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9448499330554294 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 3.207986648791043e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8246531028938913\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9448499330554294 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] Unknown parameter: 2.3518330284706857e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6800683737674726\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5966551200624631 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 2.3518330284706857e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6800683737674726\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5966551200624631 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 2.3518330284706857e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6800683737674726\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5966551200624631 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:18,762] Trial 9 finished with value: 0.7112418765309987 and parameters: {'num_leaves': 45, 'learning_rate': 0.007342546959161461, 'max_depth': 5, 'min_data_in_leaf': 91, 'subsample': 0.5966551200624631, 'feature_fraction': 0.7314165925048234, 'lambda_l1': 2.3518330284706857e-08, 'lambda_l2': 0.1361505278521004, 'n_estimators ': 600, 'bagging_fraction ': 0.6800683737674726, 'bagging_freq': 8, 'class_weight': 1.1310807506460359}. Best is trial 5 with value: 0.7139627073851124.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:18,939] Trial 10 finished with value: 0.6948700116169149 and parameters: {'num_leaves': 30, 'learning_rate': 0.0011326652379311905, 'max_depth': 2, 'min_data_in_leaf': 66, 'subsample': 0.7013201134619593, 'feature_fraction': 0.7998190042578475, 'lambda_l1': 7.1932030436246, 'lambda_l2': 8.008509365626976e-07, 'n_estimators ': 1000, 'bagging_fraction ': 0.532294994723135, 'bagging_freq': 10, 'class_weight': 1.4023738175993594}. Best is trial 5 with value: 0.7139627073851124.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 7.1932030436246\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: 0.532294994723135\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7013201134619593 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 7.1932030436246\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: 0.532294994723135\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7013201134619593 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 7.1932030436246\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: 0.532294994723135\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7013201134619593 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 0.05691929562638827\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9994410783957643\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8431613628929215 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:19,239] Trial 11 finished with value: 0.7141546054241461 and parameters: {'num_leaves': 30, 'learning_rate': 0.004187381418170811, 'max_depth': 7, 'min_data_in_leaf': 76, 'subsample': 0.8431613628929215, 'feature_fraction': 0.5360283157528055, 'lambda_l1': 0.05691929562638827, 'lambda_l2': 7.831113357940845, 'n_estimators ': 800, 'bagging_fraction ': 0.9994410783957643, 'bagging_freq': 3, 'class_weight': 1.5046147299878045}. Best is trial 11 with value: 0.7141546054241461.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.05691929562638827\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9994410783957643\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8431613628929215 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 0.05691929562638827\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9994410783957643\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8431613628929215 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:19,499] Trial 12 finished with value: 0.7155646052438392 and parameters: {'num_leaves': 30, 'learning_rate': 0.004091015480567871, 'max_depth': 7, 'min_data_in_leaf': 81, 'subsample': 0.8740028496273393, 'feature_fraction': 0.5024047280312942, 'lambda_l1': 0.1956781253270064, 'lambda_l2': 2.7012721275057507, 'n_estimators ': 800, 'bagging_fraction ': 0.5242328968596074, 'bagging_freq': 2, 'class_weight': 1.388281972987332}. Best is trial 12 with value: 0.7155646052438392.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.1956781253270064\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5242328968596074\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8740028496273393 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.1956781253270064\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5242328968596074\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8740028496273393 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001533 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.1956781253270064\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5242328968596074\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8740028496273393 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] Unknown parameter: 0.11562233150847577\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5013066202128171\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8502021797134117 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.11562233150847577\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5013066202128171\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8502021797134117 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.11562233150847577\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5013066202128171\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8502021797134117 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:19,821] Trial 13 finished with value: 0.7152289768614755 and parameters: {'num_leaves': 35, 'learning_rate': 0.004309017810284394, 'max_depth': 8, 'min_data_in_leaf': 61, 'subsample': 0.8502021797134117, 'feature_fraction': 0.500813832024637, 'lambda_l1': 0.11562233150847577, 'lambda_l2': 7.187167046999487, 'n_estimators ': 900, 'bagging_fraction ': 0.5013066202128171, 'bagging_freq': 2, 'class_weight': 1.2322419002851261}. Best is trial 12 with value: 0.7155646052438392.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.18354071460338514\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5073144707315813\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7250116067498846 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.18354071460338514\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5073144707315813\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7250116067498846 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.18354071460338514\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5073144707315813\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7250116067498846 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:20,111] Trial 14 finished with value: 0.7157763370399277 and parameters: {'num_leaves': 35, 'learning_rate': 0.00584739773566223, 'max_depth': 8, 'min_data_in_leaf': 61, 'subsample': 0.7250116067498846, 'feature_fraction': 0.5078002543905772, 'lambda_l1': 0.18354071460338514, 'lambda_l2': 8.955685726948005, 'n_estimators ': 1000, 'bagging_fraction ': 0.5073144707315813, 'bagging_freq': 1, 'class_weight': 1.0312676026775196}. Best is trial 14 with value: 0.7157763370399277.\n",
      "[I 2023-07-05 16:17:20,380] Trial 15 finished with value: 0.714756830411074 and parameters: {'num_leaves': 40, 'learning_rate': 0.0075413850183645844, 'max_depth': 6, 'min_data_in_leaf': 31, 'subsample': 0.7098156688260963, 'feature_fraction': 0.5626903478794645, 'lambda_l1': 0.24813506194159732, 'lambda_l2': 0.0053036313476812315, 'n_estimators ': 1000, 'bagging_fraction ': 0.5843630228663899, 'bagging_freq': 1, 'class_weight': 1.0363047848731344}. Best is trial 14 with value: 0.7157763370399277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.24813506194159732\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5843630228663899\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7098156688260963 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.24813506194159732\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5843630228663899\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7098156688260963 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.24813506194159732\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5843630228663899\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7098156688260963 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:20,629] Trial 16 finished with value: 0.7150731401989041 and parameters: {'num_leaves': 25, 'learning_rate': 0.009974928400044809, 'max_depth': 8, 'min_data_in_leaf': 56, 'subsample': 0.6381255795251063, 'feature_fraction': 0.598857255436249, 'lambda_l1': 0.006096824962951625, 'lambda_l2': 7.721521715050305, 'n_estimators ': 800, 'bagging_fraction ': 0.505414679354313, 'bagging_freq': 3, 'class_weight': 1.0415627634058269}. Best is trial 14 with value: 0.7157763370399277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 0.006096824962951625\n",
      "[LightGBM] [Warning] Unknown parameter: 0.505414679354313\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6381255795251063 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 0.006096824962951625\n",
      "[LightGBM] [Warning] Unknown parameter: 0.505414679354313\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6381255795251063 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 0.006096824962951625\n",
      "[LightGBM] [Warning] Unknown parameter: 0.505414679354313\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6381255795251063 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6129786534381291\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5341622059301556\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5045236632574674 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6129786534381291\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5341622059301556\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5045236632574674 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6129786534381291\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5341622059301556\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5045236632574674 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:20,979] Trial 17 finished with value: 0.7179541865970167 and parameters: {'num_leaves': 65, 'learning_rate': 0.005677456672153208, 'max_depth': 8, 'min_data_in_leaf': 81, 'subsample': 0.5045236632574674, 'feature_fraction': 0.5035167330280681, 'lambda_l1': 0.5341622059301556, 'lambda_l2': 0.011425810780509953, 'n_estimators ': 900, 'bagging_fraction ': 0.6129786534381291, 'bagging_freq': 2, 'class_weight': 1.0095999664050688}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8169950941241596\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6307012061956343\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5010228218564091 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8169950941241596\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6307012061956343\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5010228218564091 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8169950941241596\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6307012061956343\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5010228218564091 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:21,380] Trial 18 finished with value: 0.7146932078397432 and parameters: {'num_leaves': 70, 'learning_rate': 0.006197686875909023, 'max_depth': 9, 'min_data_in_leaf': 21, 'subsample': 0.5010228218564091, 'feature_fraction': 0.7033073170616184, 'lambda_l1': 0.8169950941241596, 'lambda_l2': 0.013733730431720116, 'n_estimators ': 1000, 'bagging_fraction ': 0.6307012061956343, 'bagging_freq': 1, 'class_weight': 1.131898239644561}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.0012410887515652694\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7134478186916122\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5194532778985428 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0012410887515652694\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7134478186916122\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5194532778985428 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0012410887515652694\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7134478186916122\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5194532778985428 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:21,719] Trial 19 finished with value: 0.7158319745921844 and parameters: {'num_leaves': 60, 'learning_rate': 0.005835164526416641, 'max_depth': 8, 'min_data_in_leaf': 51, 'subsample': 0.5194532778985428, 'feature_fraction': 0.5803136724021298, 'lambda_l1': 0.0012410887515652694, 'lambda_l2': 0.7893369681601653, 'n_estimators ': 900, 'bagging_fraction ': 0.7134478186916122, 'bagging_freq': 3, 'class_weight': 1.0099143230998575}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.0016465476809922766\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7154588227102563\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5121588688441703 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0016465476809922766\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7154588227102563\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5121588688441703 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001957 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0016465476809922766\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7154588227102563\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5121588688441703 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:22,020] Trial 20 finished with value: 0.7160668887017132 and parameters: {'num_leaves': 60, 'learning_rate': 0.003160238322572353, 'max_depth': 6, 'min_data_in_leaf': 51, 'subsample': 0.5121588688441703, 'feature_fraction': 0.5904511472716235, 'lambda_l1': 0.0016465476809922766, 'lambda_l2': 0.00616870370664486, 'n_estimators ': 700, 'bagging_fraction ': 0.7154588227102563, 'bagging_freq': 3, 'class_weight': 1.0070441865021664}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7226191354929534\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0011638773856395967\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5103954638858798 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7226191354929534\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0011638773856395967\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5103954638858798 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7226191354929534\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0011638773856395967\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5103954638858798 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:22,321] Trial 21 finished with value: 0.7158237319918501 and parameters: {'num_leaves': 60, 'learning_rate': 0.003106025207351727, 'max_depth': 6, 'min_data_in_leaf': 51, 'subsample': 0.5103954638858798, 'feature_fraction': 0.5804841873295518, 'lambda_l1': 0.0011638773856395967, 'lambda_l2': 0.006390304323771881, 'n_estimators ': 700, 'bagging_fraction ': 0.7226191354929534, 'bagging_freq': 3, 'class_weight': 1.0010640181295165}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:22,582] Trial 22 finished with value: 0.7133591944918823 and parameters: {'num_leaves': 70, 'learning_rate': 0.005456883872980919, 'max_depth': 5, 'min_data_in_leaf': 26, 'subsample': 0.5503743000710763, 'feature_fraction': 0.6020971842971232, 'lambda_l1': 0.0007549452202495906, 'lambda_l2': 0.851911273543866, 'n_estimators ': 900, 'bagging_fraction ': 0.7190290161466967, 'bagging_freq': 4, 'class_weight': 1.2411412451119073}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0007549452202495906\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7190290161466967\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5503743000710763 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0007549452202495906\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7190290161466967\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5503743000710763 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0007549452202495906\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7190290161466967\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5503743000710763 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.007746995300265876\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6279677359232972\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5520309264651738 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.007746995300265876\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6279677359232972\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5520309264651738 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.007746995300265876\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6279677359232972\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5520309264651738 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:22,962] Trial 23 finished with value: 0.7158945668384733 and parameters: {'num_leaves': 60, 'learning_rate': 0.00333976495823659, 'max_depth': 8, 'min_data_in_leaf': 46, 'subsample': 0.5520309264651738, 'feature_fraction': 0.5469788031485701, 'lambda_l1': 0.007746995300265876, 'lambda_l2': 0.03356975543361047, 'n_estimators ': 700, 'bagging_fraction ': 0.6279677359232972, 'bagging_freq': 2, 'class_weight': 1.0023301624060463}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.013752100073482746\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6199511459883125\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5560799130732541 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.013752100073482746\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6199511459883125\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5560799130732541 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.013752100073482746\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6199511459883125\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5560799130732541 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:23,295] Trial 24 finished with value: 0.7161624513493394 and parameters: {'num_leaves': 60, 'learning_rate': 0.0027970281057220748, 'max_depth': 6, 'min_data_in_leaf': 41, 'subsample': 0.5560799130732541, 'feature_fraction': 0.5539963997766465, 'lambda_l1': 0.013752100073482746, 'lambda_l2': 0.0018335834048971626, 'n_estimators ': 600, 'bagging_fraction ': 0.6199511459883125, 'bagging_freq': 2, 'class_weight': 1.1128810916743705}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.02416303952056167\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5993299591534624\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6045439013251135 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.02416303952056167\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5993299591534624\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6045439013251135 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.02416303952056167\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5993299591534624\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6045439013251135 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:23,506] Trial 25 finished with value: 0.7113634548859301 and parameters: {'num_leaves': 65, 'learning_rate': 0.0025979919544535457, 'max_depth': 4, 'min_data_in_leaf': 21, 'subsample': 0.6045439013251135, 'feature_fraction': 0.6274898179501545, 'lambda_l1': 0.02416303952056167, 'lambda_l2': 0.0024526081878031313, 'n_estimators ': 600, 'bagging_fraction ': 0.5993299591534624, 'bagging_freq': 2, 'class_weight': 1.1087622998577964}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.666869839147729\n",
      "[LightGBM] [Warning] Unknown parameter: 0.03451090908398424\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5541262955121257 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.666869839147729\n",
      "[LightGBM] [Warning] Unknown parameter: 0.03451090908398424\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5541262955121257 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.666869839147729\n",
      "[LightGBM] [Warning] Unknown parameter: 0.03451090908398424\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5541262955121257 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:23,843] Trial 26 finished with value: 0.7118618746248973 and parameters: {'num_leaves': 55, 'learning_rate': 0.002301899103346207, 'max_depth': 6, 'min_data_in_leaf': 1, 'subsample': 0.5541262955121257, 'feature_fraction': 0.6776069989508176, 'lambda_l1': 0.03451090908398424, 'lambda_l2': 0.001383110093160054, 'n_estimators ': 500, 'bagging_fraction ': 0.666869839147729, 'bagging_freq': 4, 'class_weight': 1.1904451473549431}. Best is trial 17 with value: 0.7179541865970167.\n",
      "[I 2023-07-05 16:17:24,009] Trial 27 finished with value: 0.7012585420385496 and parameters: {'num_leaves': 65, 'learning_rate': 0.0032306007340454045, 'max_depth': 2, 'min_data_in_leaf': 71, 'subsample': 0.6517943916895808, 'feature_fraction': 0.5566506395733284, 'lambda_l1': 1.146437820085138, 'lambda_l2': 0.022920410364747214, 'n_estimators ': 600, 'bagging_fraction ': 0.6324019935994056, 'bagging_freq': 2, 'class_weight': 1.1082615377735072}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 1.146437820085138\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6324019935994056\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6517943916895808 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.146437820085138\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6324019935994056\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6517943916895808 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 1.146437820085138\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6324019935994056\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6517943916895808 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0062130066389217975\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7659160929257045\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5003880591127738 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0062130066389217975"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:24,195] Trial 28 finished with value: 0.7069626790511736 and parameters: {'num_leaves': 50, 'learning_rate': 0.0018834538489634913, 'max_depth': 3, 'min_data_in_leaf': 36, 'subsample': 0.5003880591127738, 'feature_fraction': 0.6101820252221157, 'lambda_l1': 0.0062130066389217975, 'lambda_l2': 0.0008620260652410293, 'n_estimators ': 400, 'bagging_fraction ': 0.7659160929257045, 'bagging_freq': 4, 'class_weight': 1.2939467005364174}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7659160929257045\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5003880591127738 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0062130066389217975\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7659160929257045\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5003880591127738 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] Unknown parameter: 5.671378386018402\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5636824093087913\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5813148972383172 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 5.671378386018402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:24,454] Trial 29 finished with value: 0.7120089535246132 and parameters: {'num_leaves': 55, 'learning_rate': 0.0017202738300169586, 'max_depth': 5, 'min_data_in_leaf': 11, 'subsample': 0.5813148972383172, 'feature_fraction': 0.6532143571114593, 'lambda_l1': 5.671378386018402, 'lambda_l2': 0.009744865079246504, 'n_estimators ': 700, 'bagging_fraction ': 0.5636824093087913, 'bagging_freq': 1, 'class_weight': 1.0928090849483847}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5636824093087913\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5813148972383172 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 5.671378386018402\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5636824093087913\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5813148972383172 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7782531502541234\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6853407946445964\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5372872376089778 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7782531502541234\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6853407946445964\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5372872376089778 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7782531502541234\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6853407946445964\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5372872376089778 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:24,769] Trial 30 finished with value: 0.7155239074046886 and parameters: {'num_leaves': 45, 'learning_rate': 0.0022369574808204055, 'max_depth': 6, 'min_data_in_leaf': 56, 'subsample': 0.5372872376089778, 'feature_fraction': 0.5447847144536251, 'lambda_l1': 0.7782531502541234, 'lambda_l2': 0.00012559738936663333, 'n_estimators ': 800, 'bagging_fraction ': 0.6853407946445964, 'bagging_freq': 3, 'class_weight': 1.17631027743295}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.004051689861695146\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.619755182215964\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5633530433622281 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.004051689861695146\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.619755182215964\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5633530433622281 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.004051689861695146\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.619755182215964\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5633530433622281 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:25,214] Trial 31 finished with value: 0.716288666166959 and parameters: {'num_leaves': 60, 'learning_rate': 0.0032544198518815056, 'max_depth': 7, 'min_data_in_leaf': 41, 'subsample': 0.5633530433622281, 'feature_fraction': 0.5396413099338131, 'lambda_l1': 0.004051689861695146, 'lambda_l2': 0.028185834928337688, 'n_estimators ': 700, 'bagging_fraction ': 0.619755182215964, 'bagging_freq': 2, 'class_weight': 1.0929450072434352}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.004205088555474396\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6025719510808414\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5722216245946711 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.004205088555474396\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6025719510808414\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5722216245946711 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.004205088555474396\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6025719510808414\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5722216245946711 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:25,670] Trial 32 finished with value: 0.7168924366414494 and parameters: {'num_leaves': 70, 'learning_rate': 0.003651444371479, 'max_depth': 7, 'min_data_in_leaf': 41, 'subsample': 0.5722216245946711, 'feature_fraction': 0.5338158391355534, 'lambda_l1': 0.004205088555474396, 'lambda_l2': 0.1206395259340072, 'n_estimators ': 500, 'bagging_fraction ': 0.6025719510808414, 'bagging_freq': 2, 'class_weight': 1.0743407551607722}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.04065317779277999\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5994703213783275\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5709876127410054 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.04065317779277999\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5994703213783275\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5709876127410054 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.04065317779277999\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5994703213783275\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5709876127410054 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:26,091] Trial 33 finished with value: 0.7169503924250502 and parameters: {'num_leaves': 70, 'learning_rate': 0.003664116357328942, 'max_depth': 7, 'min_data_in_leaf': 41, 'subsample': 0.5709876127410054, 'feature_fraction': 0.5281009982800364, 'lambda_l1': 0.04065317779277999, 'lambda_l2': 0.06746019265259363, 'n_estimators ': 500, 'bagging_fraction ': 0.5994703213783275, 'bagging_freq': 2, 'class_weight': 1.0818010608134723}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0001998377306639751\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5532608428873937\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6217660169582336 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0001998377306639751\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5532608428873937\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6217660169582336 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0001998377306639751\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5532608428873937\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6217660169582336 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:26,472] Trial 34 finished with value: 0.7159970841801317 and parameters: {'num_leaves': 70, 'learning_rate': 0.0047473167149894736, 'max_depth': 7, 'min_data_in_leaf': 31, 'subsample': 0.6217660169582336, 'feature_fraction': 0.5263286754501137, 'lambda_l1': 0.0001998377306639751, 'lambda_l2': 0.1670631099476521, 'n_estimators ': 300, 'bagging_fraction ': 0.5532608428873937, 'bagging_freq': 1, 'class_weight': 1.1980736807711743}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.06222093201247039\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6044053694321085\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6630023998343781 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.06222093201247039\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6044053694321085\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6630023998343781 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.06222093201247039\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6044053694321085\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6630023998343781 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:26,831] Trial 35 finished with value: 0.7169287555991727 and parameters: {'num_leaves': 70, 'learning_rate': 0.0036818858345467292, 'max_depth': 7, 'min_data_in_leaf': 41, 'subsample': 0.6630023998343781, 'feature_fraction': 0.5004113675441291, 'lambda_l1': 0.06222093201247039, 'lambda_l2': 0.050030571693433966, 'n_estimators ': 500, 'bagging_fraction ': 0.6044053694321085, 'bagging_freq': 2, 'class_weight': 1.2942915989014006}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.07218373110498146\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5921439902081278\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6687873583065844 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.07218373110498146\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5921439902081278\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6687873583065844 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.07218373110498146\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5921439902081278\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6687873583065844 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:27,474] Trial 36 finished with value: 0.7162652262722583 and parameters: {'num_leaves': 70, 'learning_rate': 0.0036228979468318737, 'max_depth': 9, 'min_data_in_leaf': 36, 'subsample': 0.6687873583065844, 'feature_fraction': 0.5023633044995663, 'lambda_l1': 0.07218373110498146, 'lambda_l2': 0.0881171870124469, 'n_estimators ': 500, 'bagging_fraction ': 0.5921439902081278, 'bagging_freq': 6, 'class_weight': 1.304778054233911}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.43346277545292056\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5556339554094807\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5844859771892433 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.43346277545292056\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5556339554094807\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5844859771892433 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.43346277545292056\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5556339554094807\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5844859771892433 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:27,876] Trial 37 finished with value: 0.715598863551479 and parameters: {'num_leaves': 65, 'learning_rate': 0.004864586681330396, 'max_depth': 9, 'min_data_in_leaf': 26, 'subsample': 0.5844859771892433, 'feature_fraction': 0.6348377737585984, 'lambda_l1': 0.43346277545292056, 'lambda_l2': 0.24682835211100052, 'n_estimators ': 300, 'bagging_fraction ': 0.5556339554094807, 'bagging_freq': 4, 'class_weight': 1.1623898238935628}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 1.9080473475397677\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6573382368703227\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6197988930811102 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.9080473475397677\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6573382368703227\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6197988930811102 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 1.9080473475397677\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6573382368703227\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6197988930811102 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:28,258] Trial 38 finished with value: 0.7168094954755853 and parameters: {'num_leaves': 70, 'learning_rate': 0.0036583981981379806, 'max_depth': 8, 'min_data_in_leaf': 41, 'subsample': 0.6197988930811102, 'feature_fraction': 0.5712018568876587, 'lambda_l1': 1.9080473475397677, 'lambda_l2': 0.055220838580655615, 'n_estimators ': 400, 'bagging_fraction ': 0.6573382368703227, 'bagging_freq': 1, 'class_weight': 1.0713499975920246}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.07517067994683453\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5924580629701154\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5781926870283695 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.07517067994683453\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5924580629701154\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5781926870283695 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.07517067994683453\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5924580629701154\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5781926870283695 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:28,596] Trial 39 finished with value: 0.7156988050805327 and parameters: {'num_leaves': 65, 'learning_rate': 0.003714659347846093, 'max_depth': 7, 'min_data_in_leaf': 21, 'subsample': 0.5781926870283695, 'feature_fraction': 0.5217957140136882, 'lambda_l1': 0.07517067994683453, 'lambda_l2': 0.2108495231373663, 'n_estimators ': 300, 'bagging_fraction ': 0.5924580629701154, 'bagging_freq': 10, 'class_weight': 1.0633130412904124}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.032628989293905716\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5439183838274202\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5342312003732546 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.032628989293905716\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5439183838274202\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5342312003732546 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.032628989293905716\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5439183838274202\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5342312003732546 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:28,962] Trial 40 finished with value: 0.7157678368583329 and parameters: {'num_leaves': 70, 'learning_rate': 0.004835394483706728, 'max_depth': 7, 'min_data_in_leaf': 31, 'subsample': 0.5342312003732546, 'feature_fraction': 0.5269821305673253, 'lambda_l1': 0.032628989293905716, 'lambda_l2': 0.04686100881351783, 'n_estimators ': 500, 'bagging_fraction ': 0.5439183838274202, 'bagging_freq': 6, 'class_weight': 1.157400774436557}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 2.0876052783786543\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6577556649040929\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6011851718947236 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 2.0876052783786543\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6577556649040929\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6011851718947236 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000978 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 2.0876052783786543\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6577556649040929\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6011851718947236 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:29,400] Trial 41 finished with value: 0.7167244936596373 and parameters: {'num_leaves': 70, 'learning_rate': 0.0038282594099603873, 'max_depth': 8, 'min_data_in_leaf': 41, 'subsample': 0.6011851718947236, 'feature_fraction': 0.5716423997269696, 'lambda_l1': 2.0876052783786543, 'lambda_l2': 0.056547005297885825, 'n_estimators ': 400, 'bagging_fraction ': 0.6577556649040929, 'bagging_freq': 1, 'class_weight': 1.066157837222906}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 2.8639299364954875\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5657111543609448\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6217096072152642 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 2.8639299364954875\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5657111543609448\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6217096072152642 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 2.8639299364954875\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5657111543609448\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6217096072152642 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:29,784] Trial 42 finished with value: 0.7160980560342274 and parameters: {'num_leaves': 65, 'learning_rate': 0.0035466907098238654, 'max_depth': 10, 'min_data_in_leaf': 46, 'subsample': 0.6217096072152642, 'feature_fraction': 0.5762115223595059, 'lambda_l1': 2.8639299364954875, 'lambda_l2': 0.015304272487154527, 'n_estimators ': 400, 'bagging_fraction ': 0.5657111543609448, 'bagging_freq': 1, 'class_weight': 1.070367214151438}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.4513063483295722\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.603560266748336\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6753034212537502 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.4513063483295722\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.603560266748336\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6753034212537502 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.4513063483295722\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.603560266748336\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6753034212537502 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:30,140] Trial 43 finished with value: 0.7168568904275077 and parameters: {'num_leaves': 65, 'learning_rate': 0.004456983458774513, 'max_depth': 8, 'min_data_in_leaf': 56, 'subsample': 0.6753034212537502, 'feature_fraction': 0.5207479663257317, 'lambda_l1': 0.4513063483295722, 'lambda_l2': 0.46109361087036355, 'n_estimators ': 500, 'bagging_fraction ': 0.603560266748336, 'bagging_freq': 2, 'class_weight': 1.1527432240490554}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.45800985033608926\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6040947669575663\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6715681631875584 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.45800985033608926\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6040947669575663\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6715681631875584 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.45800985033608926\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6040947669575663\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6715681631875584 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:30,465] Trial 44 finished with value: 0.717639422296749 and parameters: {'num_leaves': 55, 'learning_rate': 0.004443886769348388, 'max_depth': 7, 'min_data_in_leaf': 96, 'subsample': 0.6715681631875584, 'feature_fraction': 0.5226969346372794, 'lambda_l1': 0.45800985033608926, 'lambda_l2': 0.38204740445188384, 'n_estimators ': 500, 'bagging_fraction ': 0.6040947669575663, 'bagging_freq': 2, 'class_weight': 1.1476547919190083}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.10446357347353269\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5770507983578421\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7822617125481544 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.10446357347353269\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5770507983578421\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7822617125481544 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.10446357347353269\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5770507983578421\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7822617125481544 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:30,846] Trial 45 finished with value: 0.717503161809972 and parameters: {'num_leaves': 55, 'learning_rate': 0.0040386971522944955, 'max_depth': 7, 'min_data_in_leaf': 96, 'subsample': 0.7822617125481544, 'feature_fraction': 0.5368139720189604, 'lambda_l1': 0.10446357347353269, 'lambda_l2': 1.4644819480389246, 'n_estimators ': 500, 'bagging_fraction ': 0.5770507983578421, 'bagging_freq': 3, 'class_weight': 1.226645009208849}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.12970089412367622\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5352281470970298\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7799440781499469 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.12970089412367622\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5352281470970298\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7799440781499469 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.12970089412367622\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5352281470970298\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7799440781499469 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:31,203] Trial 46 finished with value: 0.7160558127075138 and parameters: {'num_leaves': 50, 'learning_rate': 0.004179705555890208, 'max_depth': 7, 'min_data_in_leaf': 96, 'subsample': 0.7799440781499469, 'feature_fraction': 0.6148135670825914, 'lambda_l1': 0.12970089412367622, 'lambda_l2': 2.0556769229619354, 'n_estimators ': 600, 'bagging_fraction ': 0.5352281470970298, 'bagging_freq': 3, 'class_weight': 1.2643856489195087}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.3075498557654505\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5864465081851652\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7439670150275884 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.3075498557654505\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5864465081851652\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7439670150275884 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.3075498557654505\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5864465081851652\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7439670150275884 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:31,566] Trial 47 finished with value: 0.7163808802581995 and parameters: {'num_leaves': 55, 'learning_rate': 0.005181780129759929, 'max_depth': 6, 'min_data_in_leaf': 86, 'subsample': 0.7439670150275884, 'feature_fraction': 0.5043111281601808, 'lambda_l1': 0.3075498557654505, 'lambda_l2': 0.36246204746678584, 'n_estimators ': 400, 'bagging_fraction ': 0.5864465081851652, 'bagging_freq': 5, 'class_weight': 1.209125160271403}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 6.794535945273589\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5609340313313764\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.752773008824542 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 6.794535945273589\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5609340313313764\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.752773008824542 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 6.794535945273589\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5609340313313764\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.752773008824542 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:31,962] Trial 48 finished with value: 0.7161567845616096 and parameters: {'num_leaves': 45, 'learning_rate': 0.004431913446658575, 'max_depth': 9, 'min_data_in_leaf': 91, 'subsample': 0.752773008824542, 'feature_fraction': 0.5460945524241666, 'lambda_l1': 6.794535945273589, 'lambda_l2': 1.6381883998954878, 'n_estimators ': 200, 'bagging_fraction ': 0.5609340313313764, 'bagging_freq': 4, 'class_weight': 1.332549827885743}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.0570687323684706\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5251964325816112\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6860711923931115 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0570687323684706\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5251964325816112\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6860711923931115 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0570687323684706\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5251964325816112\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6860711923931115 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:32,255] Trial 49 finished with value: 0.7136502613161887 and parameters: {'num_leaves': 55, 'learning_rate': 0.00395035148245252, 'max_depth': 5, 'min_data_in_leaf': 91, 'subsample': 0.6860711923931115, 'feature_fraction': 0.5967055793019449, 'lambda_l1': 0.0570687323684706, 'lambda_l2': 0.6500825990348419, 'n_estimators ': 100, 'bagging_fraction ': 0.5251964325816112, 'bagging_freq': 3, 'class_weight': 1.2325758222475085}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.16282891165564758\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5751521486923417\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7307062959103391 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.16282891165564758\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5751521486923417\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7307062959103391 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.16282891165564758\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5751521486923417\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7307062959103391 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:32,666] Trial 50 finished with value: 0.7167332514224924 and parameters: {'num_leaves': 50, 'learning_rate': 0.002865212711010797, 'max_depth': 7, 'min_data_in_leaf': 81, 'subsample': 0.7307062959103391, 'feature_fraction': 0.5598265836647669, 'lambda_l1': 0.16282891165564758, 'lambda_l2': 0.26171623846698183, 'n_estimators ': 600, 'bagging_fraction ': 0.5751521486923417, 'bagging_freq': 2, 'class_weight': 1.2658411951430786}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 0.012259136352947127\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6069966038057727\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6443922019590702 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 0.012259136352947127\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6069966038057727\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6443922019590702 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 0.012259136352947127\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6069966038057727\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6443922019590702 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:33,105] Trial 51 finished with value: 0.7176492103846461 and parameters: {'num_leaves': 65, 'learning_rate': 0.00384083611483747, 'max_depth': 7, 'min_data_in_leaf': 96, 'subsample': 0.6443922019590702, 'feature_fraction': 0.5247254650035814, 'lambda_l1': 0.012259136352947127, 'lambda_l2': 0.10667464722073351, 'n_estimators ': 500, 'bagging_fraction ': 0.6069966038057727, 'bagging_freq': 2, 'class_weight': 1.138628354805237}. Best is trial 17 with value: 0.7179541865970167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.022935869911630262\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.644572413808908\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6522482429562402 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.022935869911630262\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.644572413808908\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6522482429562402 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001948 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.022935869911630262\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.644572413808908\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6522482429562402 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:33,490] Trial 52 finished with value: 0.7181834339188156 and parameters: {'num_leaves': 65, 'learning_rate': 0.0040760042099819566, 'max_depth': 8, 'min_data_in_leaf': 96, 'subsample': 0.6522482429562402, 'feature_fraction': 0.5032349354332954, 'lambda_l1': 0.022935869911630262, 'lambda_l2': 0.0855341785528155, 'n_estimators ': 500, 'bagging_fraction ': 0.644572413808908, 'bagging_freq': 3, 'class_weight': 1.1421447353258156}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.017007857873231905"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:33,704] Trial 53 finished with value: 0.7111576474588321 and parameters: {'num_leaves': 10, 'learning_rate': 0.004490843083047735, 'max_depth': 8, 'min_data_in_leaf': 96, 'subsample': 0.6891622748356007, 'feature_fraction': 0.521126576527131, 'lambda_l1': 0.017007857873231905, 'lambda_l2': 0.13470452714528572, 'n_estimators ': 300, 'bagging_fraction ': 0.6444347672147361, 'bagging_freq': 3, 'class_weight': 1.1508325434978344}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6444347672147361\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6891622748356007 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.017007857873231905\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6444347672147361\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6891622748356007 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.017007857873231905\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6444347672147361\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6891622748356007 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] Unknown parameter: 0.33240977481618816\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5738242395377642\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6465989377806954 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.33240977481618816\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5738242395377642\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6465989377806954 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.33240977481618816\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5738242395377642\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6465989377806954 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:34,097] Trial 54 finished with value: 0.7180742194643854 and parameters: {'num_leaves': 65, 'learning_rate': 0.004178916704499568, 'max_depth': 9, 'min_data_in_leaf': 86, 'subsample': 0.6465989377806954, 'feature_fraction': 0.5183770330232336, 'lambda_l1': 0.33240977481618816, 'lambda_l2': 1.3112714028623922, 'n_estimators ': 500, 'bagging_fraction ': 0.5738242395377642, 'bagging_freq': 3, 'class_weight': 1.2069400510479014}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.9082025488643861\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5732213906269107\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7106886418522869 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9082025488643861\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5732213906269107\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7106886418522869 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9082025488643861\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5732213906269107\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7106886418522869 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:34,452] Trial 55 finished with value: 0.716790434462312 and parameters: {'num_leaves': 55, 'learning_rate': 0.004125893810161553, 'max_depth': 10, 'min_data_in_leaf': 86, 'subsample': 0.7106886418522869, 'feature_fraction': 0.5592091038487277, 'lambda_l1': 0.9082025488643861, 'lambda_l2': 2.483084226756567, 'n_estimators ': 400, 'bagging_fraction ': 0.5732213906269107, 'bagging_freq': 5, 'class_weight': 1.2104691009658604}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.4127504397806259\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6421219157046115\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6382911291125383 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.4127504397806259\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6421219157046115\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6382911291125383 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.4127504397806259\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6421219157046115\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6382911291125383 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:34,930] Trial 56 finished with value: 0.7164460483170929 and parameters: {'num_leaves': 60, 'learning_rate': 0.00510634915978754, 'max_depth': 9, 'min_data_in_leaf': 86, 'subsample': 0.6382911291125383, 'feature_fraction': 0.5878608180948047, 'lambda_l1': 0.4127504397806259, 'lambda_l2': 1.3428846111381572, 'n_estimators ': 600, 'bagging_fraction ': 0.6421219157046115, 'bagging_freq': 4, 'class_weight': 1.1388805741911165}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.1443510015256756\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6183266825370364\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7027259676393344 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.1443510015256756\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6183266825370364\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7027259676393344 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.1443510015256756\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6183266825370364\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7027259676393344 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:35,253] Trial 57 finished with value: 0.7165678842532848 and parameters: {'num_leaves': 40, 'learning_rate': 0.005322975539021993, 'max_depth': 8, 'min_data_in_leaf': 81, 'subsample': 0.7027259676393344, 'feature_fraction': 0.5151413294965561, 'lambda_l1': 0.1443510015256756, 'lambda_l2': 4.016604373998004, 'n_estimators ': 500, 'bagging_fraction ': 0.6183266825370364, 'bagging_freq': 3, 'class_weight': 1.1295706468190598}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 3.3293850232815254\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5482000893559239\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6497170144543388 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 3.3293850232815254\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5482000893559239\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6497170144543388 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 3.3293850232815254\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5482000893559239\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6497170144543388 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:35,675] Trial 58 finished with value: 0.7161572997241304 and parameters: {'num_leaves': 60, 'learning_rate': 0.004572341911542646, 'max_depth': 10, 'min_data_in_leaf': 91, 'subsample': 0.6497170144543388, 'feature_fraction': 0.5451016268442845, 'lambda_l1': 3.3293850232815254, 'lambda_l2': 0.47387551425119656, 'n_estimators ': 600, 'bagging_fraction ': 0.5482000893559239, 'bagging_freq': 3, 'class_weight': 1.0457691298202205}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.01685486916366137\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5780772853853399\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7995253181779902 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.01685486916366137\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5780772853853399\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7995253181779902 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.01685486916366137\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5780772853853399\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7995253181779902 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:36,063] Trial 59 finished with value: 0.7178593966931718 and parameters: {'num_leaves': 65, 'learning_rate': 0.004038974774069679, 'max_depth': 8, 'min_data_in_leaf': 76, 'subsample': 0.7995253181779902, 'feature_fraction': 0.5000964369275385, 'lambda_l1': 0.01685486916366137, 'lambda_l2': 1.0615834812376017, 'n_estimators ': 400, 'bagging_fraction ': 0.5780772853853399, 'bagging_freq': 7, 'class_weight': 1.1858881525167688}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.012184939210667586\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6145282433566672\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8021791862182164 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.012184939210667586\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6145282433566672\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8021791862182164 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.012184939210667586\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6145282433566672\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8021791862182164 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:36,440] Trial 60 finished with value: 0.7179289436334928 and parameters: {'num_leaves': 65, 'learning_rate': 0.006214025871568748, 'max_depth': 8, 'min_data_in_leaf': 76, 'subsample': 0.8021791862182164, 'feature_fraction': 0.5095203953221061, 'lambda_l1': 0.012184939210667586, 'lambda_l2': 0.5659105144399548, 'n_estimators ': 400, 'bagging_fraction ': 0.6145282433566672, 'bagging_freq': 8, 'class_weight': 1.1827591127750636}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.012435374039053053\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6170489638612001\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7692447536188399 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.012435374039053053\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6170489638612001\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7692447536188399 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000605 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.012435374039053053\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6170489638612001\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7692447536188399 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:36,908] Trial 61 finished with value: 0.7178166382039373 and parameters: {'num_leaves': 65, 'learning_rate': 0.00630179698427855, 'max_depth': 8, 'min_data_in_leaf': 76, 'subsample': 0.7692447536188399, 'feature_fraction': 0.5133675075642355, 'lambda_l1': 0.012435374039053053, 'lambda_l2': 0.567939355067338, 'n_estimators ': 400, 'bagging_fraction ': 0.6170489638612001, 'bagging_freq': 8, 'class_weight': 1.196296857004389}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6181498653168578\n",
      "[LightGBM] [Warning] Unknown parameter: 0.011201914964185409\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8271484364965632 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6181498653168578\n",
      "[LightGBM] [Warning] Unknown parameter: 0.011201914964185409\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8271484364965632 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6181498653168578\n",
      "[LightGBM] [Warning] Unknown parameter: 0.011201914964185409\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8271484364965632 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:37,387] Trial 62 finished with value: 0.716551399052616 and parameters: {'num_leaves': 65, 'learning_rate': 0.006510411285315947, 'max_depth': 9, 'min_data_in_leaf': 71, 'subsample': 0.8271484364965632, 'feature_fraction': 0.5017534393006586, 'lambda_l1': 0.011201914964185409, 'lambda_l2': 3.880269356484574, 'n_estimators ': 300, 'bagging_fraction ': 0.6181498653168578, 'bagging_freq': 8, 'class_weight': 1.1784271735425254}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.0030190118437091957\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6445435555298319\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7608616878603847 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0030190118437091957\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6445435555298319\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7608616878603847 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0030190118437091957\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6445435555298319\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7608616878603847 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:37,942] Trial 63 finished with value: 0.7178233353167089 and parameters: {'num_leaves': 65, 'learning_rate': 0.005656488042829986, 'max_depth': 8, 'min_data_in_leaf': 76, 'subsample': 0.7608616878603847, 'feature_fraction': 0.5183687553242118, 'lambda_l1': 0.0030190118437091957, 'lambda_l2': 1.1147129887941432, 'n_estimators ': 400, 'bagging_fraction ': 0.6445435555298319, 'bagging_freq': 7, 'class_weight': 1.193774604644985}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0029404127094712507\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6416176436484895\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8006883742169477 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0029404127094712507\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6416176436484895\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8006883742169477 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0029404127094712507\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6416176436484895\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8006883742169477 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:38,443] Trial 64 finished with value: 0.7158917334446084 and parameters: {'num_leaves': 65, 'learning_rate': 0.00573073978050354, 'max_depth': 9, 'min_data_in_leaf': 76, 'subsample': 0.8006883742169477, 'feature_fraction': 0.5643259088882605, 'lambda_l1': 0.0029404127094712507, 'lambda_l2': 1.0662430093275355, 'n_estimators ': 400, 'bagging_fraction ': 0.6416176436484895, 'bagging_freq': 7, 'class_weight': 1.1976280103134123}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.021937281798806423\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6652294232499453\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8045159455274733 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.021937281798806423\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6652294232499453\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8045159455274733 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.021937281798806423\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6652294232499453\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8045159455274733 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:39,051] Trial 65 finished with value: 0.7170608947857826 and parameters: {'num_leaves': 60, 'learning_rate': 0.006441542534544874, 'max_depth': 8, 'min_data_in_leaf': 71, 'subsample': 0.8045159455274733, 'feature_fraction': 0.5124734691705007, 'lambda_l1': 0.021937281798806423, 'lambda_l2': 0.698068661760931, 'n_estimators ': 400, 'bagging_fraction ': 0.6652294232499453, 'bagging_freq': 9, 'class_weight': 1.2530785751751454}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0026950965965290177\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6844824869197876\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7666859393559977 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0026950965965290177\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6844824869197876\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7666859393559977 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0026950965965290177\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6844824869197876\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7666859393559977 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:39,470] Trial 66 finished with value: 0.717863002830818 and parameters: {'num_leaves': 65, 'learning_rate': 0.00706056686745677, 'max_depth': 8, 'min_data_in_leaf': 76, 'subsample': 0.7666859393559977, 'feature_fraction': 0.5439227476373708, 'lambda_l1': 0.0026950965965290177, 'lambda_l2': 5.833580734471931, 'n_estimators ': 300, 'bagging_fraction ': 0.6844824869197876, 'bagging_freq': 7, 'class_weight': 1.3687543810217269}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.0008699237408949125\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6773347854498522\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7577986606412489 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0008699237408949125\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6773347854498522\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7577986606412489 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0008699237408949125\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6773347854498522\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7577986606412489 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:40,016] Trial 67 finished with value: 0.7162149979264708 and parameters: {'num_leaves': 60, 'learning_rate': 0.006957562574870845, 'max_depth': 9, 'min_data_in_leaf': 66, 'subsample': 0.7577986606412489, 'feature_fraction': 0.5508399745238707, 'lambda_l1': 0.0008699237408949125, 'lambda_l2': 5.74706370289263, 'n_estimators ': 300, 'bagging_fraction ': 0.6773347854498522, 'bagging_freq': 7, 'class_weight': 1.346090557702542}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.0020092759190983582\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.697532953339215\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7293387681577571 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0020092759190983582\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.697532953339215\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7293387681577571 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0020092759190983582\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.697532953339215\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7293387681577571 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:40,457] Trial 68 finished with value: 0.7173210518588353 and parameters: {'num_leaves': 65, 'learning_rate': 0.008073391527660807, 'max_depth': 8, 'min_data_in_leaf': 81, 'subsample': 0.7293387681577571, 'feature_fraction': 0.5401447076481204, 'lambda_l1': 0.0020092759190983582, 'lambda_l2': 8.482772185128518, 'n_estimators ': 200, 'bagging_fraction ': 0.697532953339215, 'bagging_freq': 7, 'class_weight': 1.3893596089240545}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0005739486137782869\n",
      "[LightGBM] [Warning] Unknown parameter: 0.63898086136972\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7414083639706124 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0005739486137782869\n",
      "[LightGBM] [Warning] Unknown parameter: 0.63898086136972\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7414083639706124 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0005739486137782869\n",
      "[LightGBM] [Warning] Unknown parameter: 0.63898086136972\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7414083639706124 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:40,843] Trial 69 finished with value: 0.716512761863549 and parameters: {'num_leaves': 60, 'learning_rate': 0.005088015939374037, 'max_depth': 8, 'min_data_in_leaf': 66, 'subsample': 0.7414083639706124, 'feature_fraction': 0.5010866544866059, 'lambda_l1': 0.0005739486137782869, 'lambda_l2': 3.3467043551949516, 'n_estimators ': 200, 'bagging_fraction ': 0.63898086136972, 'bagging_freq': 6, 'class_weight': 1.111045340295693}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0030095729971906567\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6520308478668586\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7712122399400864 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0030095729971906567\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6520308478668586\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7712122399400864 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002500 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0030095729971906567\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6520308478668586\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7712122399400864 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:41,358] Trial 70 finished with value: 0.7164589273801153 and parameters: {'num_leaves': 65, 'learning_rate': 0.005602482084267638, 'max_depth': 9, 'min_data_in_leaf': 76, 'subsample': 0.7712122399400864, 'feature_fraction': 0.578767016227129, 'lambda_l1': 0.0030095729971906567, 'lambda_l2': 1.2433277131265408, 'n_estimators ': 300, 'bagging_fraction ': 0.6520308478668586, 'bagging_freq': 9, 'class_weight': 1.4243328276960197}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.007105325878629964\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6202767572098553\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7903868837693433 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.007105325878629964\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6202767572098553\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7903868837693433 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.007105325878629964\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6202767572098553\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7903868837693433 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:41,835] Trial 71 finished with value: 0.7171072594126633 and parameters: {'num_leaves': 60, 'learning_rate': 0.006094608217060041, 'max_depth': 8, 'min_data_in_leaf': 76, 'subsample': 0.7903868837693433, 'feature_fraction': 0.514387458581153, 'lambda_l1': 0.007105325878629964, 'lambda_l2': 2.584161462019048, 'n_estimators ': 400, 'bagging_fraction ': 0.6202767572098553, 'bagging_freq': 8, 'class_weight': 1.1859713696766463}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.028307900552012707\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6353935116077791\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7656815587196362 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.028307900552012707\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6353935116077791\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7656815587196362 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.028307900552012707\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6353935116077791\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7656815587196362 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:42,233] Trial 72 finished with value: 0.7140366332068608 and parameters: {'num_leaves': 20, 'learning_rate': 0.0055723571626352985, 'max_depth': 8, 'min_data_in_leaf': 71, 'subsample': 0.7656815587196362, 'feature_fraction': 0.5419149577012823, 'lambda_l1': 0.028307900552012707, 'lambda_l2': 0.8704406530408697, 'n_estimators ': 400, 'bagging_fraction ': 0.6353935116077791, 'bagging_freq': 9, 'class_weight': 1.2720188180456573}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.007941253273605741\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.675799778504964\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8147454418847653 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.007941253273605741\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.675799778504964\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8147454418847653 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.007941253273605741\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.675799778504964\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8147454418847653 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:42,724] Trial 73 finished with value: 0.717227292280032 and parameters: {'num_leaves': 65, 'learning_rate': 0.006255727273380513, 'max_depth': 9, 'min_data_in_leaf': 86, 'subsample': 0.8147454418847653, 'feature_fraction': 0.5160691901677869, 'lambda_l1': 0.007941253273605741, 'lambda_l2': 0.28682894459108643, 'n_estimators ': 300, 'bagging_fraction ': 0.675799778504964, 'bagging_freq': 8, 'class_weight': 1.2198474862494104}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.013388018164247839\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5868395231735609\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7736886947930376 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.013388018164247839\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5868395231735609\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7736886947930376 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.013388018164247839\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5868395231735609\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7736886947930376 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:43,281] Trial 74 finished with value: 0.7179753082603735 and parameters: {'num_leaves': 70, 'learning_rate': 0.0068428362309126975, 'max_depth': 8, 'min_data_in_leaf': 81, 'subsample': 0.7736886947930376, 'feature_fraction': 0.5306022497171571, 'lambda_l1': 0.013388018164247839, 'lambda_l2': 4.6628750543899, 'n_estimators ': 400, 'bagging_fraction ': 0.5868395231735609, 'bagging_freq': 7, 'class_weight': 1.0297192809726683}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0016215736932686151\n",
      "[LightGBM] [Warning] Unknown parameter: 0.58003705993252\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7936341822471615 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0016215736932686151\n",
      "[LightGBM] [Warning] Unknown parameter: 0.58003705993252\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7936341822471615 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0016215736932686151\n",
      "[LightGBM] [Warning] Unknown parameter: 0.58003705993252\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7936341822471615 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:43,736] Trial 75 finished with value: 0.7178671241309853 and parameters: {'num_leaves': 70, 'learning_rate': 0.007094135838084797, 'max_depth': 8, 'min_data_in_leaf': 81, 'subsample': 0.7936341822471615, 'feature_fraction': 0.5329535051111726, 'lambda_l1': 0.0016215736932686151, 'lambda_l2': 2.02913492711808, 'n_estimators ': 400, 'bagging_fraction ': 0.58003705993252, 'bagging_freq': 7, 'class_weight': 1.0355254772336053}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0014084222101831282\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5799484637275588\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.789844796570028 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0014084222101831282\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5799484637275588\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.789844796570028 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0014084222101831282\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5799484637275588\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.789844796570028 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:44,137] Trial 76 finished with value: 0.7174374785885578 and parameters: {'num_leaves': 70, 'learning_rate': 0.0076597863497738896, 'max_depth': 9, 'min_data_in_leaf': 81, 'subsample': 0.789844796570028, 'feature_fraction': 0.5594626551275171, 'lambda_l1': 0.0014084222101831282, 'lambda_l2': 4.674936395836755, 'n_estimators ': 300, 'bagging_fraction ': 0.5799484637275588, 'bagging_freq': 7, 'class_weight': 1.0341937654352908}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.019993862541176338\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5825727598781262\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8361817418101062 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.019993862541176338\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5825727598781262\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8361817418101062 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.019993862541176338\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5825727598781262\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8361817418101062 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:44,591] Trial 77 finished with value: 0.7164602152864175 and parameters: {'num_leaves': 70, 'learning_rate': 0.006969033337770715, 'max_depth': 10, 'min_data_in_leaf': 61, 'subsample': 0.8361817418101062, 'feature_fraction': 0.5373230968551043, 'lambda_l1': 0.019993862541176338, 'lambda_l2': 8.175178342853474, 'n_estimators ': 900, 'bagging_fraction ': 0.5825727598781262, 'bagging_freq': 6, 'class_weight': 1.0229855493313653}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.0415480036872909\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5449521676740657\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8143251829459912 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0415480036872909\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5449521676740657\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8143251829459912 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0415480036872909\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5449521676740657\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8143251829459912 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:45,161] Trial 78 finished with value: 0.7171286386572804 and parameters: {'num_leaves': 70, 'learning_rate': 0.00801160752343952, 'max_depth': 8, 'min_data_in_leaf': 81, 'subsample': 0.8143251829459912, 'feature_fraction': 0.5914200390924054, 'lambda_l1': 0.0415480036872909, 'lambda_l2': 2.3594919014605256, 'n_estimators ': 400, 'bagging_fraction ': 0.5449521676740657, 'bagging_freq': 8, 'class_weight': 1.0400036318714199}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.00043221034117181377\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5889520236958582\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8541079216627369 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.00043221034117181377\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5889520236958582\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8541079216627369 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.00043221034117181377\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5889520236958582\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8541079216627369 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:45,663] Trial 79 finished with value: 0.7173684468107576 and parameters: {'num_leaves': 70, 'learning_rate': 0.006799469717761405, 'max_depth': 9, 'min_data_in_leaf': 91, 'subsample': 0.8541079216627369, 'feature_fraction': 0.532346781136069, 'lambda_l1': 0.00043221034117181377, 'lambda_l2': 5.05813697242226, 'n_estimators ': 500, 'bagging_fraction ': 0.5889520236958582, 'bagging_freq': 7, 'class_weight': 1.0195269293810916}. Best is trial 52 with value: 0.7181834339188156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.007097185239045006\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5647207467795637\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8039452108008357 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.007097185239045006\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5647207467795637\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8039452108008357 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.007097185239045006\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5647207467795637\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8039452108008357 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:46,207] Trial 80 finished with value: 0.71843895452918 and parameters: {'num_leaves': 70, 'learning_rate': 0.008636780107651473, 'max_depth': 8, 'min_data_in_leaf': 86, 'subsample': 0.8039452108008357, 'feature_fraction': 0.5534083307989579, 'lambda_l1': 0.007097185239045006, 'lambda_l2': 0.20703559973927083, 'n_estimators ': 300, 'bagging_fraction ': 0.5647207467795637, 'bagging_freq': 6, 'class_weight': 1.1161681207566259}. Best is trial 80 with value: 0.71843895452918.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.00493154237753977\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.560345506754653\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7779134020967294 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.00493154237753977\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.560345506754653\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7779134020967294 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.00493154237753977\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.560345506754653\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7779134020967294 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:46,681] Trial 81 finished with value: 0.7177081964932888 and parameters: {'num_leaves': 70, 'learning_rate': 0.007284374623258941, 'max_depth': 8, 'min_data_in_leaf': 86, 'subsample': 0.7779134020967294, 'feature_fraction': 0.5711679118441338, 'lambda_l1': 0.00493154237753977, 'lambda_l2': 0.1899187711365537, 'n_estimators ': 300, 'bagging_fraction ': 0.560345506754653, 'bagging_freq': 6, 'class_weight': 1.0947143711655312}. Best is trial 80 with value: 0.71843895452918.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.007251879967646439\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5674760835548077\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7962904201913613 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.007251879967646439\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5674760835548077\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7962904201913613 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.007251879967646439\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5674760835548077\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7962904201913613 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:47,045] Trial 82 finished with value: 0.717560087268531 and parameters: {'num_leaves': 70, 'learning_rate': 0.00793543741630766, 'max_depth': 8, 'min_data_in_leaf': 91, 'subsample': 0.7962904201913613, 'feature_fraction': 0.5532553540953118, 'lambda_l1': 0.007251879967646439, 'lambda_l2': 1.8114299358843278, 'n_estimators ': 300, 'bagging_fraction ': 0.5674760835548077, 'bagging_freq': 7, 'class_weight': 1.1219754736667726}. Best is trial 80 with value: 0.71843895452918.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.001793930082480175\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5199962753631318\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7472534314041241 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.001793930082480175\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5199962753631318\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7472534314041241 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.001793930082480175\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5199962753631318\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7472534314041241 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:47,448] Trial 83 finished with value: 0.7178933974195509 and parameters: {'num_leaves': 65, 'learning_rate': 0.008727509398621979, 'max_depth': 8, 'min_data_in_leaf': 86, 'subsample': 0.7472534314041241, 'feature_fraction': 0.5375528954056827, 'lambda_l1': 0.001793930082480175, 'lambda_l2': 0.4128581487839267, 'n_estimators ': 200, 'bagging_fraction ': 0.5199962753631318, 'bagging_freq': 7, 'class_weight': 1.0584377214909915}. Best is trial 80 with value: 0.71843895452918.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0012938573832304925\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5082024011599016\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7484172920857854 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0012938573832304925\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5082024011599016\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7484172920857854 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0012938573832304925\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5082024011599016\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7484172920857854 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:47,847] Trial 84 finished with value: 0.7186378072622461 and parameters: {'num_leaves': 70, 'learning_rate': 0.0088025731000058, 'max_depth': 9, 'min_data_in_leaf': 86, 'subsample': 0.7484172920857854, 'feature_fraction': 0.530817739386896, 'lambda_l1': 0.0012938573832304925, 'lambda_l2': 9.702987789291358, 'n_estimators ': 100, 'bagging_fraction ': 0.5082024011599016, 'bagging_freq': 5, 'class_weight': 1.0067124590078884}. Best is trial 84 with value: 0.7186378072622461.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.000962993490225769\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5173357642555323\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7174125809714226 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.000962993490225769\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5173357642555323\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7174125809714226 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.000962993490225769\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5173357642555323\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7174125809714226 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:48,234] Trial 85 finished with value: 0.7178290021044389 and parameters: {'num_leaves': 70, 'learning_rate': 0.008610057420080067, 'max_depth': 9, 'min_data_in_leaf': 81, 'subsample': 0.7174125809714226, 'feature_fraction': 0.5328646042899945, 'lambda_l1': 0.000962993490225769, 'lambda_l2': 0.1025656056661806, 'n_estimators ': 100, 'bagging_fraction ': 0.5173357642555323, 'bagging_freq': 5, 'class_weight': 1.0046972213360652}. Best is trial 84 with value: 0.7186378072622461.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5087111226875902\n",
      "[LightGBM] [Warning] Unknown parameter: 0.00025475414657904425\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7519162631173515 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5087111226875902\n",
      "[LightGBM] [Warning] Unknown parameter: 0.00025475414657904425\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7519162631173515 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5087111226875902\n",
      "[LightGBM] [Warning] Unknown parameter: 0.00025475414657904425\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7519162631173515 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:48,631] Trial 86 finished with value: 0.7186303374056932 and parameters: {'num_leaves': 70, 'learning_rate': 0.008963453345066312, 'max_depth': 9, 'min_data_in_leaf': 86, 'subsample': 0.7519162631173515, 'feature_fraction': 0.5295219277693795, 'lambda_l1': 0.00025475414657904425, 'lambda_l2': 0.45544692726629743, 'n_estimators ': 100, 'bagging_fraction ': 0.5087111226875902, 'bagging_freq': 6, 'class_weight': 1.0535773963965867}. Best is trial 84 with value: 0.7186378072622461.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.00011904052410004904\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5001318627044582\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7430859839108317 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.00011904052410004904\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5001318627044582\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7430859839108317 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.00011904052410004904\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5001318627044582\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7430859839108317 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:49,036] Trial 87 finished with value: 0.7170503339541041 and parameters: {'num_leaves': 70, 'learning_rate': 0.009356435028228353, 'max_depth': 10, 'min_data_in_leaf': 86, 'subsample': 0.7430859839108317, 'feature_fraction': 0.5668152317011869, 'lambda_l1': 0.00011904052410004904, 'lambda_l2': 0.3622534302060433, 'n_estimators ': 100, 'bagging_fraction ': 0.5001318627044582, 'bagging_freq': 6, 'class_weight': 1.0569741088617657}. Best is trial 84 with value: 0.7186378072622461.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0002800686046274497\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.516857737001524\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7314520755852767 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0002800686046274497\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.516857737001524\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7314520755852767 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0002800686046274497\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.516857737001524\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7314520755852767 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:49,463] Trial 88 finished with value: 0.7182684357347634 and parameters: {'num_leaves': 65, 'learning_rate': 0.00852620986112823, 'max_depth': 9, 'min_data_in_leaf': 91, 'subsample': 0.7314520755852767, 'feature_fraction': 0.5102655888613894, 'lambda_l1': 0.0002800686046274497, 'lambda_l2': 0.18108208725682434, 'n_estimators ': 100, 'bagging_fraction ': 0.516857737001524, 'bagging_freq': 6, 'class_weight': 1.083697376296676}. Best is trial 84 with value: 0.7186378072622461.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0002386133523694716\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5352548601158972\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6943744646127791 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0002386133523694716\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5352548601158972\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6943744646127791 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0002386133523694716\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5352548601158972\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6943744646127791 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:49,957] Trial 89 finished with value: 0.7176932567801828 and parameters: {'num_leaves': 70, 'learning_rate': 0.009666584102188935, 'max_depth': 9, 'min_data_in_leaf': 96, 'subsample': 0.6943744646127791, 'feature_fraction': 0.5100089627609269, 'lambda_l1': 0.0002386133523694716, 'lambda_l2': 0.16632921934029174, 'n_estimators ': 100, 'bagging_fraction ': 0.5352548601158972, 'bagging_freq': 5, 'class_weight': 1.084930735751751}. Best is trial 84 with value: 0.7186378072622461.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0004823990071731023\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5118424785202974\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7359556240581935 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0004823990071731023\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5118424785202974\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7359556240581935 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0004823990071731023\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5118424785202974\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7359556240581935 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:50,344] Trial 90 finished with value: 0.7168190259822218 and parameters: {'num_leaves': 65, 'learning_rate': 0.007562234231002823, 'max_depth': 10, 'min_data_in_leaf': 91, 'subsample': 0.7359556240581935, 'feature_fraction': 0.5525731373716285, 'lambda_l1': 0.0004823990071731023, 'lambda_l2': 0.027392159991122215, 'n_estimators ': 100, 'bagging_fraction ': 0.5118424785202974, 'bagging_freq': 6, 'class_weight': 1.1011143502255023}. Best is trial 84 with value: 0.7186378072622461.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 5.725114675493951e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5195359291177492\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7207305621087313 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 5.725114675493951e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5195359291177492\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7207305621087313 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 5.725114675493951e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5195359291177492\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7207305621087313 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:50,800] Trial 91 finished with value: 0.7183307703997918 and parameters: {'num_leaves': 65, 'learning_rate': 0.0090624506989461, 'max_depth': 9, 'min_data_in_leaf': 91, 'subsample': 0.7207305621087313, 'feature_fraction': 0.5288066075346674, 'lambda_l1': 5.725114675493951e-05, 'lambda_l2': 0.07759651278403105, 'n_estimators ': 200, 'bagging_fraction ': 0.5195359291177492, 'bagging_freq': 6, 'class_weight': 1.0575141494953033}. Best is trial 84 with value: 0.7186378072622461.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5362177317867413\n",
      "[LightGBM] [Warning] Unknown parameter: 6.191319859933216e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7238323162900867 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5362177317867413\n",
      "[LightGBM] [Warning] Unknown parameter: 6.191319859933216e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7238323162900867 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5362177317867413\n",
      "[LightGBM] [Warning] Unknown parameter: 6.191319859933216e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7238323162900867 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:51,316] Trial 92 finished with value: 0.7177233937876553 and parameters: {'num_leaves': 60, 'learning_rate': 0.009096291176550267, 'max_depth': 9, 'min_data_in_leaf': 91, 'subsample': 0.7238323162900867, 'feature_fraction': 0.525809876852276, 'lambda_l1': 6.191319859933216e-05, 'lambda_l2': 0.08127061487335847, 'n_estimators ': 200, 'bagging_fraction ': 0.5362177317867413, 'bagging_freq': 6, 'class_weight': 1.0759115941736928}. Best is trial 84 with value: 0.7186378072622461.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 2.5400853225809383e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5090268614342277\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7151524608106111 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 2.5400853225809383e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5090268614342277\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7151524608106111 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 2.5400853225809383e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5090268614342277\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7151524608106111 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:51,745] Trial 93 finished with value: 0.7179356407462645 and parameters: {'num_leaves': 65, 'learning_rate': 0.008475762861813618, 'max_depth': 9, 'min_data_in_leaf': 86, 'subsample': 0.7151524608106111, 'feature_fraction': 0.516677377824838, 'lambda_l1': 2.5400853225809383e-05, 'lambda_l2': 0.22976681719482836, 'n_estimators ': 100, 'bagging_fraction ': 0.5090268614342277, 'bagging_freq': 5, 'class_weight': 1.0072186198466877}. Best is trial 84 with value: 0.7186378072622461.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 1.3059069189791678e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5073619671260041\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7171050755365013 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.3059069189791678e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5073619671260041\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7171050755365013 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001951 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 1.3059069189791678e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5073619671260041\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7171050755365013 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:52,154] Trial 94 finished with value: 0.7184680612116107 and parameters: {'num_leaves': 70, 'learning_rate': 0.009888898392766908, 'max_depth': 9, 'min_data_in_leaf': 91, 'subsample': 0.7171050755365013, 'feature_fraction': 0.5282344485307041, 'lambda_l1': 1.3059069189791678e-05, 'lambda_l2': 0.03238063792780419, 'n_estimators ': 100, 'bagging_fraction ': 0.5073619671260041, 'bagging_freq': 5, 'class_weight': 1.0001574725932598}. Best is trial 84 with value: 0.7186378072622461.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 2.0255436051176553e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5248596629964725\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7509359685112221 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 2.0255436051176553e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5248596629964725\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7509359685112221 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 2.0255436051176553e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5248596629964725\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7509359685112221 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:52,714] Trial 95 finished with value: 0.7161925883568119 and parameters: {'num_leaves': 70, 'learning_rate': 0.009964911777788679, 'max_depth': 10, 'min_data_in_leaf': 91, 'subsample': 0.7509359685112221, 'feature_fraction': 0.5816946483500767, 'lambda_l1': 2.0255436051176553e-05, 'lambda_l2': 0.03882228253797663, 'n_estimators ': 100, 'bagging_fraction ': 0.5248596629964725, 'bagging_freq': 5, 'class_weight': 1.0450398219113808}. Best is trial 84 with value: 0.7186378072622461.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.2302084616037964\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5270123745985323\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6971845557340939 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.2302084616037964\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5270123745985323\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6971845557340939 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.2302084616037964\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5270123745985323\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6971845557340939 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:53,108] Trial 96 finished with value: 0.7178985490447599 and parameters: {'num_leaves': 70, 'learning_rate': 0.009178369936602926, 'max_depth': 9, 'min_data_in_leaf': 96, 'subsample': 0.6971845557340939, 'feature_fraction': 0.5276290073895247, 'lambda_l1': 0.2302084616037964, 'lambda_l2': 0.013939308840682155, 'n_estimators ': 200, 'bagging_fraction ': 0.5270123745985323, 'bagging_freq': 6, 'class_weight': 1.0004462103219942}. Best is trial 84 with value: 0.7186378072622461.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 1.188450933259874e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 0.510498293665129\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6804329443913716 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.188450933259874e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 0.510498293665129\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6804329443913716 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 1.188450933259874e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 0.510498293665129\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6804329443913716 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:53,546] Trial 97 finished with value: 0.7176829535297647 and parameters: {'num_leaves': 70, 'learning_rate': 0.008812795892948854, 'max_depth': 10, 'min_data_in_leaf': 86, 'subsample': 0.6804329443913716, 'feature_fraction': 0.5520111594414294, 'lambda_l1': 1.188450933259874e-05, 'lambda_l2': 0.05666713895162779, 'n_estimators ': 100, 'bagging_fraction ': 0.510498293665129, 'bagging_freq': 4, 'class_weight': 1.0306777541395578}. Best is trial 84 with value: 0.7186378072622461.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.00022187759996866908\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5530058523827018\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.704239246691654 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.00022187759996866908\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5530058523827018\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.704239246691654 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.00022187759996866908\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5530058523827018\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.704239246691654 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:53,973] Trial 98 finished with value: 0.7165532021214394 and parameters: {'num_leaves': 70, 'learning_rate': 0.008333710949881754, 'max_depth': 9, 'min_data_in_leaf': 91, 'subsample': 0.704239246691654, 'feature_fraction': 0.6011987321623941, 'lambda_l1': 0.00022187759996866908, 'lambda_l2': 0.018159830759592505, 'n_estimators ': 200, 'bagging_fraction ': 0.5530058523827018, 'bagging_freq': 5, 'class_weight': 1.0884854442857193}. Best is trial 84 with value: 0.7186378072622461.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0880322378941527\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.502052297745264\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7170839750689082 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0880322378941527\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.502052297745264\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7170839750689082 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0880322378941527\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.502052297745264\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7170839750689082 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:17:54,284] Trial 99 finished with value: 0.7164483665484369 and parameters: {'num_leaves': 35, 'learning_rate': 0.009444239186294962, 'max_depth': 9, 'min_data_in_leaf': 96, 'subsample': 0.7170839750689082, 'feature_fraction': 0.5675811842541245, 'lambda_l1': 0.0880322378941527, 'lambda_l2': 0.0357238481158322, 'n_estimators ': 100, 'bagging_fraction ': 0.502052297745264, 'bagging_freq': 6, 'class_weight': 1.1230889315659236}. Best is trial 84 with value: 0.7186378072622461.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "best_params = study.best_params\n",
    "best_score = study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8c1fbf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best parameters are:  {'num_leaves': 70, 'learning_rate': 0.0088025731000058, 'max_depth': 9, 'min_data_in_leaf': 86, 'subsample': 0.7484172920857854, 'feature_fraction': 0.530817739386896, 'lambda_l1': 0.0012938573832304925, 'lambda_l2': 9.702987789291358, 'n_estimators ': 100, 'bagging_fraction ': 0.5082024011599016, 'bagging_freq': 5, 'class_weight': 1.0067124590078884}\n",
      "The best score is:  0.7186378072622461\n"
     ]
    }
   ],
   "source": [
    "print('the best parameters are: ', best_params)\n",
    "print('The best score is: ', best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7c6580",
   "metadata": {},
   "source": [
    "Past params:  \n",
    "- the best parameters are:  {'num_leaves': 45, 'learning_rate': 0.03300619602041917, 'max_depth': 7, 'min_data_in_leaf': 96, 'subsample': 0.6621885034162259, 'feature_fraction': 0.5141782866984629, 'lambda_l1': 4.598980413991733e-06, 'lambda_l2': 1.5185449619617765e-07, 'n_estimators ': 1000, 'bagging_fraction ': 0.948850128847817, 'bagging_freq': 1, 'class_weight': 1.9943692388353824}|The best score is:  0.717371022623362"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b7cbafaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5082024011599016\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7484172920857854 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5082024011599016\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7484172920857854 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5082024011599016\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7484172920857854 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.666639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Train Accuracy score is: 0.6998315080033698\n",
      "Test Accuracy score is: 0.7014824797843666\n",
      "ROCAUC score is: 0.7186218372240982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.14      0.23       973\n",
      "           1       0.70      0.98      0.81      1995\n",
      "\n",
      "    accuracy                           0.70      2968\n",
      "   macro avg       0.72      0.56      0.52      2968\n",
      "weighted avg       0.71      0.70      0.62      2968\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = lgb.Dataset(X_train, label=y_train)\n",
    "val = lgb.Dataset(X_val, label=y_val)\n",
    "model1 = lgb.train(best_params, train, valid_sets=val, early_stopping_rounds=100, verbose_eval=False)\n",
    "# lgbm = LGBMClassifier(**best_params, random_state=2, objective='binary')\n",
    "# lgbm.fit(X_train, y_train)\n",
    "\n",
    "evaluate_lgbm(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b047b065",
   "metadata": {},
   "source": [
    "# EC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ed8c6987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BertzCT</th>\n",
       "      <th>ExactMolWt</th>\n",
       "      <th>HeavyAtomMolWt</th>\n",
       "      <th>Chi1</th>\n",
       "      <th>Chi1n</th>\n",
       "      <th>Chi1v</th>\n",
       "      <th>Chi2n</th>\n",
       "      <th>Chi2v</th>\n",
       "      <th>Chi3v</th>\n",
       "      <th>Chi4n</th>\n",
       "      <th>...</th>\n",
       "      <th>PEOE_VSA14</th>\n",
       "      <th>PEOE_VSA6</th>\n",
       "      <th>PEOE_VSA7</th>\n",
       "      <th>PEOE_VSA8</th>\n",
       "      <th>SMR_VSA10</th>\n",
       "      <th>SMR_VSA5</th>\n",
       "      <th>SlogP_VSA3</th>\n",
       "      <th>VSA_EState9</th>\n",
       "      <th>fr_COO</th>\n",
       "      <th>fr_COO2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6788</th>\n",
       "      <td>-0.479488</td>\n",
       "      <td>-0.631739</td>\n",
       "      <td>-0.633457</td>\n",
       "      <td>4.825699</td>\n",
       "      <td>2.793756</td>\n",
       "      <td>2.793756</td>\n",
       "      <td>1.932542</td>\n",
       "      <td>1.932542</td>\n",
       "      <td>1.438134</td>\n",
       "      <td>0.895230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.393687</td>\n",
       "      <td>5.687386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>-0.633683</td>\n",
       "      <td>-0.596321</td>\n",
       "      <td>-0.577001</td>\n",
       "      <td>5.947265</td>\n",
       "      <td>3.675670</td>\n",
       "      <td>3.675670</td>\n",
       "      <td>2.757262</td>\n",
       "      <td>2.757262</td>\n",
       "      <td>1.708684</td>\n",
       "      <td>0.955337</td>\n",
       "      <td>...</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.938611</td>\n",
       "      <td>25.304306</td>\n",
       "      <td>9.531400</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3551</th>\n",
       "      <td>-0.513457</td>\n",
       "      <td>-0.613643</td>\n",
       "      <td>-0.651981</td>\n",
       "      <td>5.036581</td>\n",
       "      <td>3.414884</td>\n",
       "      <td>3.414884</td>\n",
       "      <td>2.703542</td>\n",
       "      <td>2.703542</td>\n",
       "      <td>1.827002</td>\n",
       "      <td>1.029291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.15204</td>\n",
       "      <td>17.696186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.103966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8301</th>\n",
       "      <td>-0.635423</td>\n",
       "      <td>-0.538873</td>\n",
       "      <td>-0.525580</td>\n",
       "      <td>5.092224</td>\n",
       "      <td>2.925131</td>\n",
       "      <td>2.925131</td>\n",
       "      <td>2.116586</td>\n",
       "      <td>2.116586</td>\n",
       "      <td>1.611120</td>\n",
       "      <td>0.757462</td>\n",
       "      <td>...</td>\n",
       "      <td>12.062229</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.907600</td>\n",
       "      <td>12.462662</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>-0.795743</td>\n",
       "      <td>-0.835799</td>\n",
       "      <td>-0.821568</td>\n",
       "      <td>2.642734</td>\n",
       "      <td>1.049739</td>\n",
       "      <td>1.049739</td>\n",
       "      <td>0.504904</td>\n",
       "      <td>0.504904</td>\n",
       "      <td>0.142577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.752550</td>\n",
       "      <td>6.544756</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>29.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       BertzCT  ExactMolWt  HeavyAtomMolWt      Chi1     Chi1n     Chi1v  \\\n",
       "6788 -0.479488   -0.631739       -0.633457  4.825699  2.793756  2.793756   \n",
       "1962 -0.633683   -0.596321       -0.577001  5.947265  3.675670  3.675670   \n",
       "3551 -0.513457   -0.613643       -0.651981  5.036581  3.414884  3.414884   \n",
       "8301 -0.635423   -0.538873       -0.525580  5.092224  2.925131  2.925131   \n",
       "281  -0.795743   -0.835799       -0.821568  2.642734  1.049739  1.049739   \n",
       "\n",
       "         Chi2n     Chi2v     Chi3v     Chi4n  ...  PEOE_VSA14  PEOE_VSA6  \\\n",
       "6788  1.932542  1.932542  1.438134  0.895230  ...    0.000000    0.00000   \n",
       "1962  2.757262  2.757262  1.708684  0.955337  ...    5.969305    0.00000   \n",
       "3551  2.703542  2.703542  1.827002  1.029291  ...    0.000000   12.15204   \n",
       "8301  2.116586  2.116586  1.611120  0.757462  ...   12.062229    0.00000   \n",
       "281   0.504904  0.504904  0.142577  0.000000  ...    5.969305    0.00000   \n",
       "\n",
       "      PEOE_VSA7  PEOE_VSA8  SMR_VSA10   SMR_VSA5  SlogP_VSA3  VSA_EState9  \\\n",
       "6788   0.000000  12.393687   5.687386   0.000000    0.000000    30.000000   \n",
       "1962   0.000000   0.000000  11.938611  25.304306    9.531400    47.000000   \n",
       "3551  17.696186   0.000000   0.000000   6.103966    0.000000    36.166667   \n",
       "8301   0.000000   0.000000  17.907600  12.462662    9.589074    39.500000   \n",
       "281    0.000000   0.000000  11.752550   6.544756    9.589074    29.666667   \n",
       "\n",
       "      fr_COO  fr_COO2  \n",
       "6788       0        0  \n",
       "1962       1        1  \n",
       "3551       0        0  \n",
       "8301       1        1  \n",
       "281        1        1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_data.drop(['id', 'EC1', 'EC2', 'EC3', 'EC4', 'EC5', 'EC6'], axis=1)\n",
    "y = train_data['EC2']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y, test_size=.2, random_state=2)\n",
    "cols_not = [i for i in X_train.columns if i not in high_value_cols]\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_sc=pd.DataFrame(scaler.fit_transform(X_train[high_value_cols]),index=X_train.index,columns=high_value_cols)\n",
    "val_sc=pd.DataFrame(scaler.fit_transform(X_val[high_value_cols]),index=X_val.index,columns=high_value_cols)\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# X_train=pd.DataFrame(scaler.fit_transform(X_train),index=X_train.index,columns=X_train.columns)\n",
    "# X_val=pd.DataFrame(scaler.fit_transform(X_val),index=X_val.index,columns=X_val.columns)\n",
    "\n",
    "X_train = pd.concat([train_sc, X_train[cols_not]], axis=1)\n",
    "X_val = pd.concat([val_sc, X_val[cols_not]], axis=1)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d86e3b",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "27ef348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    parameters = {\n",
    "        'objective':'binary',\n",
    "        'num_leaves':trial.suggest_int('num_leaves', 10, 75),\n",
    "        'learning_rate':trial.suggest_loguniform('learning_rate', 0.001, 0.01),\n",
    "        'max_depth':trial.suggest_int('max_depth', 2, 10),\n",
    "        'min_data_in_leaf':trial.suggest_int('min_data_in_leaf', 1, 100, step=5),\n",
    "        'subsample':trial.suggest_float('subsample', 0.5, 1),\n",
    "        'feature_fraction':trial.suggest_uniform('feature_fraction', 0.5, 1),\n",
    "        'lambda_l1 ':trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'n_estimators ':trial.suggest_int('n_estimators ', 100, 500, step=100),\n",
    "        'bagging_fraction ':trial.suggest_uniform('bagging_fraction ', 0.5,1),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        'class_weight': trial.suggest_uniform('class_weight', 1.0,3.0),\n",
    "    }\n",
    "    train = lgb.Dataset(X_train, label=y_train)\n",
    "    val = lgb.Dataset(X_val, label=y_val)\n",
    "    \n",
    "    model = lgb.train(parameters, train, valid_sets=val, early_stopping_rounds=100, verbose_eval=False)\n",
    "\n",
    "    y_hat = model.predict(X_val)\n",
    "#     y_hat_bin = (y_hat>=0.5).astype(int)\n",
    "    score = roc_auc_score(y_val, y_hat)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "96d057bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:14,512] A new study created in memory with name: no-name-112801d9-fb8c-4403-a37e-8136b9e6cb2b\n",
      "[I 2023-07-05 16:25:14,655] Trial 0 finished with value: 0.5826251119237947 and parameters: {'num_leaves': 60, 'learning_rate': 0.0018826223451531197, 'max_depth': 3, 'min_data_in_leaf': 46, 'subsample': 0.9191522200447335, 'feature_fraction': 0.615136308100511, 'lambda_l1': 0.0011615554654893724, 'lambda_l2': 1.0398441959759751e-08, 'n_estimators ': 200, 'bagging_fraction ': 0.9381085995001767, 'bagging_freq': 3, 'class_weight': 1.775099129366766}. Best is trial 0 with value: 0.5826251119237947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.0011615554654893724\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9381085995001767\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9191522200447335 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0011615554654893724\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9381085995001767\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9191522200447335 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0011615554654893724\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9381085995001767\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9191522200447335 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0035973653930648883\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5600902306015607\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8198299543097539 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0035973653930648883\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5600902306015607\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8198299543097539 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0035973653930648883\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5600902306015607\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8198299543097539 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:14,948] Trial 1 finished with value: 0.5816520491493791 and parameters: {'num_leaves': 59, 'learning_rate': 0.009349769419424397, 'max_depth': 7, 'min_data_in_leaf': 76, 'subsample': 0.8198299543097539, 'feature_fraction': 0.872410999111833, 'lambda_l1': 0.0035973653930648883, 'lambda_l2': 3.084748649774647e-07, 'n_estimators ': 400, 'bagging_fraction ': 0.5600902306015607, 'bagging_freq': 6, 'class_weight': 1.0294815305149319}. Best is trial 0 with value: 0.5826251119237947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.601572587407202\n",
      "[LightGBM] [Warning] Unknown parameter: 0.002741412084536542\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9576918422106929 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.601572587407202\n",
      "[LightGBM] [Warning] Unknown parameter: 0.002741412084536542\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9576918422106929 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.601572587407202\n",
      "[LightGBM] [Warning] Unknown parameter: 0.002741412084536542\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9576918422106929 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:15,165] Trial 2 finished with value: 0.5894268422926309 and parameters: {'num_leaves': 20, 'learning_rate': 0.005300637177824105, 'max_depth': 8, 'min_data_in_leaf': 51, 'subsample': 0.9576918422106929, 'feature_fraction': 0.9614615323427617, 'lambda_l1': 0.002741412084536542, 'lambda_l2': 9.258678632515555e-05, 'n_estimators ': 400, 'bagging_fraction ': 0.601572587407202, 'bagging_freq': 1, 'class_weight': 2.683329455877766}. Best is trial 2 with value: 0.5894268422926309.\n",
      "[I 2023-07-05 16:25:15,356] Trial 3 finished with value: 0.5884206968222632 and parameters: {'num_leaves': 49, 'learning_rate': 0.006740658762416032, 'max_depth': 5, 'min_data_in_leaf': 81, 'subsample': 0.603930404305484, 'feature_fraction': 0.9189881967651294, 'lambda_l1': 0.00015756913582465372, 'lambda_l2': 1.7612243430409804e-08, 'n_estimators ': 200, 'bagging_fraction ': 0.7696701964246266, 'bagging_freq': 10, 'class_weight': 1.6615155732579765}. Best is trial 2 with value: 0.5894268422926309.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.7696701964246266\n",
      "[LightGBM] [Warning] Unknown parameter: 0.00015756913582465372\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.603930404305484 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7696701964246266\n",
      "[LightGBM] [Warning] Unknown parameter: 0.00015756913582465372\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.603930404305484 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7696701964246266\n",
      "[LightGBM] [Warning] Unknown parameter: 0.00015756913582465372\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.603930404305484 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.885803073192399\n",
      "[LightGBM] [Warning] Unknown parameter: 6.722802108489905e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8629547055579971 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.885803073192399\n",
      "[LightGBM] [Warning] Unknown parameter: 6.722802108489905e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8629547055579971 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.885803073192399\n",
      "[LightGBM] [Warning] Unknown parameter: 6.722802108489905e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8629547055579971 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:15,623] Trial 4 finished with value: 0.5882703863123941 and parameters: {'num_leaves': 27, 'learning_rate': 0.0074702649205746815, 'max_depth': 5, 'min_data_in_leaf': 46, 'subsample': 0.8629547055579971, 'feature_fraction': 0.9238725736164045, 'lambda_l1': 6.722802108489905e-06, 'lambda_l2': 2.1597588293011736, 'n_estimators ': 300, 'bagging_fraction ': 0.885803073192399, 'bagging_freq': 9, 'class_weight': 1.2944766525529978}. Best is trial 2 with value: 0.5894268422926309.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 9.047033611822928e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5755096051331379\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8012091386158997 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 9.047033611822928e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5755096051331379\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8012091386158997 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002442 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 9.047033611822928e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5755096051331379\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8012091386158997 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:15,876] Trial 5 finished with value: 0.5891959826100089 and parameters: {'num_leaves': 36, 'learning_rate': 0.0017512394365156046, 'max_depth': 4, 'min_data_in_leaf': 66, 'subsample': 0.8012091386158997, 'feature_fraction': 0.8455050399321689, 'lambda_l1': 9.047033611822928e-06, 'lambda_l2': 4.711285373663615e-06, 'n_estimators ': 300, 'bagging_fraction ': 0.5755096051331379, 'bagging_freq': 8, 'class_weight': 2.139873036798947}. Best is trial 2 with value: 0.5894268422926309.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 3.445025978468208e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5573632739636667\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6060915717398636 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 3.445025978468208e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5573632739636667\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6060915717398636 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 3.445025978468208e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5573632739636667\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6060915717398636 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:16,053] Trial 6 finished with value: 0.5906678029853537 and parameters: {'num_leaves': 19, 'learning_rate': 0.0012422162913457795, 'max_depth': 4, 'min_data_in_leaf': 86, 'subsample': 0.6060915717398636, 'feature_fraction': 0.8156801723580974, 'lambda_l1': 3.445025978468208e-08, 'lambda_l2': 0.0004651575678640811, 'n_estimators ': 500, 'bagging_fraction ': 0.5573632739636667, 'bagging_freq': 3, 'class_weight': 1.7488527215542315}. Best is trial 6 with value: 0.5906678029853537.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 6.635109467019452e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9220943199956287\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7156234492944531 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 6.635109467019452e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9220943199956287\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7156234492944531 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 6.635109467019452e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9220943199956287\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7156234492944531 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:16,260] Trial 7 finished with value: 0.5882362248328785 and parameters: {'num_leaves': 18, 'learning_rate': 0.003744833391570508, 'max_depth': 6, 'min_data_in_leaf': 81, 'subsample': 0.7156234492944531, 'feature_fraction': 0.9882356228879343, 'lambda_l1': 6.635109467019452e-08, 'lambda_l2': 0.023386263004904023, 'n_estimators ': 400, 'bagging_fraction ': 0.9220943199956287, 'bagging_freq': 9, 'class_weight': 2.2960270975047075}. Best is trial 6 with value: 0.5906678029853537.\n",
      "[I 2023-07-05 16:25:16,455] Trial 8 finished with value: 0.591518244028034 and parameters: {'num_leaves': 63, 'learning_rate': 0.007747685697952172, 'max_depth': 5, 'min_data_in_leaf': 31, 'subsample': 0.6730230355401112, 'feature_fraction': 0.8403986054100614, 'lambda_l1': 1.203427346449579e-05, 'lambda_l2': 0.9633923675118913, 'n_estimators ': 300, 'bagging_fraction ': 0.6169455562392985, 'bagging_freq': 1, 'class_weight': 2.13556828156836}. Best is trial 8 with value: 0.591518244028034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.6169455562392985\n",
      "[LightGBM] [Warning] Unknown parameter: 1.203427346449579e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6730230355401112 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6169455562392985\n",
      "[LightGBM] [Warning] Unknown parameter: 1.203427346449579e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6730230355401112 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6169455562392985\n",
      "[LightGBM] [Warning] Unknown parameter: 1.203427346449579e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6730230355401112 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 1.1907275152104792e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6216861480926821\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6150706349591906 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.1907275152104792e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6216861480926821\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6150706349591906 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 1.1907275152104792e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6216861480926821\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6150706349591906 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:16,681] Trial 9 finished with value: 0.5927645986385751 and parameters: {'num_leaves': 32, 'learning_rate': 0.007488828686679601, 'max_depth': 10, 'min_data_in_leaf': 31, 'subsample': 0.6150706349591906, 'feature_fraction': 0.8406574706979022, 'lambda_l1': 1.1907275152104792e-07, 'lambda_l2': 0.00038630522088465034, 'n_estimators ': 100, 'bagging_fraction ': 0.6216861480926821, 'bagging_freq': 5, 'class_weight': 2.1307293947739394}. Best is trial 9 with value: 0.5927645986385751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 1.0284840236391513\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7632667272053952\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5275490097943556 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.0284840236391513\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7632667272053952\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5275490097943556 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 1.0284840236391513\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7632667272053952\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5275490097943556 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:17,198] Trial 10 finished with value: 0.5925276258490926 and parameters: {'num_leaves': 74, 'learning_rate': 0.004169901299477461, 'max_depth': 10, 'min_data_in_leaf': 6, 'subsample': 0.5275490097943556, 'feature_fraction': 0.7192013509133253, 'lambda_l1': 1.0284840236391513, 'lambda_l2': 0.0047679666238652, 'n_estimators ': 100, 'bagging_fraction ': 0.7632667272053952, 'bagging_freq': 6, 'class_weight': 2.8988890803231424}. Best is trial 9 with value: 0.5927645986385751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 4.017892906035241\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6884152285566301\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5212700855177165 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 4.017892906035241\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6884152285566301\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5212700855177165 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 4.017892906035241\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6884152285566301\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5212700855177165 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:17,830] Trial 11 finished with value: 0.5915516863185073 and parameters: {'num_leaves': 75, 'learning_rate': 0.004541877449009686, 'max_depth': 10, 'min_data_in_leaf': 1, 'subsample': 0.5212700855177165, 'feature_fraction': 0.7267307807046302, 'lambda_l1': 4.017892906035241, 'lambda_l2': 0.004262660900944991, 'n_estimators ': 100, 'bagging_fraction ': 0.6884152285566301, 'bagging_freq': 6, 'class_weight': 2.89737746089668}. Best is trial 9 with value: 0.5927645986385751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.834658289550829\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7485844535547371\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5053498738889919 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.834658289550829\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7485844535547371\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5053498738889919 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.834658289550829\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7485844535547371\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5053498738889919 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:18,324] Trial 12 finished with value: 0.5870736557457811 and parameters: {'num_leaves': 40, 'learning_rate': 0.0028995711701303543, 'max_depth': 10, 'min_data_in_leaf': 6, 'subsample': 0.5053498738889919, 'feature_fraction': 0.7334920746430347, 'lambda_l1': 0.834658289550829, 'lambda_l2': 0.028307725762285095, 'n_estimators ': 100, 'bagging_fraction ': 0.7485844535547371, 'bagging_freq': 4, 'class_weight': 2.5118405552278564}. Best is trial 9 with value: 0.5927645986385751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.19624951422293913\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5061701646456029\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5924054877356424 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.19624951422293913\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5061701646456029\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5924054877356424 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.19624951422293913\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5061701646456029\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5924054877356424 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:18,610] Trial 13 finished with value: 0.5907476329690641 and parameters: {'num_leaves': 32, 'learning_rate': 0.005679048641983188, 'max_depth': 9, 'min_data_in_leaf': 21, 'subsample': 0.5924054877356424, 'feature_fraction': 0.6646873647179579, 'lambda_l1': 0.19624951422293913, 'lambda_l2': 8.011946696956336e-05, 'n_estimators ': 100, 'bagging_fraction ': 0.5061701646456029, 'bagging_freq': 7, 'class_weight': 2.9279449909848934}. Best is trial 9 with value: 0.5927645986385751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.09950926640295592\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6961311078484091\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6678945615436545 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.09950926640295592\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6961311078484091\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6678945615436545 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.09950926640295592\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6961311078484091\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6678945615436545 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:19,029] Trial 14 finished with value: 0.5873440708257369 and parameters: {'num_leaves': 51, 'learning_rate': 0.00929176693711664, 'max_depth': 8, 'min_data_in_leaf': 21, 'subsample': 0.6678945615436545, 'feature_fraction': 0.5146859852246628, 'lambda_l1': 0.09950926640295592, 'lambda_l2': 0.0018937985888918144, 'n_estimators ': 200, 'bagging_fraction ': 0.6961311078484091, 'bagging_freq': 5, 'class_weight': 2.444235715440344}. Best is trial 9 with value: 0.5927645986385751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.04658782793322772\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8076152147886141\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5700474884086147 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.04658782793322772\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8076152147886141\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5700474884086147 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.04658782793322772\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8076152147886141\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5700474884086147 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:19,575] Trial 15 finished with value: 0.5894124585117821 and parameters: {'num_leaves': 74, 'learning_rate': 0.0038428072650902698, 'max_depth': 9, 'min_data_in_leaf': 16, 'subsample': 0.5700474884086147, 'feature_fraction': 0.7825374781251269, 'lambda_l1': 0.04658782793322772, 'lambda_l2': 1.1664490807228032e-05, 'n_estimators ': 100, 'bagging_fraction ': 0.8076152147886141, 'bagging_freq': 5, 'class_weight': 2.6926521491648248}. Best is trial 9 with value: 0.5927645986385751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 3.3438173325030363\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6523924631183077\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5054562392438865 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 3.3438173325030363\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6523924631183077\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5054562392438865 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 3.3438173325030363\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6523924631183077\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5054562392438865 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:20,014] Trial 16 finished with value: 0.593642368864868 and parameters: {'num_leaves': 47, 'learning_rate': 0.005393544784208034, 'max_depth': 10, 'min_data_in_leaf': 31, 'subsample': 0.5054562392438865, 'feature_fraction': 0.7676413290316153, 'lambda_l1': 3.3438173325030363, 'lambda_l2': 0.08478918378647908, 'n_estimators ': 200, 'bagging_fraction ': 0.6523924631183077, 'bagging_freq': 7, 'class_weight': 2.962648600589888}. Best is trial 16 with value: 0.593642368864868.\n",
      "[I 2023-07-05 16:25:20,227] Trial 17 finished with value: 0.5939555756928487 and parameters: {'num_leaves': 11, 'learning_rate': 0.005934264165199988, 'max_depth': 8, 'min_data_in_leaf': 31, 'subsample': 0.6590753872731892, 'feature_fraction': 0.7811822617934353, 'lambda_l1': 3.218639422912176e-07, 'lambda_l2': 0.14509593258908607, 'n_estimators ': 200, 'bagging_fraction ': 0.66260182098784, 'bagging_freq': 7, 'class_weight': 1.9827416379486862}. Best is trial 17 with value: 0.5939555756928487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 3.218639422912176e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.66260182098784\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6590753872731892 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 3.218639422912176e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.66260182098784\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6590753872731892 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 3.218639422912176e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.66260182098784\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6590753872731892 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:20,477] Trial 18 finished with value: 0.5903236710285482 and parameters: {'num_leaves': 10, 'learning_rate': 0.005857406704232283, 'max_depth': 8, 'min_data_in_leaf': 36, 'subsample': 0.7531120248696315, 'feature_fraction': 0.7805428028821502, 'lambda_l1': 0.028881212473132026, 'lambda_l2': 9.47135959792918, 'n_estimators ': 200, 'bagging_fraction ': 0.6718054583578354, 'bagging_freq': 8, 'class_weight': 1.956813461765983}. Best is trial 17 with value: 0.5939555756928487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.028881212473132026\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6718054583578354\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7531120248696315 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.028881212473132026\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6718054583578354\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7531120248696315 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.028881212473132026\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6718054583578354\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7531120248696315 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] Unknown parameter: 8.13508677684788\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6629459801827123\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6683187134707022 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 8.13508677684788\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6629459801827123\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6683187134707022 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 8.13508677684788\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6629459801827123\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6683187134707022 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:20,810] Trial 19 finished with value: 0.5887982710695421 and parameters: {'num_leaves': 47, 'learning_rate': 0.0030851443011974964, 'max_depth': 7, 'min_data_in_leaf': 61, 'subsample': 0.6683187134707022, 'feature_fraction': 0.6763673057922447, 'lambda_l1': 8.13508677684788, 'lambda_l2': 0.15588926910264939, 'n_estimators ': 200, 'bagging_fraction ': 0.6629459801827123, 'bagging_freq': 7, 'class_weight': 2.415698912457968}. Best is trial 17 with value: 0.5939555756928487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 5.364712557512859e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9954069826953904\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5459229957290186 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 5.364712557512859e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9954069826953904\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5459229957290186 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 5.364712557512859e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9954069826953904\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5459229957290186 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:21,233] Trial 20 finished with value: 0.589366070818545 and parameters: {'num_leaves': 55, 'learning_rate': 0.004939936494637522, 'max_depth': 9, 'min_data_in_leaf': 96, 'subsample': 0.5459229957290186, 'feature_fraction': 0.7998803868923013, 'lambda_l1': 5.364712557512859e-07, 'lambda_l2': 0.19347708736467617, 'n_estimators ': 300, 'bagging_fraction ': 0.9954069826953904, 'bagging_freq': 7, 'class_weight': 2.6204003289719533}. Best is trial 17 with value: 0.5939555756928487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 1.7425507065579013e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6267040122171144\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6243767489736773 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 1.7425507065579013e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6267040122171144\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6243767489736773 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 1.7425507065579013e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6267040122171144\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6243767489736773 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:21,572] Trial 21 finished with value: 0.5930026502116214 and parameters: {'num_leaves': 29, 'learning_rate': 0.007356830347000482, 'max_depth': 10, 'min_data_in_leaf': 31, 'subsample': 0.6243767489736773, 'feature_fraction': 0.874039617969272, 'lambda_l1': 1.7425507065579013e-08, 'lambda_l2': 0.0504742049508284, 'n_estimators ': 200, 'bagging_fraction ': 0.6267040122171144, 'bagging_freq': 4, 'class_weight': 2.231385255617941}. Best is trial 17 with value: 0.5939555756928487.\n",
      "[I 2023-07-05 16:25:21,786] Trial 22 finished with value: 0.5919195515137131 and parameters: {'num_leaves': 10, 'learning_rate': 0.006307237932291357, 'max_depth': 9, 'min_data_in_leaf': 36, 'subsample': 0.569145847464115, 'feature_fraction': 0.8868211075293304, 'lambda_l1': 1.366542612269931e-08, 'lambda_l2': 0.06648542094562489, 'n_estimators ': 200, 'bagging_fraction ': 0.6383053939862138, 'bagging_freq': 4, 'class_weight': 2.3546951280123793}. Best is trial 17 with value: 0.5939555756928487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 1.366542612269931e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6383053939862138\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.569145847464115 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.366542612269931e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6383053939862138\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.569145847464115 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 1.366542612269931e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6383053939862138\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.569145847464115 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] Unknown parameter: 5.491020622717279e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7127629006404274\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6456805273857484 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 5.491020622717279e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7127629006404274\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6456805273857484 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 5.491020622717279e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7127629006404274\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6456805273857484 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:22,153] Trial 23 finished with value: 0.5891956230154878 and parameters: {'num_leaves': 42, 'learning_rate': 0.00523626671151919, 'max_depth': 7, 'min_data_in_leaf': 16, 'subsample': 0.6456805273857484, 'feature_fraction': 0.7594209536937062, 'lambda_l1': 5.491020622717279e-07, 'lambda_l2': 0.5814302107169098, 'n_estimators ': 200, 'bagging_fraction ': 0.7127629006404274, 'bagging_freq': 3, 'class_weight': 1.9457195351687935}. Best is trial 17 with value: 0.5939555756928487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 8.743366827373136e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6488781114258201\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5493309317912674 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 8.743366827373136e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6488781114258201\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5493309317912674 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 8.743366827373136e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6488781114258201\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5493309317912674 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:22,439] Trial 24 finished with value: 0.5920831670208673 and parameters: {'num_leaves': 25, 'learning_rate': 0.009614903567713924, 'max_depth': 8, 'min_data_in_leaf': 26, 'subsample': 0.5493309317912674, 'feature_fraction': 0.8073756277803136, 'lambda_l1': 8.743366827373136e-05, 'lambda_l2': 0.021421314074643684, 'n_estimators ': 200, 'bagging_fraction ': 0.6488781114258201, 'bagging_freq': 8, 'class_weight': 2.7647124462200816}. Best is trial 17 with value: 0.5939555756928487.\n",
      "[I 2023-07-05 16:25:22,697] Trial 25 finished with value: 0.5935700903661032 and parameters: {'num_leaves': 15, 'learning_rate': 0.006467928960494477, 'max_depth': 9, 'min_data_in_leaf': 41, 'subsample': 0.5016830249259995, 'feature_fraction': 0.8812995904975249, 'lambda_l1': 5.732472423249548e-07, 'lambda_l2': 0.20032764276834122, 'n_estimators ': 300, 'bagging_fraction ': 0.7235680349361697, 'bagging_freq': 4, 'class_weight': 2.5599446514037174}. Best is trial 17 with value: 0.5939555756928487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 5.732472423249548e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7235680349361697\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5016830249259995 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 5.732472423249548e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7235680349361697\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5016830249259995 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 5.732472423249548e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7235680349361697\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5016830249259995 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:22,929] Trial 26 finished with value: 0.5901111506665084 and parameters: {'num_leaves': 15, 'learning_rate': 0.006292362256162445, 'max_depth': 9, 'min_data_in_leaf': 56, 'subsample': 0.5057999528640734, 'feature_fraction': 0.7563013822523956, 'lambda_l1': 4.1837939620527665e-05, 'lambda_l2': 5.560858753402187, 'n_estimators ': 300, 'bagging_fraction ': 0.721326258250017, 'bagging_freq': 2, 'class_weight': 2.9929689191663877}. Best is trial 17 with value: 0.5939555756928487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.721326258250017\n",
      "[LightGBM] [Warning] Unknown parameter: 4.1837939620527665e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5057999528640734 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.721326258250017\n",
      "[LightGBM] [Warning] Unknown parameter: 4.1837939620527665e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5057999528640734 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.721326258250017\n",
      "[LightGBM] [Warning] Unknown parameter: 4.1837939620527665e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5057999528640734 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:23,213] Trial 27 finished with value: 0.5925186359860621 and parameters: {'num_leaves': 24, 'learning_rate': 0.004573779941923955, 'max_depth': 7, 'min_data_in_leaf': 41, 'subsample': 0.5661773047129031, 'feature_fraction': 0.908930990592854, 'lambda_l1': 1.45583187197266e-06, 'lambda_l2': 0.3702467993985253, 'n_estimators ': 400, 'bagging_fraction ': 0.6771123010283764, 'bagging_freq': 7, 'class_weight': 2.5638279745225505}. Best is trial 17 with value: 0.5939555756928487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 1.45583187197266e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6771123010283764\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5661773047129031 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.45583187197266e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6771123010283764\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5661773047129031 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 1.45583187197266e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6771123010283764\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5661773047129031 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:23,466] Trial 28 finished with value: 0.5909576361694553 and parameters: {'num_leaves': 14, 'learning_rate': 0.003632826341339762, 'max_depth': 8, 'min_data_in_leaf': 41, 'subsample': 0.5395375194349245, 'feature_fraction': 0.8264412073008246, 'lambda_l1': 0.0007229871501455455, 'lambda_l2': 1.497958383079478, 'n_estimators ': 500, 'bagging_fraction ': 0.8094630589413525, 'bagging_freq': 9, 'class_weight': 2.568741765757939}. Best is trial 17 with value: 0.5939555756928487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.0007229871501455455\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8094630589413525\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5395375194349245 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0007229871501455455\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8094630589413525\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5395375194349245 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0007229871501455455\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8094630589413525\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5395375194349245 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:23,654] Trial 29 finished with value: 0.5776734953666246 and parameters: {'num_leaves': 37, 'learning_rate': 0.005290101853162196, 'max_depth': 2, 'min_data_in_leaf': 51, 'subsample': 0.5075704778016797, 'feature_fraction': 0.7803966277972004, 'lambda_l1': 0.0004426448570383209, 'lambda_l2': 0.2121161369646941, 'n_estimators ': 300, 'bagging_fraction ': 0.7226682380085659, 'bagging_freq': 6, 'class_weight': 2.4413818476004456}. Best is trial 17 with value: 0.5939555756928487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.0004426448570383209\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7226682380085659\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5075704778016797 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0004426448570383209\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7226682380085659\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5075704778016797 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0004426448570383209\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7226682380085659\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5075704778016797 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] Unknown parameter: 2.060632517247032e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6650816289454557\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5818220721069816 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 2.060632517247032e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6650816289454557\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5818220721069816 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 2.060632517247032e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6650816289454557\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5818220721069816 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:24,073] Trial 30 finished with value: 0.5883103013042493 and parameters: {'num_leaves': 65, 'learning_rate': 0.002723109255821557, 'max_depth': 6, 'min_data_in_leaf': 66, 'subsample': 0.5818220721069816, 'feature_fraction': 0.7070708298484553, 'lambda_l1': 2.060632517247032e-07, 'lambda_l2': 2.6119002694833595, 'n_estimators ': 300, 'bagging_fraction ': 0.6650816289454557, 'bagging_freq': 2, 'class_weight': 2.791496430825017}. Best is trial 17 with value: 0.5939555756928487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 1.285913362432602e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6363122330872386\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6439887938266213 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: 1.285913362432602e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6363122330872386\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6439887938266213 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001933 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 1.285913362432602e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6363122330872386\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6439887938266213 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:24,426] Trial 31 finished with value: 0.5933658406780514 and parameters: {'num_leaves': 31, 'learning_rate': 0.008043901585166843, 'max_depth': 10, 'min_data_in_leaf': 31, 'subsample': 0.6439887938266213, 'feature_fraction': 0.8695011517013345, 'lambda_l1': 1.285913362432602e-08, 'lambda_l2': 0.06954749461563886, 'n_estimators ': 200, 'bagging_fraction ': 0.6363122330872386, 'bagging_freq': 4, 'class_weight': 2.262062391964812}. Best is trial 17 with value: 0.5939555756928487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 5.763755854669987e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.592975175704298\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7115693831452921 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 5.763755854669987e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.592975175704298\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7115693831452921 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 5.763755854669987e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.592975175704298\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7115693831452921 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:24,836] Trial 32 finished with value: 0.5928214145729276 and parameters: {'num_leaves': 22, 'learning_rate': 0.008540367110935228, 'max_depth': 9, 'min_data_in_leaf': 41, 'subsample': 0.7115693831452921, 'feature_fraction': 0.8649393294063632, 'lambda_l1': 5.763755854669987e-08, 'lambda_l2': 0.645850034807836, 'n_estimators ': 200, 'bagging_fraction ': 0.592975175704298, 'bagging_freq': 4, 'class_weight': 2.2737026463869734}. Best is trial 17 with value: 0.5939555756928487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 2.3927494353641706e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6471915174174693\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6311678400128529 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 2.3927494353641706e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6471915174174693\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6311678400128529 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 2.3927494353641706e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6471915174174693\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6311678400128529 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:25,613] Trial 33 finished with value: 0.59217845956899 and parameters: {'num_leaves': 46, 'learning_rate': 0.008400972100115048, 'max_depth': 10, 'min_data_in_leaf': 26, 'subsample': 0.6311678400128529, 'feature_fraction': 0.9377061828038774, 'lambda_l1': 2.3927494353641706e-06, 'lambda_l2': 0.0962681325068494, 'n_estimators ': 400, 'bagging_fraction ': 0.6471915174174693, 'bagging_freq': 5, 'class_weight': 2.80715599591142}. Best is trial 17 with value: 0.5939555756928487.\n",
      "[I 2023-07-05 16:25:25,881] Trial 34 finished with value: 0.5906314839387108 and parameters: {'num_leaves': 15, 'learning_rate': 0.006558038877738676, 'max_depth': 9, 'min_data_in_leaf': 51, 'subsample': 0.5496180308177133, 'feature_fraction': 0.9553808813139747, 'lambda_l1': 1.3797095196122437e-08, 'lambda_l2': 0.015716704411869942, 'n_estimators ': 200, 'bagging_fraction ': 0.6979269715651024, 'bagging_freq': 3, 'class_weight': 2.6331303831873227}. Best is trial 17 with value: 0.5939555756928487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.6979269715651024\n",
      "[LightGBM] [Warning] Unknown parameter: 1.3797095196122437e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5496180308177133 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6979269715651024\n",
      "[LightGBM] [Warning] Unknown parameter: 1.3797095196122437e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5496180308177133 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6979269715651024\n",
      "[LightGBM] [Warning] Unknown parameter: 1.3797095196122437e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5496180308177133 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] Unknown parameter: 0.007999138419617862\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6043651773806988\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5861885244533606 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.007999138419617862\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6043651773806988\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5861885244533606 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.007999138419617862\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6043651773806988\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5861885244533606 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:26,476] Trial 35 finished with value: 0.587443318913593 and parameters: {'num_leaves': 53, 'learning_rate': 0.006959439437283954, 'max_depth': 10, 'min_data_in_leaf': 16, 'subsample': 0.5861885244533606, 'feature_fraction': 0.8636512221760165, 'lambda_l1': 0.007999138419617862, 'lambda_l2': 0.36548384504213105, 'n_estimators ': 200, 'bagging_fraction ': 0.6043651773806988, 'bagging_freq': 6, 'class_weight': 2.9995456963467326}. Best is trial 17 with value: 0.5939555756928487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 1.9608290405738962e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6503155586620849\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5007515213913336 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: 1.9608290405738962e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6503155586620849\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5007515213913336 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 1.9608290405738962e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6503155586620849\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5007515213913336 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:26,861] Trial 36 finished with value: 0.5924290969502789 and parameters: {'num_leaves': 31, 'learning_rate': 0.009847876212630759, 'max_depth': 8, 'min_data_in_leaf': 36, 'subsample': 0.5007515213913336, 'feature_fraction': 0.895590150489662, 'lambda_l1': 1.9608290405738962e-07, 'lambda_l2': 0.10348582944735342, 'n_estimators ': 300, 'bagging_fraction ': 0.6503155586620849, 'bagging_freq': 10, 'class_weight': 1.866040134214499}. Best is trial 17 with value: 0.5939555756928487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.00022246310683143283\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5770132702654345\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.606084847658942 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.00022246310683143283\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5770132702654345\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.606084847658942 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.00022246310683143283\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5770132702654345\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.606084847658942 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:27,229] Trial 37 finished with value: 0.5909015394241454 and parameters: {'num_leaves': 36, 'learning_rate': 0.005774799314851234, 'max_depth': 9, 'min_data_in_leaf': 46, 'subsample': 0.606084847658942, 'feature_fraction': 0.9024987359202097, 'lambda_l1': 0.00022246310683143283, 'lambda_l2': 2.1921421662025558, 'n_estimators ': 300, 'bagging_fraction ': 0.5770132702654345, 'bagging_freq': 2, 'class_weight': 2.0990438584856377}. Best is trial 17 with value: 0.5939555756928487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 4.230399144284714e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7391065368942341\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6395765970504194 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 4.230399144284714e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7391065368942341\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6395765970504194 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 4.230399144284714e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7391065368942341\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6395765970504194 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:27,621] Trial 38 finished with value: 0.591274079348127 and parameters: {'num_leaves': 19, 'learning_rate': 0.008294784325264752, 'max_depth': 7, 'min_data_in_leaf': 26, 'subsample': 0.6395765970504194, 'feature_fraction': 0.8134673315594804, 'lambda_l1': 4.230399144284714e-08, 'lambda_l2': 0.014123337855363398, 'n_estimators ': 200, 'bagging_fraction ': 0.7391065368942341, 'bagging_freq': 4, 'class_weight': 2.698906135274777}. Best is trial 17 with value: 0.5939555756928487.\n",
      "[I 2023-07-05 16:25:27,875] Trial 39 finished with value: 0.5906174597523832 and parameters: {'num_leaves': 15, 'learning_rate': 0.006817758754821204, 'max_depth': 10, 'min_data_in_leaf': 56, 'subsample': 0.531846750462942, 'feature_fraction': 0.8498373002646173, 'lambda_l1': 2.107800160055011e-05, 'lambda_l2': 0.0548377664296889, 'n_estimators ': 400, 'bagging_fraction ': 0.6924191259741174, 'bagging_freq': 8, 'class_weight': 1.650650751145227}. Best is trial 17 with value: 0.5939555756928487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 2.107800160055011e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6924191259741174\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.531846750462942 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 2.107800160055011e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6924191259741174\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.531846750462942 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 2.107800160055011e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6924191259741174\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.531846750462942 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] Unknown parameter: 0.003277700786128712\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6263569765571394\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5988537100736466 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.003277700786128712\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6263569765571394\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5988537100736466 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.003277700786128712\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6263569765571394\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5988537100736466 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:28,390] Trial 40 finished with value: 0.5854249148659971 and parameters: {'num_leaves': 44, 'learning_rate': 0.0061285855494647105, 'max_depth': 8, 'min_data_in_leaf': 11, 'subsample': 0.5988537100736466, 'feature_fraction': 0.9391869836863279, 'lambda_l1': 0.003277700786128712, 'lambda_l2': 1.159775238409006, 'n_estimators ': 200, 'bagging_fraction ': 0.6263569765571394, 'bagging_freq': 3, 'class_weight': 2.348647319964064}. Best is trial 17 with value: 0.5939555756928487.\n",
      "[I 2023-07-05 16:25:28,684] Trial 41 finished with value: 0.5933162166341234 and parameters: {'num_leaves': 27, 'learning_rate': 0.007455269886198375, 'max_depth': 10, 'min_data_in_leaf': 31, 'subsample': 0.6301187587375265, 'feature_fraction': 0.8742187271707075, 'lambda_l1': 1.0562615838503676e-08, 'lambda_l2': 0.054119655735630955, 'n_estimators ': 200, 'bagging_fraction ': 0.6304317755289245, 'bagging_freq': 4, 'class_weight': 2.165800813323613}. Best is trial 17 with value: 0.5939555756928487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 1.0562615838503676e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6304317755289245\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6301187587375265 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.0562615838503676e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6304317755289245\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6301187587375265 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 1.0562615838503676e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6304317755289245\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6301187587375265 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] Unknown parameter: 1.172080731192739e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6110527500927825\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7010630656035378 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.172080731192739e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6110527500927825\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7010630656035378 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 1.172080731192739e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6110527500927825\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7010630656035378 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:29,061] Trial 42 finished with value: 0.5931299466721325 and parameters: {'num_leaves': 28, 'learning_rate': 0.0076400652642817845, 'max_depth': 10, 'min_data_in_leaf': 31, 'subsample': 0.7010630656035378, 'feature_fraction': 0.8319684990644527, 'lambda_l1': 1.172080731192739e-08, 'lambda_l2': 0.1711468953678426, 'n_estimators ': 200, 'bagging_fraction ': 0.6110527500927825, 'bagging_freq': 5, 'class_weight': 2.2295375328831177}. Best is trial 17 with value: 0.5939555756928487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 9.103020940925136e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6697659036581038\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6168938998696334 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 9.103020940925136e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6697659036581038\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6168938998696334 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 9.103020940925136e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6697659036581038\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6168938998696334 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:29,395] Trial 43 finished with value: 0.5908012125527256 and parameters: {'num_leaves': 21, 'learning_rate': 0.006960635647209789, 'max_depth': 10, 'min_data_in_leaf': 46, 'subsample': 0.6168938998696334, 'feature_fraction': 0.8864067506509774, 'lambda_l1': 9.103020940925136e-08, 'lambda_l2': 0.008180430405785198, 'n_estimators ': 100, 'bagging_fraction ': 0.6697659036581038, 'bagging_freq': 4, 'class_weight': 2.053351090863133}. Best is trial 17 with value: 0.5939555756928487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 3.50459702296456e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5491573682088174\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6529965363200355 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 3.50459702296456e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5491573682088174\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6529965363200355 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 3.50459702296456e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5491573682088174\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6529965363200355 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:29,713] Trial 44 finished with value: 0.5924895088298434 and parameters: {'num_leaves': 35, 'learning_rate': 0.008469872084842756, 'max_depth': 9, 'min_data_in_leaf': 36, 'subsample': 0.6529965363200355, 'feature_fraction': 0.9217159842137481, 'lambda_l1': 3.50459702296456e-08, 'lambda_l2': 0.0019026769476001514, 'n_estimators ': 300, 'bagging_fraction ': 0.5491573682088174, 'bagging_freq': 7, 'class_weight': 2.205502122449414}. Best is trial 17 with value: 0.5939555756928487.\n",
      "[I 2023-07-05 16:25:29,954] Trial 45 finished with value: 0.5909461291447764 and parameters: {'num_leaves': 12, 'learning_rate': 0.005587025334971266, 'max_depth': 10, 'min_data_in_leaf': 21, 'subsample': 0.6941286062141837, 'feature_fraction': 0.9904075025497413, 'lambda_l1': 6.507156587843963e-06, 'lambda_l2': 0.05012556294164219, 'n_estimators ': 100, 'bagging_fraction ': 0.6350799591780466, 'bagging_freq': 6, 'class_weight': 2.0218950452575233}. Best is trial 17 with value: 0.5939555756928487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 6.507156587843963e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6350799591780466\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6941286062141837 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 6.507156587843963e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6350799591780466\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6941286062141837 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000794 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 6.507156587843963e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6350799591780466\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6941286062141837 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:30,214] Trial 46 finished with value: 0.5917224937160858 and parameters: {'num_leaves': 18, 'learning_rate': 0.004949829272628191, 'max_depth': 9, 'min_data_in_leaf': 26, 'subsample': 0.734678054878832, 'feature_fraction': 0.847994878122052, 'lambda_l1': 1.0636964401135074e-07, 'lambda_l2': 0.5291801749471483, 'n_estimators ': 300, 'bagging_fraction ': 0.59902412741404, 'bagging_freq': 5, 'class_weight': 2.1620518666539907}. Best is trial 17 with value: 0.5939555756928487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 1.0636964401135074e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.59902412741404\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.734678054878832 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.0636964401135074e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.59902412741404\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.734678054878832 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 1.0636964401135074e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.59902412741404\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.734678054878832 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:30,481] Trial 47 finished with value: 0.5905358317960667 and parameters: {'num_leaves': 25, 'learning_rate': 0.007097611660159479, 'max_depth': 6, 'min_data_in_leaf': 41, 'subsample': 0.6827381698961514, 'feature_fraction': 0.8695735050708275, 'lambda_l1': 0.0015848188368457374, 'lambda_l2': 0.008914142750405026, 'n_estimators ': 100, 'bagging_fraction ': 0.5802898209642825, 'bagging_freq': 9, 'class_weight': 2.517048167928179}. Best is trial 17 with value: 0.5939555756928487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.0015848188368457374\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5802898209642825\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6827381698961514 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0015848188368457374\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5802898209642825\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6827381698961514 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0015848188368457374\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5802898209642825\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6827381698961514 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] Unknown parameter: 2.862529316733801e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.680877149288875\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.655755991860866 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 2.862529316733801e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.680877149288875\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.655755991860866 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 2.862529316733801e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.680877149288875\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.655755991860866 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:25:30,835] Trial 48 finished with value: 0.5954198445832479 and parameters: {'num_leaves': 39, 'learning_rate': 0.006227028830888428, 'max_depth': 10, 'min_data_in_leaf': 31, 'subsample': 0.655755991860866, 'feature_fraction': 0.8216872417725498, 'lambda_l1': 2.862529316733801e-08, 'lambda_l2': 0.030603706906218907, 'n_estimators ': 200, 'bagging_fraction ': 0.680877149288875, 'bagging_freq': 4, 'class_weight': 2.097265819752266}. Best is trial 48 with value: 0.5954198445832479.\n",
      "[I 2023-07-05 16:25:31,073] Trial 49 finished with value: 0.591097518438209 and parameters: {'num_leaves': 39, 'learning_rate': 0.006195398609195893, 'max_depth': 4, 'min_data_in_leaf': 21, 'subsample': 0.6651076247967264, 'feature_fraction': 0.8203607224151932, 'lambda_l1': 3.785395713256073e-07, 'lambda_l2': 0.025850890817774766, 'n_estimators ': 200, 'bagging_fraction ': 0.7090198704827819, 'bagging_freq': 3, 'class_weight': 2.0829482589281416}. Best is trial 48 with value: 0.5954198445832479.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 3.785395713256073e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7090198704827819\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6651076247967264 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 3.785395713256073e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7090198704827819\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6651076247967264 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 3.785395713256073e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7090198704827819\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6651076247967264 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "best_params = study.best_params\n",
    "best_score = study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0ea94f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best parameters are:  {'num_leaves': 39, 'learning_rate': 0.006227028830888428, 'max_depth': 10, 'min_data_in_leaf': 31, 'subsample': 0.655755991860866, 'feature_fraction': 0.8216872417725498, 'lambda_l1': 2.862529316733801e-08, 'lambda_l2': 0.030603706906218907, 'n_estimators ': 200, 'bagging_fraction ': 0.680877149288875, 'bagging_freq': 4, 'class_weight': 2.097265819752266}\n",
      "The best score is:  0.5954198445832479\n"
     ]
    }
   ],
   "source": [
    "print('the best parameters are: ', best_params)\n",
    "print('The best score is: ', best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac80df8",
   "metadata": {},
   "source": [
    "Past parameters:\n",
    "- the best parameters are:  {'num_leaves': 30, 'learning_rate': 0.09786548967700766, 'max_depth': 4, 'min_data_in_leaf': 1, 'subsample': 0.5124095803194548, 'feature_fraction': 0.853953700500865, 'lambda_l1': 4.214458221798507e-08, 'lambda_l2': 7.479331373474433e-08, 'n_estimators ': 300, 'bagging_fraction ': 0.7924084423072477, 'bagging_freq': 7, 'class_weight': 2.4216495124985684}|The best score is:  0.5959822504144328"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "786bfe89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.680877149288875\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.655755991860866 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.680877149288875\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.655755991860866 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6241\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 31\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.680877149288875\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.655755991860866 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.797810\n",
      "Train Accuracy score is: 0.797809604043808\n",
      "Test Accuracy score is: 0.8035714285714286\n",
      "ROCAUC score is: 0.5941497567343064\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       583\n",
      "           1       0.80      1.00      0.89      2385\n",
      "\n",
      "    accuracy                           0.80      2968\n",
      "   macro avg       0.40      0.50      0.45      2968\n",
      "weighted avg       0.65      0.80      0.72      2968\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = lgb.Dataset(X_train, label=y_train)\n",
    "val = lgb.Dataset(X_val, label=y_val)\n",
    "model2 = lgb.train(best_params, train, valid_sets=val, early_stopping_rounds=100, verbose_eval=False)\n",
    "\n",
    "evaluate_lgbm(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8a34f6",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9095c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4a6137c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define the search space for XGBoost parameters\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'booster': 'gbtree',\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 10),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.01),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
    "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1.0, 2.5),  \n",
    "    }\n",
    "\n",
    "    # Train and evaluate the XGBoost model\n",
    "    model = xgb.XGBClassifier(**params, random_state=5)\n",
    "    model.fit(X_train, y_train)\n",
    "    pos_probs = model.predict_proba(X_val)[:, 1]\n",
    "    score = roc_auc_score(y_val, pos_probs)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ea6260cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:35:50,830] A new study created in memory with name: no-name-b1089ca6-f328-49b9-a669-be0eedf2e289\n",
      "[I 2023-07-05 16:35:52,650] Trial 0 finished with value: 0.5833421433991031 and parameters: {'max_depth': 10, 'learning_rate': 0.002022453786040902, 'subsample': 0.5732845882099673, 'colsample_bytree': 0.8497160019574542, 'lambda': 5.501099894234255e-05, 'alpha': 0.00023019814194361198, 'scale_pos_weight': 2.3193029604316706}. Best is trial 0 with value: 0.5833421433991031.\n",
      "[I 2023-07-05 16:35:53,877] Trial 1 finished with value: 0.5898691435537288 and parameters: {'max_depth': 9, 'learning_rate': 0.0016524910826948456, 'subsample': 0.7939441472367768, 'colsample_bytree': 0.5560028493441742, 'lambda': 0.0002793818974188376, 'alpha': 0.0012216403275692733, 'scale_pos_weight': 1.122340727754433}. Best is trial 1 with value: 0.5898691435537288.\n",
      "[I 2023-07-05 16:35:54,495] Trial 2 finished with value: 0.5832508063907138 and parameters: {'max_depth': 4, 'learning_rate': 0.003207479303700463, 'subsample': 0.8293730879975783, 'colsample_bytree': 0.862134467684839, 'lambda': 0.9872986328978384, 'alpha': 6.324330853407581e-05, 'scale_pos_weight': 1.8425268836512223}. Best is trial 1 with value: 0.5898691435537288.\n",
      "[I 2023-07-05 16:35:54,882] Trial 3 finished with value: 0.5798245897925499 and parameters: {'max_depth': 3, 'learning_rate': 0.0017924575784123084, 'subsample': 0.9650787519651876, 'colsample_bytree': 0.5961628322981696, 'lambda': 6.028013748320501e-08, 'alpha': 0.0002315606638458472, 'scale_pos_weight': 1.672214617406072}. Best is trial 1 with value: 0.5898691435537288.\n",
      "[I 2023-07-05 16:35:55,475] Trial 4 finished with value: 0.5862347217277798 and parameters: {'max_depth': 4, 'learning_rate': 0.0016114966961557227, 'subsample': 0.5458363870493079, 'colsample_bytree': 0.6997855883565718, 'lambda': 0.5451937169969516, 'alpha': 0.043659317591401944, 'scale_pos_weight': 1.0138114089839454}. Best is trial 1 with value: 0.5898691435537288.\n",
      "[I 2023-07-05 16:35:56,190] Trial 5 finished with value: 0.5855730678087389 and parameters: {'max_depth': 5, 'learning_rate': 0.008227030953482664, 'subsample': 0.9059178544143176, 'colsample_bytree': 0.736531619331511, 'lambda': 0.00694795652618261, 'alpha': 0.00011896623459184335, 'scale_pos_weight': 1.0869080131916764}. Best is trial 1 with value: 0.5898691435537288.\n",
      "[I 2023-07-05 16:35:57,289] Trial 6 finished with value: 0.5893966363528486 and parameters: {'max_depth': 7, 'learning_rate': 0.003574344991962336, 'subsample': 0.7267547607231675, 'colsample_bytree': 0.7463971700496836, 'lambda': 6.141269086934829e-07, 'alpha': 0.0002511201800502065, 'scale_pos_weight': 1.5871959825267348}. Best is trial 1 with value: 0.5898691435537288.\n",
      "[I 2023-07-05 16:35:58,970] Trial 7 finished with value: 0.5846647320481425 and parameters: {'max_depth': 9, 'learning_rate': 0.00101373487656496, 'subsample': 0.5989951072853421, 'colsample_bytree': 0.9083090309855253, 'lambda': 1.0606314135885278e-06, 'alpha': 3.178513134941024e-06, 'scale_pos_weight': 1.860758417472084}. Best is trial 1 with value: 0.5898691435537288.\n",
      "[I 2023-07-05 16:35:59,289] Trial 8 finished with value: 0.5766177258523288 and parameters: {'max_depth': 2, 'learning_rate': 0.0022203266892712064, 'subsample': 0.9192484177045829, 'colsample_bytree': 0.636137534808236, 'lambda': 2.1805799410410894e-08, 'alpha': 3.052520261451713e-07, 'scale_pos_weight': 1.2615454603079876}. Best is trial 1 with value: 0.5898691435537288.\n",
      "[I 2023-07-05 16:35:59,762] Trial 9 finished with value: 0.5769356074090856 and parameters: {'max_depth': 3, 'learning_rate': 0.0012806379032670621, 'subsample': 0.9480424369164352, 'colsample_bytree': 0.785471380208247, 'lambda': 0.0009278123531068997, 'alpha': 1.9269028314248605e-05, 'scale_pos_weight': 1.476500017772407}. Best is trial 1 with value: 0.5898691435537288.\n",
      "[I 2023-07-05 16:36:00,636] Trial 10 finished with value: 0.5859502824614964 and parameters: {'max_depth': 7, 'learning_rate': 0.00452051842425387, 'subsample': 0.7309245208539141, 'colsample_bytree': 0.5035399548215872, 'lambda': 3.1756731562708366e-05, 'alpha': 0.8291411296561626, 'scale_pos_weight': 1.3251576164688101}. Best is trial 1 with value: 0.5898691435537288.\n",
      "[I 2023-07-05 16:36:01,911] Trial 11 finished with value: 0.590552732738564 and parameters: {'max_depth': 7, 'learning_rate': 0.003178636861351332, 'subsample': 0.7263747733517797, 'colsample_bytree': 0.9472242276626288, 'lambda': 1.72697645036829e-06, 'alpha': 1.2654436885312775e-08, 'scale_pos_weight': 1.524109032015563}. Best is trial 11 with value: 0.590552732738564.\n",
      "[I 2023-07-05 16:36:03,512] Trial 12 finished with value: 0.5811802611375414 and parameters: {'max_depth': 8, 'learning_rate': 0.0026365583587109162, 'subsample': 0.7938292964237285, 'colsample_bytree': 0.9859663077610761, 'lambda': 5.938793488692418e-06, 'alpha': 4.9039426212002186e-08, 'scale_pos_weight': 1.2754153910949626}. Best is trial 11 with value: 0.590552732738564.\n",
      "[I 2023-07-05 16:36:05,677] Trial 13 finished with value: 0.5794243610904344 and parameters: {'max_depth': 10, 'learning_rate': 0.004453324863861013, 'subsample': 0.6523438782841278, 'colsample_bytree': 0.9814407535806687, 'lambda': 0.0007123634654253821, 'alpha': 1.1277705303707482e-07, 'scale_pos_weight': 1.015891549238572}. Best is trial 11 with value: 0.590552732738564.\n",
      "[I 2023-07-05 16:36:06,755] Trial 14 finished with value: 0.5908127195774046 and parameters: {'max_depth': 8, 'learning_rate': 0.0014662346124954824, 'subsample': 0.6555277371967088, 'colsample_bytree': 0.5470785706511594, 'lambda': 3.9679450329936785e-06, 'alpha': 2.227519794750774e-08, 'scale_pos_weight': 1.4549943998278425}. Best is trial 14 with value: 0.5908127195774046.\n",
      "[I 2023-07-05 16:36:07,786] Trial 15 finished with value: 0.5866590432628169 and parameters: {'max_depth': 6, 'learning_rate': 0.0025237278178009115, 'subsample': 0.676340154316321, 'colsample_bytree': 0.6749876927900655, 'lambda': 4.7306638197354504e-07, 'alpha': 1.561633139786074e-08, 'scale_pos_weight': 1.4819950011185175}. Best is trial 14 with value: 0.5908127195774046.\n",
      "[I 2023-07-05 16:36:08,905] Trial 16 finished with value: 0.5924086000625695 and parameters: {'max_depth': 7, 'learning_rate': 0.001249794734181726, 'subsample': 0.5067060086754951, 'colsample_bytree': 0.6416136628739622, 'lambda': 3.594188172003599e-06, 'alpha': 1.840144470775147e-08, 'scale_pos_weight': 1.8085194781924112}. Best is trial 16 with value: 0.5924086000625695.\n",
      "[I 2023-07-05 16:36:10,033] Trial 17 finished with value: 0.5925527974655778 and parameters: {'max_depth': 8, 'learning_rate': 0.0010198107327323133, 'subsample': 0.5077619186446125, 'colsample_bytree': 0.605632899712089, 'lambda': 1.296648061490611e-05, 'alpha': 4.2932538528035216e-07, 'scale_pos_weight': 2.0018883603520674}. Best is trial 17 with value: 0.5925527974655778.\n",
      "[I 2023-07-05 16:36:10,903] Trial 18 finished with value: 0.5868183436357164 and parameters: {'max_depth': 6, 'learning_rate': 0.001055112110601016, 'subsample': 0.5284432297307915, 'colsample_bytree': 0.6220591187925998, 'lambda': 1.4173565417509966e-07, 'alpha': 7.520328663587013e-07, 'scale_pos_weight': 2.0325450177860804}. Best is trial 17 with value: 0.5925527974655778.\n",
      "[I 2023-07-05 16:36:12,085] Trial 19 finished with value: 0.5923478285884836 and parameters: {'max_depth': 8, 'learning_rate': 0.0012615384535802708, 'subsample': 0.508195773717273, 'colsample_bytree': 0.6656325542462008, 'lambda': 2.1435884268556867e-05, 'alpha': 5.22176289132969e-07, 'scale_pos_weight': 2.0797875610238457}. Best is trial 17 with value: 0.5925527974655778.\n",
      "[I 2023-07-05 16:36:12,821] Trial 20 finished with value: 0.5832903617880478 and parameters: {'max_depth': 5, 'learning_rate': 0.0012524795277232509, 'subsample': 0.5028490147440202, 'colsample_bytree': 0.5772521510970273, 'lambda': 6.41417293960172e-06, 'alpha': 4.518166244773372e-06, 'scale_pos_weight': 2.3892028455572447}. Best is trial 17 with value: 0.5925527974655778.\n",
      "[I 2023-07-05 16:36:13,998] Trial 21 finished with value: 0.5896005264463791 and parameters: {'max_depth': 8, 'learning_rate': 0.0012346150583758115, 'subsample': 0.50155317008969, 'colsample_bytree': 0.6655367122033192, 'lambda': 2.2767871844847995e-05, 'alpha': 2.6154484296972206e-07, 'scale_pos_weight': 2.06178012091221}. Best is trial 17 with value: 0.5925527974655778.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:36:15,332] Trial 22 finished with value: 0.5988392288855088 and parameters: {'max_depth': 9, 'learning_rate': 0.001011958075939031, 'subsample': 0.5851516701668487, 'colsample_bytree': 0.6314593218425315, 'lambda': 1.5694634001169536e-05, 'alpha': 1.1234862322248062e-07, 'scale_pos_weight': 2.0632639671902515}. Best is trial 22 with value: 0.5988392288855088.\n",
      "[I 2023-07-05 16:36:16,681] Trial 23 finished with value: 0.5948358630807902 and parameters: {'max_depth': 9, 'learning_rate': 0.001009323522176334, 'subsample': 0.5816683609859139, 'colsample_bytree': 0.609680245305213, 'lambda': 1.005980454812338e-08, 'alpha': 4.767146989076207e-08, 'scale_pos_weight': 1.789618879053206}. Best is trial 22 with value: 0.5988392288855088.\n",
      "[I 2023-07-05 16:36:18,251] Trial 24 finished with value: 0.5969305011668843 and parameters: {'max_depth': 9, 'learning_rate': 0.0010753055910071732, 'subsample': 0.594271476462312, 'colsample_bytree': 0.5999486713288357, 'lambda': 2.063660199130312e-08, 'alpha': 1.1104964236657137e-07, 'scale_pos_weight': 1.9019181271170325}. Best is trial 22 with value: 0.5988392288855088.\n",
      "[I 2023-07-05 16:36:19,552] Trial 25 finished with value: 0.5973310894635209 and parameters: {'max_depth': 9, 'learning_rate': 0.0010011272698780638, 'subsample': 0.6007783889625506, 'colsample_bytree': 0.5210748870341725, 'lambda': 1.6171609509345785e-08, 'alpha': 8.967507852636067e-08, 'scale_pos_weight': 1.7173959552469125}. Best is trial 22 with value: 0.5988392288855088.\n",
      "[I 2023-07-05 16:36:21,199] Trial 26 finished with value: 0.59376103505687 and parameters: {'max_depth': 10, 'learning_rate': 0.001504468720061612, 'subsample': 0.6177081874454119, 'colsample_bytree': 0.5081870080480586, 'lambda': 1.2392030534061657e-07, 'alpha': 8.433784099922147e-08, 'scale_pos_weight': 1.6785284344068427}. Best is trial 22 with value: 0.5988392288855088.\n",
      "[I 2023-07-05 16:36:22,615] Trial 27 finished with value: 0.5920490055413515 and parameters: {'max_depth': 9, 'learning_rate': 0.0018595306622494747, 'subsample': 0.6147947979476011, 'colsample_bytree': 0.5407827083557618, 'lambda': 1.0934888467768706e-08, 'alpha': 1.2799736179984976e-06, 'scale_pos_weight': 2.2048727992137303}. Best is trial 22 with value: 0.5988392288855088.\n",
      "[I 2023-07-05 16:36:24,422] Trial 28 finished with value: 0.5927671158002237 and parameters: {'max_depth': 10, 'learning_rate': 0.0014369673507324046, 'subsample': 0.5781815847745828, 'colsample_bytree': 0.5637850923104788, 'lambda': 3.378376239412893e-08, 'alpha': 1.1313350569434331e-07, 'scale_pos_weight': 1.9243476275688651}. Best is trial 22 with value: 0.5988392288855088.\n",
      "[I 2023-07-05 16:36:25,903] Trial 29 finished with value: 0.5995325271224168 and parameters: {'max_depth': 9, 'learning_rate': 0.002000999545978187, 'subsample': 0.5545565992414124, 'colsample_bytree': 0.5762594472848954, 'lambda': 9.902703489831188e-08, 'alpha': 2.54471854674416e-06, 'scale_pos_weight': 2.1923293222840936}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:36:27,547] Trial 30 finished with value: 0.591661722242 and parameters: {'max_depth': 10, 'learning_rate': 0.0020039761272685154, 'subsample': 0.5516640652814042, 'colsample_bytree': 0.5296452668341691, 'lambda': 2.2468651451804942e-07, 'alpha': 3.410095792535361e-06, 'scale_pos_weight': 2.2565413556859832}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:36:28,980] Trial 31 finished with value: 0.5928998061785531 and parameters: {'max_depth': 9, 'learning_rate': 0.0011522385719058667, 'subsample': 0.5591968154772341, 'colsample_bytree': 0.5823060730208409, 'lambda': 4.3980469293085326e-08, 'alpha': 1.294448785050138e-06, 'scale_pos_weight': 2.172998327440926}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:36:30,334] Trial 32 finished with value: 0.5957330514112287 and parameters: {'max_depth': 9, 'learning_rate': 0.0014460410847181937, 'subsample': 0.585336027791491, 'colsample_bytree': 0.5575510908140014, 'lambda': 2.2339438198064178e-07, 'alpha': 2.0055076723914904e-07, 'scale_pos_weight': 2.490149102070899}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:36:31,763] Trial 33 finished with value: 0.5938793416543505 and parameters: {'max_depth': 9, 'learning_rate': 0.0016866854203951502, 'subsample': 0.6179006798693144, 'colsample_bytree': 0.579514989677552, 'lambda': 3.80389256883201e-08, 'alpha': 6.125735148992284e-08, 'scale_pos_weight': 1.941609896098199}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:36:33,211] Trial 34 finished with value: 0.5918030428888386 and parameters: {'max_depth': 10, 'learning_rate': 0.001140617043671666, 'subsample': 0.560432947313884, 'colsample_bytree': 0.529787847239275, 'lambda': 7.513902946406825e-08, 'alpha': 2.076507539700846e-07, 'scale_pos_weight': 2.1082037156308724}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:36:34,335] Trial 35 finished with value: 0.5919547917767924 and parameters: {'max_depth': 8, 'learning_rate': 0.0013893831029108351, 'subsample': 0.5406799539150565, 'colsample_bytree': 0.6047924361797739, 'lambda': 5.648991697200494e-07, 'alpha': 1.1237193073754895e-05, 'scale_pos_weight': 1.7172733564711948}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:36:35,701] Trial 36 finished with value: 0.5912765965097756 and parameters: {'max_depth': 9, 'learning_rate': 0.0016912568336391123, 'subsample': 0.6401572752820065, 'colsample_bytree': 0.5809977088598771, 'lambda': 1.4722541636395115e-08, 'alpha': 6.46348812727637e-07, 'scale_pos_weight': 1.9443614286479287}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:36:37,398] Trial 37 finished with value: 0.5916325950857813 and parameters: {'max_depth': 10, 'learning_rate': 0.0011204485661292123, 'subsample': 0.5958441209668682, 'colsample_bytree': 0.6379991241705177, 'lambda': 7.09758059107708e-08, 'alpha': 3.6164817951539076e-08, 'scale_pos_weight': 2.311581011012019}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:36:38,232] Trial 38 finished with value: 0.5913355700112553 and parameters: {'max_depth': 6, 'learning_rate': 0.00160888407689417, 'subsample': 0.5348446611905021, 'colsample_bytree': 0.5268275681063742, 'lambda': 3.535550106604244e-07, 'alpha': 1.2297978989431018e-06, 'scale_pos_weight': 1.8536149251080078}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:36:39,634] Trial 39 finished with value: 0.5941519143014337 and parameters: {'max_depth': 9, 'learning_rate': 0.0011341842523348595, 'subsample': 0.687370750014546, 'colsample_bytree': 0.5572035941456199, 'lambda': 1.3632520510038544e-06, 'alpha': 1.0209179002790884e-08, 'scale_pos_weight': 1.7524157888849123}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:36:40,790] Trial 40 finished with value: 0.5904797350507568 and parameters: {'max_depth': 7, 'learning_rate': 0.0010062274375983, 'subsample': 0.5714239270483477, 'colsample_bytree': 0.5986405566915426, 'lambda': 3.004973833116345e-08, 'alpha': 1.314748731001197e-07, 'scale_pos_weight': 2.137381022463572}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:36:42,058] Trial 41 finished with value: 0.5877590429032223 and parameters: {'max_depth': 9, 'learning_rate': 0.0013950146067652465, 'subsample': 0.5927735510226051, 'colsample_bytree': 0.5522661029210828, 'lambda': 1.9675941989922183e-07, 'alpha': 2.2385999554514363e-07, 'scale_pos_weight': 2.479357867881352}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:36:43,080] Trial 42 finished with value: 0.5951767586869047 and parameters: {'max_depth': 8, 'learning_rate': 0.0014101803253436327, 'subsample': 0.6216620399739802, 'colsample_bytree': 0.5073012469932032, 'lambda': 8.070383508918875e-08, 'alpha': 5.5048693515435725e-08, 'scale_pos_weight': 2.2093233464724213}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:36:44,338] Trial 43 finished with value: 0.5921040235030979 and parameters: {'max_depth': 9, 'learning_rate': 0.001143819730163784, 'subsample': 0.5940792762045226, 'colsample_bytree': 0.5642204313315704, 'lambda': 2.3843588575151406e-07, 'alpha': 2.4555657777297453e-07, 'scale_pos_weight': 2.3327071376661888}. Best is trial 29 with value: 0.5995325271224168.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:36:45,856] Trial 44 finished with value: 0.5929526665731721 and parameters: {'max_depth': 10, 'learning_rate': 0.0013129795095316976, 'subsample': 0.5699234179506002, 'colsample_bytree': 0.6260109349747881, 'lambda': 2.1349188806511416e-08, 'alpha': 3.1919759037156414e-08, 'scale_pos_weight': 2.4781808497990134}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:36:47,140] Trial 45 finished with value: 0.5866975198765871 and parameters: {'max_depth': 8, 'learning_rate': 0.001559539623563403, 'subsample': 0.6375385849753298, 'colsample_bytree': 0.7141378848194221, 'lambda': 9.86023738943164e-07, 'alpha': 1.1274276464212386e-07, 'scale_pos_weight': 2.0105845872253094}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:36:48,476] Trial 46 finished with value: 0.5903517194012031 and parameters: {'max_depth': 9, 'learning_rate': 0.0019450015581645042, 'subsample': 0.5350252974894072, 'colsample_bytree': 0.5878334802018523, 'lambda': 8.107595036107174e-08, 'alpha': 1.9004976811152335e-06, 'scale_pos_weight': 2.1311653174130836}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:36:50,171] Trial 47 finished with value: 0.5950465854702238 and parameters: {'max_depth': 10, 'learning_rate': 0.0017708094452637687, 'subsample': 0.595628990372777, 'colsample_bytree': 0.5004237530176177, 'lambda': 8.195937745734437e-05, 'alpha': 4.332008283967916e-07, 'scale_pos_weight': 1.9044107017478262}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:36:50,606] Trial 48 finished with value: 0.574935902276593 and parameters: {'max_depth': 2, 'learning_rate': 0.0015454389022786401, 'subsample': 0.5560326859729229, 'colsample_bytree': 0.5411288711124812, 'lambda': 5.862452134576577e-07, 'alpha': 8.674538830546176e-06, 'scale_pos_weight': 1.8619841830939394}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:36:51,681] Trial 49 finished with value: 0.5901507060638425 and parameters: {'max_depth': 7, 'learning_rate': 0.001343849117505221, 'subsample': 0.6720721574846777, 'colsample_bytree': 0.5673862537229486, 'lambda': 1.9465184190580006e-08, 'alpha': 3.5448421242356274e-05, 'scale_pos_weight': 1.6451006265498431}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:36:52,515] Trial 50 finished with value: 0.5824079168329791 and parameters: {'max_depth': 4, 'learning_rate': 0.001112886268556641, 'subsample': 0.692138936579727, 'colsample_bytree': 0.6478762132584974, 'lambda': 1.4865383108014628e-07, 'alpha': 2.2197319910662022e-08, 'scale_pos_weight': 1.9947997298669022}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:36:53,614] Trial 51 finished with value: 0.5964184385686699 and parameters: {'max_depth': 8, 'learning_rate': 0.0012133255096080581, 'subsample': 0.6234682738057639, 'colsample_bytree': 0.5104554318437631, 'lambda': 5.3949797404481924e-08, 'alpha': 6.355801302414756e-08, 'scale_pos_weight': 2.2124582442580882}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:36:54,923] Trial 52 finished with value: 0.5921007871524069 and parameters: {'max_depth': 9, 'learning_rate': 0.0011935734016361938, 'subsample': 0.5754224186804253, 'colsample_bytree': 0.5226382086200073, 'lambda': 3.219504239507632e-08, 'alpha': 1.428643355413898e-07, 'scale_pos_weight': 2.246241821768683}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:36:56,199] Trial 53 finished with value: 0.5902373683434559 and parameters: {'max_depth': 8, 'learning_rate': 0.001268079918646848, 'subsample': 0.6378875479028805, 'colsample_bytree': 0.5472083091499529, 'lambda': 3.1552037369039224e-07, 'alpha': 6.123804585722872e-08, 'scale_pos_weight': 2.07980747620278}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:36:57,471] Trial 54 finished with value: 0.5934334444480405 and parameters: {'max_depth': 8, 'learning_rate': 0.0010809999670922093, 'subsample': 0.6108498339288664, 'colsample_bytree': 0.6174696652025555, 'lambda': 5.1942074625190075e-08, 'alpha': 2.4597923944942027e-08, 'scale_pos_weight': 2.164117670756166}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:36:58,912] Trial 55 finished with value: 0.5931177204584112 and parameters: {'max_depth': 9, 'learning_rate': 0.0010080161781582683, 'subsample': 0.5304657000920501, 'colsample_bytree': 0.5913718813016497, 'lambda': 2.0891382077497443e-06, 'alpha': 4.812503842520473e-07, 'scale_pos_weight': 2.4215461402855607}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:37:00,246] Trial 56 finished with value: 0.5956780334494823 and parameters: {'max_depth': 9, 'learning_rate': 0.0013109389613198054, 'subsample': 0.5864366438953047, 'colsample_bytree': 0.5220689307765995, 'lambda': 1.6956141005610927e-08, 'alpha': 1.155941036768201e-08, 'scale_pos_weight': 2.3066380277412826}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:37:01,514] Trial 57 finished with value: 0.5920069329823692 and parameters: {'max_depth': 8, 'learning_rate': 0.0012108861212888002, 'subsample': 0.6020972610017126, 'colsample_bytree': 0.5555324663252849, 'lambda': 9.656320200120221e-08, 'alpha': 2.7949747990548563e-07, 'scale_pos_weight': 2.367333106116445}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:37:02,670] Trial 58 finished with value: 0.5899015070606384 and parameters: {'max_depth': 7, 'learning_rate': 0.0010621235472101022, 'subsample': 0.655106622860854, 'colsample_bytree': 0.5988043096217385, 'lambda': 1.5560391930080712e-07, 'alpha': 7.974474437992828e-07, 'scale_pos_weight': 2.063153224104939}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:37:04,347] Trial 59 finished with value: 0.5877561661470526 and parameters: {'max_depth': 10, 'learning_rate': 0.0014392351455263528, 'subsample': 0.5219278800580701, 'colsample_bytree': 0.569248259586968, 'lambda': 4.180404646000875e-08, 'alpha': 8.052652807304234e-08, 'scale_pos_weight': 2.268788970809712}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:37:05,194] Trial 60 finished with value: 0.5880157933913719 and parameters: {'max_depth': 5, 'learning_rate': 0.001227665297866611, 'subsample': 0.5442821578953331, 'colsample_bytree': 0.5391814397755342, 'lambda': 1.1664414096838558e-08, 'alpha': 3.31511278440156e-08, 'scale_pos_weight': 2.200886658768905}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:37:06,505] Trial 61 finished with value: 0.591379800137365 and parameters: {'max_depth': 9, 'learning_rate': 0.001311324016023601, 'subsample': 0.5828646049939171, 'colsample_bytree': 0.5178645998177306, 'lambda': 2.1689663208937964e-08, 'alpha': 1.3595797662729862e-08, 'scale_pos_weight': 2.2965585214326154}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:37:07,987] Trial 62 finished with value: 0.5932241604366916 and parameters: {'max_depth': 9, 'learning_rate': 0.0021794245100400945, 'subsample': 0.5631199790217657, 'colsample_bytree': 0.5135001098119084, 'lambda': 1.082583711666855e-08, 'alpha': 1.6856656219517214e-08, 'scale_pos_weight': 2.424482122059898}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:37:09,304] Trial 63 finished with value: 0.5912266128713263 and parameters: {'max_depth': 9, 'learning_rate': 0.0010896566562604802, 'subsample': 0.626422682868214, 'colsample_bytree': 0.5306032824287975, 'lambda': 2.211352995549619e-08, 'alpha': 1.60655667708284e-07, 'scale_pos_weight': 2.36959508886411}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:37:11,050] Trial 64 finished with value: 0.5974199093102618 and parameters: {'max_depth': 10, 'learning_rate': 0.001546732611871273, 'subsample': 0.5852264579147388, 'colsample_bytree': 0.5180914182972112, 'lambda': 5.709755532379364e-08, 'alpha': 4.4034037144638675e-08, 'scale_pos_weight': 2.3385149913809977}. Best is trial 29 with value: 0.5995325271224168.\n",
      "[I 2023-07-05 16:37:12,427] Trial 65 finished with value: 0.6025193192156524 and parameters: {'max_depth': 10, 'learning_rate': 0.001519335187028576, 'subsample': 0.6066911369160539, 'colsample_bytree': 0.5027994488907361, 'lambda': 5.6621538761724025e-08, 'alpha': 7.92155619322075e-08, 'scale_pos_weight': 2.228380485572755}. Best is trial 65 with value: 0.6025193192156524.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:37:13,763] Trial 66 finished with value: 0.6011007188294479 and parameters: {'max_depth': 10, 'learning_rate': 0.0015589162302276926, 'subsample': 0.6066375539465089, 'colsample_bytree': 0.5020255163188336, 'lambda': 1.209523902639541e-07, 'alpha': 5.556837029687459e-08, 'scale_pos_weight': 2.222780751193342}. Best is trial 65 with value: 0.6025193192156524.\n",
      "[I 2023-07-05 16:37:15,322] Trial 67 finished with value: 0.5926624737945493 and parameters: {'max_depth': 10, 'learning_rate': 0.0018080077266133632, 'subsample': 0.5527323169734398, 'colsample_bytree': 0.5015393954022987, 'lambda': 7.457236952332408e-07, 'alpha': 3.623351327785535e-08, 'scale_pos_weight': 2.1330494157269744}. Best is trial 65 with value: 0.6025193192156524.\n",
      "[I 2023-07-05 16:37:16,809] Trial 68 finished with value: 0.5953180793337433 and parameters: {'max_depth': 10, 'learning_rate': 0.0015926284903189324, 'subsample': 0.6050130511913016, 'colsample_bytree': 0.5356188149111363, 'lambda': 1.312753784921251e-07, 'alpha': 9.76934309615626e-08, 'scale_pos_weight': 2.246908819709277}. Best is trial 65 with value: 0.6025193192156524.\n",
      "[I 2023-07-05 16:37:18,398] Trial 69 finished with value: 0.5904718239712899 and parameters: {'max_depth': 10, 'learning_rate': 0.0016624407883523453, 'subsample': 0.6077609337576341, 'colsample_bytree': 0.5778103728135555, 'lambda': 5.106254095397972e-07, 'alpha': 3.413787883725029e-07, 'scale_pos_weight': 2.08919592275889}. Best is trial 65 with value: 0.6025193192156524.\n",
      "[I 2023-07-05 16:37:19,971] Trial 70 finished with value: 0.5852605801698005 and parameters: {'max_depth': 10, 'learning_rate': 0.0015045885621705543, 'subsample': 0.5218645761944499, 'colsample_bytree': 0.540313466839975, 'lambda': 3.741836340460838e-07, 'alpha': 4.2411903613923235e-08, 'scale_pos_weight': 2.038218745273186}. Best is trial 65 with value: 0.6025193192156524.\n",
      "[I 2023-07-05 16:37:21,481] Trial 71 finished with value: 0.5980348159415443 and parameters: {'max_depth': 10, 'learning_rate': 0.0012218189174949526, 'subsample': 0.5665533098891158, 'colsample_bytree': 0.5129327847779057, 'lambda': 5.243181814854837e-08, 'alpha': 6.575935144914167e-08, 'scale_pos_weight': 2.18292655275232}. Best is trial 65 with value: 0.6025193192156524.\n",
      "[I 2023-07-05 16:37:23,171] Trial 72 finished with value: 0.5911733928821861 and parameters: {'max_depth': 10, 'learning_rate': 0.0013628377403170262, 'subsample': 0.571448739783131, 'colsample_bytree': 0.5204053982096847, 'lambda': 5.830976371695788e-08, 'alpha': 8.809105857048728e-08, 'scale_pos_weight': 2.1575659421117455}. Best is trial 65 with value: 0.6025193192156524.\n",
      "[I 2023-07-05 16:37:24,817] Trial 73 finished with value: 0.5910813366847543 and parameters: {'max_depth': 10, 'learning_rate': 0.001085621846690684, 'subsample': 0.5477566997600104, 'colsample_bytree': 0.502840203417335, 'lambda': 1.0138471215205248e-07, 'alpha': 2.1394291063250398e-08, 'scale_pos_weight': 1.9811575219551039}. Best is trial 65 with value: 0.6025193192156524.\n",
      "[I 2023-07-05 16:37:26,266] Trial 74 finished with value: 0.5913700910852921 and parameters: {'max_depth': 10, 'learning_rate': 0.0011669432740879697, 'subsample': 0.56476997539904, 'colsample_bytree': 0.546750683658626, 'lambda': 3.069875133117958e-08, 'alpha': 1.7595313837640944e-07, 'scale_pos_weight': 2.1059976227040136}. Best is trial 65 with value: 0.6025193192156524.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=75)\n",
    "best_params = study.best_params\n",
    "best_score = study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "030baa6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best parameters are:  {'max_depth': 10, 'learning_rate': 0.001519335187028576, 'subsample': 0.6066911369160539, 'colsample_bytree': 0.5027994488907361, 'lambda': 5.6621538761724025e-08, 'alpha': 7.92155619322075e-08, 'scale_pos_weight': 2.228380485572755}\n",
      "The best score is:  0.6025193192156524\n"
     ]
    }
   ],
   "source": [
    "print('the best parameters are: ', best_params)\n",
    "print('The best score is: ', best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ab0f98",
   "metadata": {},
   "source": [
    "Past parameters:\n",
    "- the best parameters are:  {'max_depth': 10, 'learning_rate': 0.001519335187028576, 'subsample': 0.6066911369160539, 'colsample_bytree': 0.5027994488907361, 'lambda': 5.6621538761724025e-08, 'alpha': 7.92155619322075e-08, 'scale_pos_weight': 2.228380485572755}|The best score is:  0.6025193192156524"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5ba20fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy score is: 0.7988205560235889\n",
      "Test Accuracy score is: 0.8035714285714286\n",
      "ROCAUC score is: 0.6025193192156524\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       583\n",
      "           1       0.80      1.00      0.89      2385\n",
      "\n",
      "    accuracy                           0.80      2968\n",
      "   macro avg       0.40      0.50      0.45      2968\n",
      "weighted avg       0.65      0.80      0.72      2968\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(**best_params, random_state=5)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "evaluate_model(xgb_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6cf0ecd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5481805929919138"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_ec1 = (model1.predict(X_val)>=0.5).astype(int)\n",
    "y_hat_ec2 = (model2.predict(X_val)>=0.5).astype(int)\n",
    "\n",
    "y_hat = pd.DataFrame(zip(y_hat_ec1, y_hat_ec2)).values\n",
    "\n",
    "y_true = np.array(train_data.iloc[y_val.index,:][['EC1', 'EC2']])\n",
    "\n",
    "accuracy_score(y_true, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654494b1",
   "metadata": {},
   "source": [
    "# Using EC1 to predict EC2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe4a0f0",
   "metadata": {},
   "source": [
    "Based on my previous lgbm2 model, the model failed to predict any 0 (false) value class (0%). So, I am going to try using EC1 to also contribute to predicting EC2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e7e4095a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BertzCT</th>\n",
       "      <th>ExactMolWt</th>\n",
       "      <th>HeavyAtomMolWt</th>\n",
       "      <th>Chi1</th>\n",
       "      <th>Chi1n</th>\n",
       "      <th>Chi1v</th>\n",
       "      <th>Chi2n</th>\n",
       "      <th>Chi2v</th>\n",
       "      <th>Chi3v</th>\n",
       "      <th>Chi4n</th>\n",
       "      <th>...</th>\n",
       "      <th>PEOE_VSA6</th>\n",
       "      <th>PEOE_VSA7</th>\n",
       "      <th>PEOE_VSA8</th>\n",
       "      <th>SMR_VSA10</th>\n",
       "      <th>SMR_VSA5</th>\n",
       "      <th>SlogP_VSA3</th>\n",
       "      <th>VSA_EState9</th>\n",
       "      <th>fr_COO</th>\n",
       "      <th>fr_COO2</th>\n",
       "      <th>EC1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6788</th>\n",
       "      <td>-0.479488</td>\n",
       "      <td>-0.631739</td>\n",
       "      <td>-0.633457</td>\n",
       "      <td>4.825699</td>\n",
       "      <td>2.793756</td>\n",
       "      <td>2.793756</td>\n",
       "      <td>1.932542</td>\n",
       "      <td>1.932542</td>\n",
       "      <td>1.438134</td>\n",
       "      <td>0.895230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.393687</td>\n",
       "      <td>5.687386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>-0.633683</td>\n",
       "      <td>-0.596321</td>\n",
       "      <td>-0.577001</td>\n",
       "      <td>5.947265</td>\n",
       "      <td>3.675670</td>\n",
       "      <td>3.675670</td>\n",
       "      <td>2.757262</td>\n",
       "      <td>2.757262</td>\n",
       "      <td>1.708684</td>\n",
       "      <td>0.955337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.938611</td>\n",
       "      <td>25.304306</td>\n",
       "      <td>9.531400</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3551</th>\n",
       "      <td>-0.513457</td>\n",
       "      <td>-0.613643</td>\n",
       "      <td>-0.651981</td>\n",
       "      <td>5.036581</td>\n",
       "      <td>3.414884</td>\n",
       "      <td>3.414884</td>\n",
       "      <td>2.703542</td>\n",
       "      <td>2.703542</td>\n",
       "      <td>1.827002</td>\n",
       "      <td>1.029291</td>\n",
       "      <td>...</td>\n",
       "      <td>12.152040</td>\n",
       "      <td>17.696186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.103966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8301</th>\n",
       "      <td>-0.635423</td>\n",
       "      <td>-0.538873</td>\n",
       "      <td>-0.525580</td>\n",
       "      <td>5.092224</td>\n",
       "      <td>2.925131</td>\n",
       "      <td>2.925131</td>\n",
       "      <td>2.116586</td>\n",
       "      <td>2.116586</td>\n",
       "      <td>1.611120</td>\n",
       "      <td>0.757462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.907600</td>\n",
       "      <td>12.462662</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>-0.795743</td>\n",
       "      <td>-0.835799</td>\n",
       "      <td>-0.821568</td>\n",
       "      <td>2.642734</td>\n",
       "      <td>1.049739</td>\n",
       "      <td>1.049739</td>\n",
       "      <td>0.504904</td>\n",
       "      <td>0.504904</td>\n",
       "      <td>0.142577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.752550</td>\n",
       "      <td>6.544756</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>29.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11798</th>\n",
       "      <td>-0.679346</td>\n",
       "      <td>-0.552008</td>\n",
       "      <td>-0.539291</td>\n",
       "      <td>5.163902</td>\n",
       "      <td>3.722225</td>\n",
       "      <td>3.722225</td>\n",
       "      <td>2.229188</td>\n",
       "      <td>2.229188</td>\n",
       "      <td>1.749075</td>\n",
       "      <td>0.933119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.822697</td>\n",
       "      <td>25.235636</td>\n",
       "      <td>9.088795</td>\n",
       "      <td>35.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13896</th>\n",
       "      <td>-0.756094</td>\n",
       "      <td>-0.777881</td>\n",
       "      <td>-0.793221</td>\n",
       "      <td>3.553418</td>\n",
       "      <td>2.189533</td>\n",
       "      <td>2.189533</td>\n",
       "      <td>1.477829</td>\n",
       "      <td>1.477829</td>\n",
       "      <td>0.711731</td>\n",
       "      <td>0.182919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.132734</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6637</th>\n",
       "      <td>-0.945332</td>\n",
       "      <td>-1.035367</td>\n",
       "      <td>-1.023724</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>1.341641</td>\n",
       "      <td>1.341641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.027704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.180556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>-0.586183</td>\n",
       "      <td>-0.777975</td>\n",
       "      <td>-0.774255</td>\n",
       "      <td>3.931852</td>\n",
       "      <td>2.786883</td>\n",
       "      <td>2.786883</td>\n",
       "      <td>1.927161</td>\n",
       "      <td>1.927161</td>\n",
       "      <td>0.962617</td>\n",
       "      <td>0.350229</td>\n",
       "      <td>...</td>\n",
       "      <td>18.199101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7336</th>\n",
       "      <td>-0.540939</td>\n",
       "      <td>-0.498730</td>\n",
       "      <td>-0.501801</td>\n",
       "      <td>6.270857</td>\n",
       "      <td>3.876105</td>\n",
       "      <td>3.876105</td>\n",
       "      <td>2.719449</td>\n",
       "      <td>2.719449</td>\n",
       "      <td>1.749075</td>\n",
       "      <td>1.002679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.705892</td>\n",
       "      <td>4.736863</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11870 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        BertzCT  ExactMolWt  HeavyAtomMolWt      Chi1     Chi1n     Chi1v  \\\n",
       "6788  -0.479488   -0.631739       -0.633457  4.825699  2.793756  2.793756   \n",
       "1962  -0.633683   -0.596321       -0.577001  5.947265  3.675670  3.675670   \n",
       "3551  -0.513457   -0.613643       -0.651981  5.036581  3.414884  3.414884   \n",
       "8301  -0.635423   -0.538873       -0.525580  5.092224  2.925131  2.925131   \n",
       "281   -0.795743   -0.835799       -0.821568  2.642734  1.049739  1.049739   \n",
       "...         ...         ...             ...       ...       ...       ...   \n",
       "11798 -0.679346   -0.552008       -0.539291  5.163902  3.722225  3.722225   \n",
       "13896 -0.756094   -0.777881       -0.793221  3.553418  2.189533  2.189533   \n",
       "6637  -0.945332   -1.035367       -1.023724  1.732051  1.341641  1.341641   \n",
       "2575  -0.586183   -0.777975       -0.774255  3.931852  2.786883  2.786883   \n",
       "7336  -0.540939   -0.498730       -0.501801  6.270857  3.876105  3.876105   \n",
       "\n",
       "          Chi2n     Chi2v     Chi3v     Chi4n  ...  PEOE_VSA6  PEOE_VSA7  \\\n",
       "6788   1.932542  1.932542  1.438134  0.895230  ...   0.000000   0.000000   \n",
       "1962   2.757262  2.757262  1.708684  0.955337  ...   0.000000   0.000000   \n",
       "3551   2.703542  2.703542  1.827002  1.029291  ...  12.152040  17.696186   \n",
       "8301   2.116586  2.116586  1.611120  0.757462  ...   0.000000   0.000000   \n",
       "281    0.504904  0.504904  0.142577  0.000000  ...   0.000000   0.000000   \n",
       "...         ...       ...       ...       ...  ...        ...        ...   \n",
       "11798  2.229188  2.229188  1.749075  0.933119  ...   0.000000   0.000000   \n",
       "13896  1.477829  1.477829  0.711731  0.182919  ...   0.000000  12.132734   \n",
       "6637   0.000000  0.000000  0.000000  0.000000  ...   0.000000   0.000000   \n",
       "2575   1.927161  1.927161  0.962617  0.350229  ...  18.199101   0.000000   \n",
       "7336   2.719449  2.719449  1.749075  1.002679  ...   0.000000   0.000000   \n",
       "\n",
       "       PEOE_VSA8  SMR_VSA10   SMR_VSA5  SlogP_VSA3  VSA_EState9  fr_COO  \\\n",
       "6788   12.393687   5.687386   0.000000    0.000000    30.000000       0   \n",
       "1962    0.000000  11.938611  25.304306    9.531400    47.000000       1   \n",
       "3551    0.000000   0.000000   6.103966    0.000000    36.166667       0   \n",
       "8301    0.000000  17.907600  12.462662    9.589074    39.500000       1   \n",
       "281     0.000000  11.752550   6.544756    9.589074    29.666667       1   \n",
       "...          ...        ...        ...         ...          ...     ...   \n",
       "11798   0.000000   7.822697  25.235636    9.088795    35.166667       0   \n",
       "13896   0.000000   5.969305   0.000000    0.000000    23.166667       1   \n",
       "6637    0.000000   0.000000  13.027704    0.000000     8.180556       0   \n",
       "2575    0.000000   0.000000   0.000000    0.000000    23.333333       0   \n",
       "7336    0.000000   0.000000  30.705892    4.736863    41.666667       0   \n",
       "\n",
       "       fr_COO2  EC1  \n",
       "6788         0    0  \n",
       "1962         1    1  \n",
       "3551         0    1  \n",
       "8301         1    1  \n",
       "281          1    1  \n",
       "...        ...  ...  \n",
       "11798        0    0  \n",
       "13896        1    1  \n",
       "6637         0    1  \n",
       "2575         0    1  \n",
       "7336         0    1  \n",
       "\n",
       "[11870 rows x 32 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_data.drop(['id','EC2', 'EC3', 'EC4', 'EC5', 'EC6'], axis=1)\n",
    "y = train_data['EC2']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y, test_size=.2, random_state=2)\n",
    "cols_not = [i for i in X_train.columns if i not in high_value_cols]\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_sc=pd.DataFrame(scaler.fit_transform(X_train[high_value_cols]),index=X_train.index,columns=high_value_cols)\n",
    "val_sc=pd.DataFrame(scaler.fit_transform(X_val[high_value_cols]),index=X_val.index,columns=high_value_cols)\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# X_train=pd.DataFrame(scaler.fit_transform(X_train),index=X_train.index,columns=X_train.columns)\n",
    "# X_val=pd.DataFrame(scaler.fit_transform(X_val),index=X_val.index,columns=X_val.columns)\n",
    "\n",
    "X_train = pd.concat([train_sc, X_train[cols_not]], axis=1)\n",
    "X_val = pd.concat([val_sc, X_val[cols_not]], axis=1)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399d334d",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "cd6640c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    parameters = {\n",
    "        'objective':'binary',\n",
    "        'num_leaves':trial.suggest_int('num_leaves', 10, 70),\n",
    "        'learning_rate':trial.suggest_loguniform('learning_rate', 0.001, 0.01),\n",
    "        'max_depth':trial.suggest_int('max_depth', 2, 10),\n",
    "        'min_data_in_leaf':trial.suggest_int('min_data_in_leaf', 1, 100, step=5),\n",
    "        'subsample':trial.suggest_float('subsample', 0.5, 1),\n",
    "        'feature_fraction':trial.suggest_uniform('feature_fraction', 0.5, 1),\n",
    "        'lambda_l1 ':trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'n_estimators ':trial.suggest_int('n_estimators ', 100, 1000, step=100),\n",
    "        'bagging_fraction ':trial.suggest_uniform('bagging_fraction ', 0.5,1),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        'class_weight': trial.suggest_uniform('class_weight', 1.0,2.5),\n",
    "    }\n",
    "    train = lgb.Dataset(X_train, label=y_train)\n",
    "    val = lgb.Dataset(X_val, label=y_val)\n",
    "    \n",
    "    model = lgb.train(parameters, train, valid_sets=val, early_stopping_rounds=100, verbose_eval=False)\n",
    "\n",
    "    y_hat = model.predict(X_val)\n",
    "#     y_hat_bin = (y_hat>=0.5).astype(int)\n",
    "    score = roc_auc_score(y_val, y_hat)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "17a41e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:03,582] A new study created in memory with name: no-name-8b902793-6c22-452e-bb6a-17d0d0891359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 5.761762731094583e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5100112215201874\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6360042556414442 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 5.761762731094583e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5100112215201874\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6360042556414442 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 5.761762731094583e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5100112215201874\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6360042556414442 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:03,808] Trial 0 finished with value: 0.627133564193016 and parameters: {'num_leaves': 67, 'learning_rate': 0.0036527737868794056, 'max_depth': 5, 'min_data_in_leaf': 26, 'subsample': 0.6360042556414442, 'feature_fraction': 0.645737345256419, 'lambda_l1': 5.761762731094583e-06, 'lambda_l2': 3.5014081902353772e-06, 'n_estimators ': 1000, 'bagging_fraction ': 0.5100112215201874, 'bagging_freq': 9, 'class_weight': 2.3712229905218347}. Best is trial 0 with value: 0.627133564193016.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5098400346305876\n",
      "[LightGBM] [Warning] Unknown parameter: 0.028587411156779777\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8253181971494234 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5098400346305876\n",
      "[LightGBM] [Warning] Unknown parameter: 0.028587411156779777\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8253181971494234 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5098400346305876\n",
      "[LightGBM] [Warning] Unknown parameter: 0.028587411156779777\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8253181971494234 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:04,060] Trial 1 finished with value: 0.6274474902100391 and parameters: {'num_leaves': 43, 'learning_rate': 0.00744488655449367, 'max_depth': 8, 'min_data_in_leaf': 56, 'subsample': 0.8253181971494234, 'feature_fraction': 0.6649956714406746, 'lambda_l1': 0.028587411156779777, 'lambda_l2': 1.0874127383566291e-07, 'n_estimators ': 600, 'bagging_fraction ': 0.5098400346305876, 'bagging_freq': 9, 'class_weight': 1.3077362845439349}. Best is trial 1 with value: 0.6274474902100391.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.31085311654271747\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5560906342043437\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6824561331753762 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.31085311654271747\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5560906342043437\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6824561331753762 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 0.31085311654271747\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5560906342043437\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6824561331753762 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:04,413] Trial 2 finished with value: 0.6272874706480972 and parameters: {'num_leaves': 29, 'learning_rate': 0.0018193350499283634, 'max_depth': 8, 'min_data_in_leaf': 66, 'subsample': 0.6824561331753762, 'feature_fraction': 0.8120008176705604, 'lambda_l1': 0.31085311654271747, 'lambda_l2': 1.881374656054195e-07, 'n_estimators ': 900, 'bagging_fraction ': 0.5560906342043437, 'bagging_freq': 2, 'class_weight': 1.068613244079016}. Best is trial 1 with value: 0.6274474902100391.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 2.705161804265538e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7610108722456137\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8394777553677664 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 2.705161804265538e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7610108722456137\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8394777553677664 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 2.705161804265538e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7610108722456137\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8394777553677664 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:04,724] Trial 3 finished with value: 0.6243848236728265 and parameters: {'num_leaves': 47, 'learning_rate': 0.0011613915854217006, 'max_depth': 8, 'min_data_in_leaf': 96, 'subsample': 0.8394777553677664, 'feature_fraction': 0.830324307603854, 'lambda_l1': 2.705161804265538e-06, 'lambda_l2': 0.00015209296244552618, 'n_estimators ': 800, 'bagging_fraction ': 0.7610108722456137, 'bagging_freq': 8, 'class_weight': 2.198469801453742}. Best is trial 1 with value: 0.6274474902100391.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 0.00012993022991611745\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9029551715581596\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5973839173559379 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 0.00012993022991611745\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9029551715581596\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5973839173559379 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 0.00012993022991611745\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9029551715581596\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5973839173559379 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:05,008] Trial 4 finished with value: 0.6270695563682391 and parameters: {'num_leaves': 45, 'learning_rate': 0.0027349380742270157, 'max_depth': 8, 'min_data_in_leaf': 56, 'subsample': 0.5973839173559379, 'feature_fraction': 0.6995934582875972, 'lambda_l1': 0.00012993022991611745, 'lambda_l2': 0.010812262599668493, 'n_estimators ': 800, 'bagging_fraction ': 0.9029551715581596, 'bagging_freq': 9, 'class_weight': 1.6901390179919222}. Best is trial 1 with value: 0.6274474902100391.\n",
      "[I 2023-07-05 16:39:05,168] Trial 5 finished with value: 0.6233434379393796 and parameters: {'num_leaves': 62, 'learning_rate': 0.006885541075851593, 'max_depth': 4, 'min_data_in_leaf': 36, 'subsample': 0.8212135848453175, 'feature_fraction': 0.9811524226611772, 'lambda_l1': 0.013473205105126168, 'lambda_l2': 6.014145456838767e-05, 'n_estimators ': 200, 'bagging_fraction ': 0.888783320321042, 'bagging_freq': 9, 'class_weight': 1.5776297229089722}. Best is trial 1 with value: 0.6274474902100391.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.888783320321042\n",
      "[LightGBM] [Warning] Unknown parameter: 0.013473205105126168\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8212135848453175 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.888783320321042\n",
      "[LightGBM] [Warning] Unknown parameter: 0.013473205105126168\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8212135848453175 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 0.888783320321042\n",
      "[LightGBM] [Warning] Unknown parameter: 0.013473205105126168\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8212135848453175 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 3.4989431823025066\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8326382933072528\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.959212610839339 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:05,318] Trial 6 finished with value: 0.6158606355473568 and parameters: {'num_leaves': 26, 'learning_rate': 0.003061909793509351, 'max_depth': 2, 'min_data_in_leaf': 26, 'subsample': 0.959212610839339, 'feature_fraction': 0.612116211905954, 'lambda_l1': 3.4989431823025066, 'lambda_l2': 0.14434769388515306, 'n_estimators ': 600, 'bagging_fraction ': 0.8326382933072528, 'bagging_freq': 2, 'class_weight': 2.387889310065106}. Best is trial 1 with value: 0.6274474902100391.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 3.4989431823025066\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8326382933072528\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.959212610839339 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 3.4989431823025066\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8326382933072528\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.959212610839339 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9494142741811509\n",
      "[LightGBM] [Warning] Unknown parameter: 6.821124473916414e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8805263951150097 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9494142741811509\n",
      "[LightGBM] [Warning] Unknown parameter: 6.821124473916414e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8805263951150097 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9494142741811509\n",
      "[LightGBM] [Warning] Unknown parameter: 6.821124473916414e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8805263951150097 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:05,466] Trial 7 finished with value: 0.6252870463265621 and parameters: {'num_leaves': 12, 'learning_rate': 0.00322027962477268, 'max_depth': 4, 'min_data_in_leaf': 61, 'subsample': 0.8805263951150097, 'feature_fraction': 0.8028144124723013, 'lambda_l1': 6.821124473916414e-07, 'lambda_l2': 0.0018564295469757513, 'n_estimators ': 500, 'bagging_fraction ': 0.9494142741811509, 'bagging_freq': 8, 'class_weight': 1.4378600490137727}. Best is trial 1 with value: 0.6274474902100391.\n",
      "[I 2023-07-05 16:39:05,644] Trial 8 finished with value: 0.6237846604169139 and parameters: {'num_leaves': 18, 'learning_rate': 0.005005825654591341, 'max_depth': 9, 'min_data_in_leaf': 61, 'subsample': 0.7485001724896883, 'feature_fraction': 0.6297651679613523, 'lambda_l1': 3.06513562245248e-05, 'lambda_l2': 0.0010242484463847549, 'n_estimators ': 100, 'bagging_fraction ': 0.9578853085778231, 'bagging_freq': 1, 'class_weight': 2.3253169385358436}. Best is trial 1 with value: 0.6274474902100391.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 3.06513562245248e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9578853085778231\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7485001724896883 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 3.06513562245248e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9578853085778231\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7485001724896883 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 3.06513562245248e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9578853085778231\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7485001724896883 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] Unknown parameter: 0.007722005318112481\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5809751939921883\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7447798595872899 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.007722005318112481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:05,787] Trial 9 finished with value: 0.6155168631850725 and parameters: {'num_leaves': 30, 'learning_rate': 0.0018192722498594192, 'max_depth': 3, 'min_data_in_leaf': 11, 'subsample': 0.7447798595872899, 'feature_fraction': 0.6777741815994743, 'lambda_l1': 0.007722005318112481, 'lambda_l2': 1.0807274904189092e-05, 'n_estimators ': 200, 'bagging_fraction ': 0.5809751939921883, 'bagging_freq': 2, 'class_weight': 1.430210527215352}. Best is trial 1 with value: 0.6274474902100391.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5809751939921883\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7447798595872899 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001911 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 0.007722005318112481\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5809751939921883\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7447798595872899 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] Unknown parameter: 8.830998240287995e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6332087914853473\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5380990816955453 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 8.830998240287995e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6332087914853473\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5380990816955453 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 8.830998240287995e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6332087914853473\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.5380990816955453 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:06,183] Trial 10 finished with value: 0.623070146103254 and parameters: {'num_leaves': 57, 'learning_rate': 0.00900911473037337, 'max_depth': 10, 'min_data_in_leaf': 91, 'subsample': 0.5380990816955453, 'feature_fraction': 0.5061858092735848, 'lambda_l1': 8.830998240287995e-08, 'lambda_l2': 1.722379493613729e-08, 'n_estimators ': 500, 'bagging_fraction ': 0.6332087914853473, 'bagging_freq': 5, 'class_weight': 1.0180291004957274}. Best is trial 1 with value: 0.6274474902100391.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6599356729483437\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5008678758821318\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6917809504383756 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6599356729483437\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5008678758821318\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6917809504383756 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6599356729483437\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5008678758821318\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6917809504383756 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:06,752] Trial 11 finished with value: 0.6254463466994618 and parameters: {'num_leaves': 33, 'learning_rate': 0.009787669401194946, 'max_depth': 7, 'min_data_in_leaf': 76, 'subsample': 0.6917809504383756, 'feature_fraction': 0.7702741092915903, 'lambda_l1': 0.6599356729483437, 'lambda_l2': 2.7819909223083972e-08, 'n_estimators ': 1000, 'bagging_fraction ': 0.5008678758821318, 'bagging_freq': 5, 'class_weight': 1.045657465119113}. Best is trial 1 with value: 0.6274474902100391.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0744214458040927\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6327466852745405\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6952962419344687 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0744214458040927\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6327466852745405\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6952962419344687 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0744214458040927\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6327466852745405\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.6952962419344687 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:07,271] Trial 12 finished with value: 0.6242992401767767 and parameters: {'num_leaves': 39, 'learning_rate': 0.0054672797400449015, 'max_depth': 6, 'min_data_in_leaf': 76, 'subsample': 0.6952962419344687, 'feature_fraction': 0.8477358034962719, 'lambda_l1': 0.0744214458040927, 'lambda_l2': 4.342920846937023e-07, 'n_estimators ': 700, 'bagging_fraction ': 0.6327466852745405, 'bagging_freq': 4, 'class_weight': 1.2052107038774438}. Best is trial 1 with value: 0.6274474902100391.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0017849554976649363\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.586913608703466\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7951519861058781 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0017849554976649363\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.586913608703466\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7951519861058781 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0017849554976649363\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.586913608703466\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7951519861058781 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:07,813] Trial 13 finished with value: 0.628269163691022 and parameters: {'num_leaves': 52, 'learning_rate': 0.0018262268415589241, 'max_depth': 10, 'min_data_in_leaf': 46, 'subsample': 0.7951519861058781, 'feature_fraction': 0.8887214635607243, 'lambda_l1': 0.0017849554976649363, 'lambda_l2': 3.707504073165085e-07, 'n_estimators ': 400, 'bagging_fraction ': 0.586913608703466, 'bagging_freq': 7, 'class_weight': 1.2484125625965041}. Best is trial 13 with value: 0.628269163691022.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.001006992743792125\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6774258603595443\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7882035540020981 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.001006992743792125\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6774258603595443\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7882035540020981 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 0.001006992743792125\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6774258603595443\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.7882035540020981 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:08,236] Trial 14 finished with value: 0.6281878953292267 and parameters: {'num_leaves': 52, 'learning_rate': 0.006728642312796103, 'max_depth': 10, 'min_data_in_leaf': 41, 'subsample': 0.7882035540020981, 'feature_fraction': 0.9108871647575871, 'lambda_l1': 0.001006992743792125, 'lambda_l2': 1.5825144329893897e-06, 'n_estimators ': 400, 'bagging_fraction ': 0.6774258603595443, 'bagging_freq': 7, 'class_weight': 1.3489428781197332}. Best is trial 13 with value: 0.628269163691022.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.0008676771277592927\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6845433134550305\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9997822120045396 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0008676771277592927\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6845433134550305\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9997822120045396 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0008676771277592927\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6845433134550305\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9997822120045396 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:08,608] Trial 15 finished with value: 0.6284910335106135 and parameters: {'num_leaves': 51, 'learning_rate': 0.004472706003066478, 'max_depth': 10, 'min_data_in_leaf': 36, 'subsample': 0.9997822120045396, 'feature_fraction': 0.9368746996857462, 'lambda_l1': 0.0008676771277592927, 'lambda_l2': 2.9106374239086364e-06, 'n_estimators ': 400, 'bagging_fraction ': 0.6845433134550305, 'bagging_freq': 7, 'class_weight': 1.866226427697262}. Best is trial 15 with value: 0.6284910335106135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.0007985465042664815\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7031201993387249\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9944575816342115 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0007985465042664815\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7031201993387249\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9944575816342115 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0007985465042664815\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7031201993387249\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9944575816342115 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:09,092] Trial 16 finished with value: 0.628048013060473 and parameters: {'num_leaves': 55, 'learning_rate': 0.004033087587283102, 'max_depth': 10, 'min_data_in_leaf': 1, 'subsample': 0.9944575816342115, 'feature_fraction': 0.9971410619678709, 'lambda_l1': 0.0007985465042664815, 'lambda_l2': 2.8149798269827313e-05, 'n_estimators ': 300, 'bagging_fraction ': 0.7031201993387249, 'bagging_freq': 7, 'class_weight': 1.926091377735657}. Best is trial 15 with value: 0.6284910335106135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.0014683620499799572\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7759256450772167\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9090434887014119 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0014683620499799572\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7759256450772167\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9090434887014119 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0014683620499799572\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7759256450772167\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9090434887014119 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:09,497] Trial 17 finished with value: 0.6266714852332509 and parameters: {'num_leaves': 68, 'learning_rate': 0.0021840147188477133, 'max_depth': 9, 'min_data_in_leaf': 41, 'subsample': 0.9090434887014119, 'feature_fraction': 0.9028335554961032, 'lambda_l1': 0.0014683620499799572, 'lambda_l2': 2.100095426377389e-06, 'n_estimators ': 400, 'bagging_fraction ': 0.7759256450772167, 'bagging_freq': 6, 'class_weight': 1.86874615029524}. Best is trial 15 with value: 0.6284910335106135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 7.369633334146806e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7026371273812856\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.925689669013247 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 7.369633334146806e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7026371273812856\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.925689669013247 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 7.369633334146806e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7026371273812856\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.925689669013247 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:09,832] Trial 18 finished with value: 0.6148638395345408 and parameters: {'num_leaves': 50, 'learning_rate': 0.001056214472884355, 'max_depth': 6, 'min_data_in_leaf': 26, 'subsample': 0.925689669013247, 'feature_fraction': 0.9200364832807137, 'lambda_l1': 7.369633334146806e-05, 'lambda_l2': 7.995494734960717, 'n_estimators ': 400, 'bagging_fraction ': 0.7026371273812856, 'bagging_freq': 4, 'class_weight': 1.5744955816055317}. Best is trial 15 with value: 0.6284910335106135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0022323125867329974\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.605151351388924\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8740678248984955 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0022323125867329974\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.605151351388924\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8740678248984955 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 0.0022323125867329974\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.605151351388924\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8740678248984955 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:10,166] Trial 19 finished with value: 0.629682010564887 and parameters: {'num_leaves': 38, 'learning_rate': 0.004568685175819091, 'max_depth': 9, 'min_data_in_leaf': 16, 'subsample': 0.8740678248984955, 'feature_fraction': 0.8767623433235306, 'lambda_l1': 0.0022323125867329974, 'lambda_l2': 1.1859816080116056e-05, 'n_estimators ': 300, 'bagging_fraction ': 0.605151351388924, 'bagging_freq': 10, 'class_weight': 2.0412225610363897}. Best is trial 19 with value: 0.629682010564887.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.7436435446831803\n",
      "[LightGBM] [Warning] Unknown parameter: 1.4628220269586929e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9777212934623309 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7436435446831803\n",
      "[LightGBM] [Warning] Unknown parameter: 1.4628220269586929e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9777212934623309 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7436435446831803\n",
      "[LightGBM] [Warning] Unknown parameter: 1.4628220269586929e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9777212934623309 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:10,483] Trial 20 finished with value: 0.6307043377887095 and parameters: {'num_leaves': 36, 'learning_rate': 0.004638896047001705, 'max_depth': 9, 'min_data_in_leaf': 11, 'subsample': 0.9777212934623309, 'feature_fraction': 0.9506784521418206, 'lambda_l1': 1.4628220269586929e-08, 'lambda_l2': 1.526371279673488e-05, 'n_estimators ': 100, 'bagging_fraction ': 0.7436435446831803, 'bagging_freq': 10, 'class_weight': 2.0544972333479348}. Best is trial 20 with value: 0.6307043377887095.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 2.1263164965103102e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7401113467076136\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9852772356084678 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 2.1263164965103102e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7401113467076136\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9852772356084678 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 2.1263164965103102e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7401113467076136\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9852772356084678 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:10,809] Trial 21 finished with value: 0.631322480770683 and parameters: {'num_leaves': 38, 'learning_rate': 0.004680019053333568, 'max_depth': 9, 'min_data_in_leaf': 11, 'subsample': 0.9852772356084678, 'feature_fraction': 0.9468415482969073, 'lambda_l1': 2.1263164965103102e-08, 'lambda_l2': 1.1426166690870412e-05, 'n_estimators ': 100, 'bagging_fraction ': 0.7401113467076136, 'bagging_freq': 10, 'class_weight': 2.059733785703482}. Best is trial 21 with value: 0.631322480770683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.7937775677643354\n",
      "[LightGBM] [Warning] Unknown parameter: 1.9903373027570353e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9425609727235996 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7937775677643354\n",
      "[LightGBM] [Warning] Unknown parameter: 1.9903373027570353e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9425609727235996 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7937775677643354\n",
      "[LightGBM] [Warning] Unknown parameter: 1.9903373027570353e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9425609727235996 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:11,242] Trial 22 finished with value: 0.6316044028753178 and parameters: {'num_leaves': 38, 'learning_rate': 0.00502875810407211, 'max_depth': 9, 'min_data_in_leaf': 11, 'subsample': 0.9425609727235996, 'feature_fraction': 0.9626269792704852, 'lambda_l1': 1.9903373027570353e-08, 'lambda_l2': 2.044135280105889e-05, 'n_estimators ': 100, 'bagging_fraction ': 0.7937775677643354, 'bagging_freq': 10, 'class_weight': 2.0788316979275585}. Best is trial 22 with value: 0.6316044028753178.\n",
      "[I 2023-07-05 16:39:11,522] Trial 23 finished with value: 0.6274776961498214 and parameters: {'num_leaves': 22, 'learning_rate': 0.005720517543786006, 'max_depth': 7, 'min_data_in_leaf': 1, 'subsample': 0.9489073479561974, 'feature_fraction': 0.9587375483259909, 'lambda_l1': 2.3337953041056926e-08, 'lambda_l2': 8.381819057538749e-05, 'n_estimators ': 100, 'bagging_fraction ': 0.7969594787172876, 'bagging_freq': 10, 'class_weight': 2.1404354377931196}. Best is trial 22 with value: 0.6316044028753178.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 2.3337953041056926e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7969594787172876\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9489073479561974 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 2.3337953041056926e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7969594787172876\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9489073479561974 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 2.3337953041056926e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7969594787172876\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9489073479561974 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] Unknown parameter: 1.798362029000704e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7325069297999014\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9631977931212785 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.798362029000704e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7325069297999014\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9631977931212785 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000740 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 1.798362029000704e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7325069297999014\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9631977931212785 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:11,860] Trial 24 finished with value: 0.6284137206885516 and parameters: {'num_leaves': 35, 'learning_rate': 0.005666113394758949, 'max_depth': 7, 'min_data_in_leaf': 11, 'subsample': 0.9631977931212785, 'feature_fraction': 0.9612336313236467, 'lambda_l1': 1.798362029000704e-08, 'lambda_l2': 2.2592480109552954e-05, 'n_estimators ': 100, 'bagging_fraction ': 0.7325069297999014, 'bagging_freq': 10, 'class_weight': 2.0481228370802413}. Best is trial 22 with value: 0.6316044028753178.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.8062597152149767\n",
      "[LightGBM] [Warning] Unknown parameter: 1.2059963939022524e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9094930220265558 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8062597152149767\n",
      "[LightGBM] [Warning] Unknown parameter: 1.2059963939022524e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9094930220265558 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001810 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8062597152149767\n",
      "[LightGBM] [Warning] Unknown parameter: 1.2059963939022524e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9094930220265558 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:12,232] Trial 25 finished with value: 0.6254603708857892 and parameters: {'num_leaves': 42, 'learning_rate': 0.003977124081544909, 'max_depth': 9, 'min_data_in_leaf': 16, 'subsample': 0.9094930220265558, 'feature_fraction': 0.9912693542183582, 'lambda_l1': 1.2059963939022524e-07, 'lambda_l2': 0.00028371794426972167, 'n_estimators ': 200, 'bagging_fraction ': 0.8062597152149767, 'bagging_freq': 10, 'class_weight': 2.2291807152048704}. Best is trial 22 with value: 0.6316044028753178.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 1.0077970436499032e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7420777815092833\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9980902374453833 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.0077970436499032e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7420777815092833\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9980902374453833 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 1.0077970436499032e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7420777815092833\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9980902374453833 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:12,622] Trial 26 finished with value: 0.628168477225081 and parameters: {'num_leaves': 35, 'learning_rate': 0.004949834681289588, 'max_depth': 9, 'min_data_in_leaf': 6, 'subsample': 0.9980902374453833, 'feature_fraction': 0.9430993027188056, 'lambda_l1': 1.0077970436499032e-08, 'lambda_l2': 2.187547612204324e-05, 'n_estimators ': 200, 'bagging_fraction ': 0.7420777815092833, 'bagging_freq': 8, 'class_weight': 2.457689636576777}. Best is trial 22 with value: 0.6316044028753178.\n",
      "[I 2023-07-05 16:39:12,901] Trial 27 finished with value: 0.6285388595819354 and parameters: {'num_leaves': 25, 'learning_rate': 0.006018483808506779, 'max_depth': 7, 'min_data_in_leaf': 21, 'subsample': 0.9417612459130413, 'feature_fraction': 0.8767399309582405, 'lambda_l1': 3.573904029587916e-07, 'lambda_l2': 0.0002985419874394132, 'n_estimators ': 100, 'bagging_fraction ': 0.8305466291325487, 'bagging_freq': 10, 'class_weight': 2.0632659967528775}. Best is trial 22 with value: 0.6316044028753178.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 3.573904029587916e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8305466291325487\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9417612459130413 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 3.573904029587916e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8305466291325487\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9417612459130413 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 3.573904029587916e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8305466291325487\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9417612459130413 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 6.04957206297886e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7351131299477753\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8826238971252268 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 6.04957206297886e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7351131299477753\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8826238971252268 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 6.04957206297886e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7351131299477753\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8826238971252268 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:13,268] Trial 28 finished with value: 0.6272820767302789 and parameters: {'num_leaves': 39, 'learning_rate': 0.0043008324411965854, 'max_depth': 8, 'min_data_in_leaf': 6, 'subsample': 0.8826238971252268, 'feature_fraction': 0.9408501653827324, 'lambda_l1': 6.04957206297886e-08, 'lambda_l2': 6.44393659926873e-06, 'n_estimators ': 300, 'bagging_fraction ': 0.7351131299477753, 'bagging_freq': 9, 'class_weight': 1.9680524845726972}. Best is trial 22 with value: 0.6316044028753178.\n",
      "[I 2023-07-05 16:39:13,552] Trial 29 finished with value: 0.6267365718415914 and parameters: {'num_leaves': 31, 'learning_rate': 0.003766570966036787, 'max_depth': 5, 'min_data_in_leaf': 31, 'subsample': 0.9486804413044706, 'feature_fraction': 0.8597659152386157, 'lambda_l1': 2.9135956073886625e-06, 'lambda_l2': 9.556695688615265e-07, 'n_estimators ': 100, 'bagging_fraction ': 0.7783324380489035, 'bagging_freq': 8, 'class_weight': 1.790286723040661}. Best is trial 22 with value: 0.6316044028753178.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 2.9135956073886625e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7783324380489035\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9486804413044706 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: 2.9135956073886625e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7783324380489035\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9486804413044706 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 2.9135956073886625e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7783324380489035\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9486804413044706 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 3.3628833279147387e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8317951051336712\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.979963919642199 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 3.3628833279147387e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8317951051336712\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.979963919642199 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 3.3628833279147387e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8317951051336712\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.979963919642199 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:13,862] Trial 30 finished with value: 0.6282346426169849 and parameters: {'num_leaves': 20, 'learning_rate': 0.003500665419246067, 'max_depth': 9, 'min_data_in_leaf': 16, 'subsample': 0.979963919642199, 'feature_fraction': 0.909440116897546, 'lambda_l1': 3.3628833279147387e-07, 'lambda_l2': 5.099477783030825e-06, 'n_estimators ': 200, 'bagging_fraction ': 0.8317951051336712, 'bagging_freq': 9, 'class_weight': 2.2906848236514064}. Best is trial 22 with value: 0.6316044028753178.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 4.43018853950174e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6544168175473958\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.88360799744347 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 4.43018853950174e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6544168175473958\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.88360799744347 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001340 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 4.43018853950174e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6544168175473958\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.88360799744347 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:14,218] Trial 31 finished with value: 0.6284248681187093 and parameters: {'num_leaves': 38, 'learning_rate': 0.004783851071634667, 'max_depth': 9, 'min_data_in_leaf': 21, 'subsample': 0.88360799744347, 'feature_fraction': 0.9682005853011281, 'lambda_l1': 4.43018853950174e-08, 'lambda_l2': 9.198825596956489e-06, 'n_estimators ': 300, 'bagging_fraction ': 0.6544168175473958, 'bagging_freq': 10, 'class_weight': 2.0815043698246427}. Best is trial 22 with value: 0.6316044028753178.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 1.200110393465418e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7278050850261885\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9224176206864478 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.200110393465418e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7278050850261885\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9224176206864478 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 1.200110393465418e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7278050850261885\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9224176206864478 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:14,622] Trial 32 finished with value: 0.6293616118464819 and parameters: {'num_leaves': 46, 'learning_rate': 0.004468733483606733, 'max_depth': 8, 'min_data_in_leaf': 11, 'subsample': 0.9224176206864478, 'feature_fraction': 0.8784039658247973, 'lambda_l1': 1.200110393465418e-08, 'lambda_l2': 7.231530772462864e-05, 'n_estimators ': 300, 'bagging_fraction ': 0.7278050850261885, 'bagging_freq': 10, 'class_weight': 2.0034978744339935}. Best is trial 22 with value: 0.6316044028753178.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 1.1764260930516392e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5449040682484545\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9619865276702515 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.1764260930516392e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5449040682484545\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9619865276702515 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 1.1764260930516392e-05\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.5449040682484545\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9619865276702515 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:14,995] Trial 33 finished with value: 0.6283666138062721 and parameters: {'num_leaves': 36, 'learning_rate': 0.006411741912280574, 'max_depth': 9, 'min_data_in_leaf': 21, 'subsample': 0.9619865276702515, 'feature_fraction': 0.9249766730874988, 'lambda_l1': 1.1764260930516392e-05, 'lambda_l2': 1.8354620535487458e-06, 'n_estimators ': 100, 'bagging_fraction ': 0.5449040682484545, 'bagging_freq': 9, 'class_weight': 2.1509868828655523}. Best is trial 22 with value: 0.6316044028753178.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 1.013668257842016e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7573728600147197\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8593347512138345 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.013668257842016e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7573728600147197\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8593347512138345 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 1.013668257842016e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7573728600147197\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8593347512138345 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:15,398] Trial 34 finished with value: 0.6247149314433045 and parameters: {'num_leaves': 41, 'learning_rate': 0.00517838473171918, 'max_depth': 8, 'min_data_in_leaf': 6, 'subsample': 0.8593347512138345, 'feature_fraction': 0.9682069862101063, 'lambda_l1': 1.013668257842016e-06, 'lambda_l2': 1.8441323147643297e-07, 'n_estimators ': 200, 'bagging_fraction ': 0.7573728600147197, 'bagging_freq': 10, 'class_weight': 2.122657613340886}. Best is trial 22 with value: 0.6316044028753178.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 1.26675661436752e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.711358853969851\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9192214833763682 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.26675661436752e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.711358853969851\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9192214833763682 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 1.26675661436752e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.711358853969851\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9192214833763682 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:15,788] Trial 35 finished with value: 0.6258559248591289 and parameters: {'num_leaves': 44, 'learning_rate': 0.0037252598386813096, 'max_depth': 8, 'min_data_in_leaf': 16, 'subsample': 0.9192214833763682, 'feature_fraction': 0.8487758415245542, 'lambda_l1': 1.26675661436752e-07, 'lambda_l2': 2.5743924836897966e-05, 'n_estimators ': 100, 'bagging_fraction ': 0.711358853969851, 'bagging_freq': 8, 'class_weight': 2.222528513996929}. Best is trial 22 with value: 0.6316044028753178.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.6598921963933709\n",
      "[LightGBM] [Warning] Unknown parameter: 3.204436548437455e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9612063406871034 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6598921963933709\n",
      "[LightGBM] [Warning] Unknown parameter: 3.204436548437455e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9612063406871034 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003012 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 0.6598921963933709\n",
      "[LightGBM] [Warning] Unknown parameter: 3.204436548437455e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 300\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9612063406871034 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:16,184] Trial 36 finished with value: 0.6224074134006494 and parameters: {'num_leaves': 26, 'learning_rate': 0.007039745024906731, 'max_depth': 10, 'min_data_in_leaf': 1, 'subsample': 0.9612063406871034, 'feature_fraction': 0.995894091033978, 'lambda_l1': 3.204436548437455e-08, 'lambda_l2': 8.202292998343858e-08, 'n_estimators ': 300, 'bagging_fraction ': 0.6598921963933709, 'bagging_freq': 9, 'class_weight': 2.0106827158427993}. Best is trial 22 with value: 0.6316044028753178.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 5.496528209743497e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7551630833427057\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9782788892056294 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 5.496528209743497e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7551630833427057\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9782788892056294 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 5.496528209743497e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7551630833427057\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9782788892056294 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:16,510] Trial 37 finished with value: 0.626237454646141 and parameters: {'num_leaves': 33, 'learning_rate': 0.007981217908287791, 'max_depth': 9, 'min_data_in_leaf': 26, 'subsample': 0.9782788892056294, 'feature_fraction': 0.8868435256923161, 'lambda_l1': 5.496528209743497e-06, 'lambda_l2': 0.00010011269640230489, 'n_estimators ': 200, 'bagging_fraction ': 0.7551630833427057, 'bagging_freq': 9, 'class_weight': 1.9188364750960358}. Best is trial 22 with value: 0.6316044028753178.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 2.0165459463504355e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.868256437654318\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8460678884873497 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 2.0165459463504355e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.868256437654318\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8460678884873497 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 2.0165459463504355e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.868256437654318\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8460678884873497 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:16,879] Trial 38 finished with value: 0.6270271242147355 and parameters: {'num_leaves': 47, 'learning_rate': 0.006035749907023148, 'max_depth': 8, 'min_data_in_leaf': 31, 'subsample': 0.8460678884873497, 'feature_fraction': 0.9413946515208214, 'lambda_l1': 2.0165459463504355e-07, 'lambda_l2': 5.583160813968723e-06, 'n_estimators ': 200, 'bagging_fraction ': 0.868256437654318, 'bagging_freq': 10, 'class_weight': 2.202463009505569}. Best is trial 22 with value: 0.6316044028753178.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 7.380601769071549e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8053570795270543\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8915071797072258 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 7.380601769071549e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8053570795270543\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8915071797072258 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 7.380601769071549e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8053570795270543\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8915071797072258 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:17,182] Trial 39 finished with value: 0.6298636057981021 and parameters: {'num_leaves': 29, 'learning_rate': 0.004422491295834124, 'max_depth': 7, 'min_data_in_leaf': 11, 'subsample': 0.8915071797072258, 'feature_fraction': 0.8013495992328914, 'lambda_l1': 7.380601769071549e-07, 'lambda_l2': 4.534065290370392e-05, 'n_estimators ': 100, 'bagging_fraction ': 0.8053570795270543, 'bagging_freq': 8, 'class_weight': 2.0851990286179984}. Best is trial 22 with value: 0.6316044028753178.\n",
      "[I 2023-07-05 16:39:17,466] Trial 40 finished with value: 0.626552819041249 and parameters: {'num_leaves': 29, 'learning_rate': 0.00330950960173113, 'max_depth': 5, 'min_data_in_leaf': 6, 'subsample': 0.8968889460887737, 'feature_fraction': 0.8068481172070938, 'lambda_l1': 4.880317400001569e-08, 'lambda_l2': 0.0009298082710592983, 'n_estimators ': 100, 'bagging_fraction ': 0.794275798025803, 'bagging_freq': 8, 'class_weight': 2.290717200589955}. Best is trial 22 with value: 0.6316044028753178.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 4.880317400001569e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.794275798025803\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8968889460887737 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 4.880317400001569e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.794275798025803\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8968889460887737 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 4.880317400001569e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.794275798025803\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8968889460887737 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: 1.000061733159742e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7709070860819377\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9351061707990977 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.000061733159742e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7709070860819377\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9351061707990977 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 1.000061733159742e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7709070860819377\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9351061707990977 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:17,859] Trial 41 finished with value: 0.6263280724654878 and parameters: {'num_leaves': 42, 'learning_rate': 0.004652488117995699, 'max_depth': 7, 'min_data_in_leaf': 16, 'subsample': 0.9351061707990977, 'feature_fraction': 0.8282755847773351, 'lambda_l1': 1.000061733159742e-08, 'lambda_l2': 4.186585063809334e-05, 'n_estimators ': 100, 'bagging_fraction ': 0.7709070860819377, 'bagging_freq': 9, 'class_weight': 2.0919530496659062}. Best is trial 22 with value: 0.6316044028753178.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 9.411385704155503e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.86688300550677\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.862062648394849 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 9.411385704155503e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.86688300550677\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.862062648394849 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 9.411385704155503e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.86688300550677\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.862062648394849 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:18,232] Trial 42 finished with value: 0.631177204584111 and parameters: {'num_leaves': 37, 'learning_rate': 0.00519510957808111, 'max_depth': 9, 'min_data_in_leaf': 11, 'subsample': 0.862062648394849, 'feature_fraction': 0.9095417502396479, 'lambda_l1': 9.411385704155503e-07, 'lambda_l2': 1.7512257489928347e-05, 'n_estimators ': 200, 'bagging_fraction ': 0.86688300550677, 'bagging_freq': 10, 'class_weight': 2.004262255902615}. Best is trial 22 with value: 0.6316044028753178.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 5.891138465742594e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8491993477911193\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9052978819444876 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 5.891138465742594e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8491993477911193\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9052978819444876 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 5.891138465742594e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8491993477911193\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9052978819444876 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:18,612] Trial 43 finished with value: 0.626793747370465 and parameters: {'num_leaves': 28, 'learning_rate': 0.005048354720332387, 'max_depth': 8, 'min_data_in_leaf': 6, 'subsample': 0.9052978819444876, 'feature_fraction': 0.9639363938486556, 'lambda_l1': 5.891138465742594e-07, 'lambda_l2': 0.00021598751910475165, 'n_estimators ': 200, 'bagging_fraction ': 0.8491993477911193, 'bagging_freq': 9, 'class_weight': 2.1519644181939013}. Best is trial 22 with value: 0.6316044028753178.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.8898610236854004\n",
      "[LightGBM] [Warning] Unknown parameter: 1.4133417974341478e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8585108935015472 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8898610236854004\n",
      "[LightGBM] [Warning] Unknown parameter: 1.4133417974341478e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8585108935015472 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001986 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8898610236854004\n",
      "[LightGBM] [Warning] Unknown parameter: 1.4133417974341478e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8585108935015472 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:18,905] Trial 44 finished with value: 0.626145038854188 and parameters: {'num_leaves': 16, 'learning_rate': 0.005383541802898967, 'max_depth': 6, 'min_data_in_leaf': 11, 'subsample': 0.8585108935015472, 'feature_fraction': 0.7703838708413338, 'lambda_l1': 1.4133417974341478e-06, 'lambda_l2': 0.00012243829684286392, 'n_estimators ': 100, 'bagging_fraction ': 0.8898610236854004, 'bagging_freq': 9, 'class_weight': 1.9726376367578304}. Best is trial 22 with value: 0.6316044028753178.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 1.8409538727796793e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9219842656935437\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9286500760643376 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.8409538727796793e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9219842656935437\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9286500760643376 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 1.8409538727796793e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9219842656935437\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9286500760643376 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:19,294] Trial 45 finished with value: 0.6297906081102949 and parameters: {'num_leaves': 33, 'learning_rate': 0.0041266283581285115, 'max_depth': 10, 'min_data_in_leaf': 26, 'subsample': 0.9286500760643376, 'feature_fraction': 0.9217506120273914, 'lambda_l1': 1.8409538727796793e-07, 'lambda_l2': 1.2350335905460033e-05, 'n_estimators ': 700, 'bagging_fraction ': 0.9219842656935437, 'bagging_freq': 8, 'class_weight': 1.8610305708996708}. Best is trial 22 with value: 0.6316044028753178.\n",
      "[I 2023-07-05 16:39:19,478] Trial 46 finished with value: 0.60931853242284 and parameters: {'num_leaves': 32, 'learning_rate': 0.002990889781354213, 'max_depth': 2, 'min_data_in_leaf': 1, 'subsample': 0.9733888949002036, 'feature_fraction': 0.9787237371512598, 'lambda_l1': 6.697879220016067e-08, 'lambda_l2': 3.889378162410436e-06, 'n_estimators ': 200, 'bagging_fraction ': 0.8162495702559093, 'bagging_freq': 6, 'class_weight': 1.9794303505137196}. Best is trial 22 with value: 0.6316044028753178.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 6.697879220016067e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8162495702559093\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9733888949002036 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 6.697879220016067e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8162495702559093\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9733888949002036 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 6.697879220016067e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8162495702559093\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9733888949002036 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] Unknown parameter: 0.85904668042466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:19,728] Trial 47 finished with value: 0.6262014951940191 and parameters: {'num_leaves': 23, 'learning_rate': 0.006068952790785775, 'max_depth': 4, 'min_data_in_leaf': 51, 'subsample': 0.8358093035502773, 'feature_fraction': 0.9049160159922218, 'lambda_l1': 3.104040840303671e-08, 'lambda_l2': 5.301255933743003e-05, 'n_estimators ': 100, 'bagging_fraction ': 0.85904668042466, 'bagging_freq': 10, 'class_weight': 1.7772544633293927}. Best is trial 22 with value: 0.6316044028753178.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 3.104040840303671e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8358093035502773 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.85904668042466\n",
      "[LightGBM] [Warning] Unknown parameter: 3.104040840303671e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8358093035502773 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 0.85904668042466\n",
      "[LightGBM] [Warning] Unknown parameter: 3.104040840303671e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8358093035502773 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 2.64967694781373e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7893016532528808\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9422615180893313 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 2.64967694781373e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7893016532528808\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9422615180893313 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 2.64967694781373e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7893016532528808\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9422615180893313 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:20,099] Trial 48 finished with value: 0.6262877978791115 and parameters: {'num_leaves': 36, 'learning_rate': 0.007547316305121856, 'max_depth': 9, 'min_data_in_leaf': 11, 'subsample': 0.9422615180893313, 'feature_fraction': 0.9998706793508959, 'lambda_l1': 2.64967694781373e-07, 'lambda_l2': 1.0442729031220373e-06, 'n_estimators ': 900, 'bagging_fraction ': 0.7893016532528808, 'bagging_freq': 10, 'class_weight': 2.06005985212132}. Best is trial 22 with value: 0.6316044028753178.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 8.340560134749353e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8157795084921494\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8179683248417998 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 8.340560134749353e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8157795084921494\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8179683248417998 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001396 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 8.340560134749353e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8157795084921494\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8179683248417998 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:20,526] Trial 49 finished with value: 0.6277028023201039 and parameters: {'num_leaves': 61, 'learning_rate': 0.005404077044518291, 'max_depth': 10, 'min_data_in_leaf': 21, 'subsample': 0.8179683248417998, 'feature_fraction': 0.9404258728688147, 'lambda_l1': 8.340560134749353e-08, 'lambda_l2': 0.000782439146859968, 'n_estimators ': 500, 'bagging_fraction ': 0.8157795084921494, 'bagging_freq': 3, 'class_weight': 2.373519840551191}. Best is trial 22 with value: 0.6316044028753178.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.7713874481255982\n",
      "[LightGBM] [Warning] Unknown parameter: 1.6490211918128936e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9866693479513835 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7713874481255982\n",
      "[LightGBM] [Warning] Unknown parameter: 1.6490211918128936e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9866693479513835 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 0.7713874481255982\n",
      "[LightGBM] [Warning] Unknown parameter: 1.6490211918128936e-06\n",
      "[LightGBM] [Warning] Unknown parameter: 200\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9866693479513835 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:20,879] Trial 50 finished with value: 0.6287269275165324 and parameters: {'num_leaves': 44, 'learning_rate': 0.0041070303541509015, 'max_depth': 8, 'min_data_in_leaf': 71, 'subsample': 0.9866693479513835, 'feature_fraction': 0.8291768109671525, 'lambda_l1': 1.6490211918128936e-06, 'lambda_l2': 1.5161998901806175e-05, 'n_estimators ': 200, 'bagging_fraction ': 0.7713874481255982, 'bagging_freq': 9, 'class_weight': 2.184411859129171}. Best is trial 22 with value: 0.6316044028753178.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 3.488660531610282e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9183091892038502\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9255050678482304 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 3.488660531610282e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9183091892038502\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9255050678482304 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 3.488660531610282e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9183091892038502\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9255050678482304 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:21,212] Trial 51 finished with value: 0.6307313073778008 and parameters: {'num_leaves': 29, 'learning_rate': 0.004181290746992364, 'max_depth': 10, 'min_data_in_leaf': 31, 'subsample': 0.9255050678482304, 'feature_fraction': 0.9221548439925624, 'lambda_l1': 3.488660531610282e-07, 'lambda_l2': 1.3015124940326637e-05, 'n_estimators ': 700, 'bagging_fraction ': 0.9183091892038502, 'bagging_freq': 8, 'class_weight': 1.8544023463809507}. Best is trial 22 with value: 0.6316044028753178.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 6.082663903828785e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.92504610799489\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8983285803621672 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 6.082663903828785e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.92504610799489\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8983285803621672 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 6.082663903828785e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.92504610799489\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8983285803621672 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:21,584] Trial 52 finished with value: 0.6300656979190264 and parameters: {'num_leaves': 27, 'learning_rate': 0.0049168807928408505, 'max_depth': 10, 'min_data_in_leaf': 31, 'subsample': 0.8983285803621672, 'feature_fraction': 0.8980152309078843, 'lambda_l1': 6.082663903828785e-07, 'lambda_l2': 4.075923796553782e-05, 'n_estimators ': 700, 'bagging_fraction ': 0.92504610799489, 'bagging_freq': 6, 'class_weight': 1.9179869156465232}. Best is trial 22 with value: 0.6316044028753178.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 2.841104003963438e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9849161817432136\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9681682798174622 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 2.841104003963438e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9849161817432136\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9681682798174622 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 2.841104003963438e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9849161817432136\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9681682798174622 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:21,937] Trial 53 finished with value: 0.6319283975389351 and parameters: {'num_leaves': 25, 'learning_rate': 0.004885850910778597, 'max_depth': 10, 'min_data_in_leaf': 36, 'subsample': 0.9681682798174622, 'feature_fraction': 0.9008181678552182, 'lambda_l1': 2.841104003963438e-08, 'lambda_l2': 2.848055565211517e-06, 'n_estimators ': 700, 'bagging_fraction ': 0.9849161817432136, 'bagging_freq': 7, 'class_weight': 1.9097797727469497}. Best is trial 53 with value: 0.6319283975389351.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 2.4922314997390815e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9954572384031204\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9706635724878309 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 2.4922314997390815e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9954572384031204\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9706635724878309 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 2.4922314997390815e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9954572384031204\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9706635724878309 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:22,248] Trial 54 finished with value: 0.6300063648230256 and parameters: {'num_leaves': 24, 'learning_rate': 0.0036478927813475732, 'max_depth': 10, 'min_data_in_leaf': 41, 'subsample': 0.9706635724878309, 'feature_fraction': 0.9241027018028846, 'lambda_l1': 2.4922314997390815e-08, 'lambda_l2': 3.472847679468174e-06, 'n_estimators ': 800, 'bagging_fraction ': 0.9954572384031204, 'bagging_freq': 7, 'class_weight': 1.7049926671481992}. Best is trial 53 with value: 0.6319283975389351.\n",
      "[I 2023-07-05 16:39:22,528] Trial 55 finished with value: 0.6305310132294824 and parameters: {'num_leaves': 17, 'learning_rate': 0.005451980517911334, 'max_depth': 10, 'min_data_in_leaf': 36, 'subsample': 0.9464574834113517, 'feature_fraction': 0.9521836993857982, 'lambda_l1': 2.073450592628232e-08, 'lambda_l2': 5.878468625134107e-07, 'n_estimators ': 600, 'bagging_fraction ': 0.9630150029513651, 'bagging_freq': 7, 'class_weight': 1.8342293514954564}. Best is trial 53 with value: 0.6319283975389351.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 2.073450592628232e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9630150029513651\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9464574834113517 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 2.073450592628232e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9630150029513651\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9464574834113517 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 2.073450592628232e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9630150029513651\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9464574834113517 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] Unknown parameter: 1.186101030926622e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8760112349557073\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9782039055749329 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.186101030926622e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8760112349557073\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9782039055749329 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 1.186101030926622e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8760112349557073\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9782039055749329 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:22,907] Trial 56 finished with value: 0.6276423904405393 and parameters: {'num_leaves': 37, 'learning_rate': 0.004774579733217177, 'max_depth': 9, 'min_data_in_leaf': 51, 'subsample': 0.9782039055749329, 'feature_fraction': 0.9752770947123773, 'lambda_l1': 1.186101030926622e-07, 'lambda_l2': 2.9356859657401542e-06, 'n_estimators ': 600, 'bagging_fraction ': 0.8760112349557073, 'bagging_freq': 5, 'class_weight': 1.9345552806578903}. Best is trial 53 with value: 0.6319283975389351.\n",
      "[I 2023-07-05 16:39:23,158] Trial 57 finished with value: 0.620554782427335 and parameters: {'num_leaves': 10, 'learning_rate': 0.003970703133365932, 'max_depth': 10, 'min_data_in_leaf': 46, 'subsample': 0.9994459522456194, 'feature_fraction': 0.9262706402009426, 'lambda_l1': 4.59389509409079e-08, 'lambda_l2': 1.0027405961080472e-05, 'n_estimators ': 800, 'bagging_fraction ': 0.9060601608995071, 'bagging_freq': 10, 'class_weight': 2.0217931253555887}. Best is trial 53 with value: 0.6319283975389351.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 4.59389509409079e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9060601608995071\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9994459522456194 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 4.59389509409079e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9060601608995071\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9994459522456194 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 4.59389509409079e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9060601608995071\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9994459522456194 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] Unknown parameter: 1.7154585200573852e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8798190167174198\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9579013665029428 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.7154585200573852e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8798190167174198\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9579013665029428 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000792 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 1.7154585200573852e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.8798190167174198\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9579013665029428 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:23,573] Trial 58 finished with value: 0.6290225142129735 and parameters: {'num_leaves': 40, 'learning_rate': 0.006485900927528769, 'max_depth': 9, 'min_data_in_leaf': 31, 'subsample': 0.9579013665029428, 'feature_fraction': 0.9512244610288342, 'lambda_l1': 1.7154585200573852e-08, 'lambda_l2': 1.7201672316366163e-06, 'n_estimators ': 700, 'bagging_fraction ': 0.8798190167174198, 'bagging_freq': 9, 'class_weight': 1.8150872161471756}. Best is trial 53 with value: 0.6319283975389351.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 1.23642833161507e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.844955666096626\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9270711568670292 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: 1.23642833161507e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.844955666096626\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9270711568670292 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 1.23642833161507e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.844955666096626\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9270711568670292 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:24,006] Trial 59 finished with value: 0.6246048955198118 and parameters: {'num_leaves': 31, 'learning_rate': 0.0042699728602780705, 'max_depth': 10, 'min_data_in_leaf': 86, 'subsample': 0.9270711568670292, 'feature_fraction': 0.8980647024197028, 'lambda_l1': 1.23642833161507e-07, 'lambda_l2': 1.8069466280280018e-05, 'n_estimators ': 900, 'bagging_fraction ': 0.844955666096626, 'bagging_freq': 1, 'class_weight': 1.8604489132152346}. Best is trial 53 with value: 0.6319283975389351.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 2.7854449297537744e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9479982437374505\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9090257718221999 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 2.7854449297537744e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9479982437374505\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9090257718221999 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 2.7854449297537744e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9479982437374505\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9090257718221999 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:24,360] Trial 60 finished with value: 0.625918853900342 and parameters: {'num_leaves': 21, 'learning_rate': 0.0052047938333573815, 'max_depth': 9, 'min_data_in_leaf': 36, 'subsample': 0.9090257718221999, 'feature_fraction': 0.9844311062521532, 'lambda_l1': 2.7854449297537744e-07, 'lambda_l2': 5.615475085733327e-06, 'n_estimators ': 700, 'bagging_fraction ': 0.9479982437374505, 'bagging_freq': 7, 'class_weight': 1.9081996524513665}. Best is trial 53 with value: 0.6319283975389351.\n",
      "[I 2023-07-05 16:39:24,635] Trial 61 finished with value: 0.6273694581989349 and parameters: {'num_leaves': 16, 'learning_rate': 0.004634533120288894, 'max_depth': 10, 'min_data_in_leaf': 41, 'subsample': 0.9457115586792729, 'feature_fraction': 0.9562832598242509, 'lambda_l1': 1.988303091580068e-08, 'lambda_l2': 7.148753762056075e-07, 'n_estimators ': 600, 'bagging_fraction ': 0.9850781097446568, 'bagging_freq': 7, 'class_weight': 1.8275122799523635}. Best is trial 53 with value: 0.6319283975389351.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 1.988303091580068e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9850781097446568\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9457115586792729 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.988303091580068e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9850781097446568\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9457115586792729 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 1.988303091580068e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9850781097446568\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9457115586792729 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] Unknown parameter: 4.0305919122981634e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9600474459948141\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9536378353963898 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 4.0305919122981634e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9600474459948141\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9536378353963898 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 4.0305919122981634e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9600474459948141\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9536378353963898 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:25,034] Trial 62 finished with value: 0.6288096342564125 and parameters: {'num_leaves': 49, 'learning_rate': 0.005622615379480439, 'max_depth': 10, 'min_data_in_leaf': 21, 'subsample': 0.9536378353963898, 'feature_fraction': 0.9532033704200809, 'lambda_l1': 4.0305919122981634e-08, 'lambda_l2': 6.268396339960387e-07, 'n_estimators ': 600, 'bagging_fraction ': 0.9600474459948141, 'bagging_freq': 6, 'class_weight': 1.9639372089229716}. Best is trial 53 with value: 0.6319283975389351.\n",
      "[I 2023-07-05 16:39:25,326] Trial 63 finished with value: 0.6245088837826467 and parameters: {'num_leaves': 15, 'learning_rate': 0.005775910981890288, 'max_depth': 10, 'min_data_in_leaf': 56, 'subsample': 0.9809396980852334, 'feature_fraction': 0.9805122443444958, 'lambda_l1': 1.0717949276422941e-08, 'lambda_l2': 3.866587569462659e-07, 'n_estimators ': 800, 'bagging_fraction ': 0.9721087587683795, 'bagging_freq': 8, 'class_weight': 1.7352509182085285}. Best is trial 53 with value: 0.6319283975389351.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 1.0717949276422941e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9721087587683795\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9809396980852334 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 1.0717949276422941e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9721087587683795\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9809396980852334 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 1.0717949276422941e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9721087587683795\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9809396980852334 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:25,592] Trial 64 finished with value: 0.6304558579745478 and parameters: {'num_leaves': 19, 'learning_rate': 0.0051417151724570806, 'max_depth': 9, 'min_data_in_leaf': 36, 'subsample': 0.9290033891343737, 'feature_fraction': 0.9329252628413728, 'lambda_l1': 8.986574269978284e-08, 'lambda_l2': 1.4142683499269867e-06, 'n_estimators ': 500, 'bagging_fraction ': 0.932738413313001, 'bagging_freq': 5, 'class_weight': 1.6497638168685924}. Best is trial 53 with value: 0.6319283975389351.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 8.986574269978284e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.932738413313001\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9290033891343737 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 8.986574269978284e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.932738413313001\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9290033891343737 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 8.986574269978284e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 500\n",
      "[LightGBM] [Warning] Unknown parameter: 0.932738413313001\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9290033891343737 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] Unknown parameter: 2.648902844203799e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.973335559746615\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9658279596724264 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 2.648902844203799e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.973335559746615\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9658279596724264 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 2.648902844203799e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 600\n",
      "[LightGBM] [Warning] Unknown parameter: 0.973335559746615\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9658279596724264 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:25,940] Trial 65 finished with value: 0.631781323379757 and parameters: {'num_leaves': 34, 'learning_rate': 0.004348760293191523, 'max_depth': 9, 'min_data_in_leaf': 26, 'subsample': 0.9658279596724264, 'feature_fraction': 0.9172225877340059, 'lambda_l1': 2.648902844203799e-08, 'lambda_l2': 7.822118579006507e-06, 'n_estimators ': 600, 'bagging_fraction ': 0.973335559746615, 'bagging_freq': 7, 'class_weight': 2.026371940504775}. Best is trial 53 with value: 0.6319283975389351.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.981499859372657\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 3.800337976961895e-08\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.998640514742306 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.981499859372657\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 3.800337976961895e-08\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.998640514742306 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 0.981499859372657\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 3.800337976961895e-08\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.998640514742306 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:26,268] Trial 66 finished with value: 0.6310362435317936 and parameters: {'num_leaves': 34, 'learning_rate': 0.003925199666091728, 'max_depth': 9, 'min_data_in_leaf': 16, 'subsample': 0.998640514742306, 'feature_fraction': 0.8702560838400503, 'lambda_l1': 3.800337976961895e-08, 'lambda_l2': 8.262420610050197e-06, 'n_estimators ': 800, 'bagging_fraction ': 0.981499859372657, 'bagging_freq': 6, 'class_weight': 2.0290098038773707}. Best is trial 53 with value: 0.6319283975389351.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 6.182596054599355e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9761303241533985\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9991304245582504 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 6.182596054599355e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9761303241533985\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9991304245582504 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 6.182596054599355e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9761303241533985\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9991304245582504 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:26,582] Trial 67 finished with value: 0.6315047951929404 and parameters: {'num_leaves': 33, 'learning_rate': 0.0038800993159990175, 'max_depth': 9, 'min_data_in_leaf': 26, 'subsample': 0.9991304245582504, 'feature_fraction': 0.8636175394356076, 'lambda_l1': 6.182596054599355e-08, 'lambda_l2': 2.7212973131195308e-05, 'n_estimators ': 800, 'bagging_fraction ': 0.9761303241533985, 'bagging_freq': 6, 'class_weight': 2.0344905177144126}. Best is trial 53 with value: 0.6319283975389351.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 6.37828422848302e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9781039332699824\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9962038485612221 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 6.37828422848302e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9781039332699824\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9962038485612221 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 6.37828422848302e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9781039332699824\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9962038485612221 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:26,920] Trial 68 finished with value: 0.6308582442437907 and parameters: {'num_leaves': 33, 'learning_rate': 0.003841130900323832, 'max_depth': 8, 'min_data_in_leaf': 26, 'subsample': 0.9962038485612221, 'feature_fraction': 0.866533914905068, 'lambda_l1': 6.37828422848302e-08, 'lambda_l2': 7.954530610413113e-06, 'n_estimators ': 800, 'bagging_fraction ': 0.9781039332699824, 'bagging_freq': 5, 'class_weight': 2.0226980499848217}. Best is trial 53 with value: 0.6319283975389351.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 4.366456276475494e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9966780920864362\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9669250941796648 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 4.366456276475494e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9966780920864362\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9669250941796648 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 4.366456276475494e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9966780920864362\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9669250941796648 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:27,253] Trial 69 finished with value: 0.6301768126260829 and parameters: {'num_leaves': 34, 'learning_rate': 0.0034570363311678554, 'max_depth': 9, 'min_data_in_leaf': 21, 'subsample': 0.9669250941796648, 'feature_fraction': 0.8643174974594204, 'lambda_l1': 4.366456276475494e-08, 'lambda_l2': 0.00012384408020211558, 'n_estimators ': 1000, 'bagging_fraction ': 0.9966780920864362, 'bagging_freq': 6, 'class_weight': 2.1175952210495246}. Best is trial 53 with value: 0.6319283975389351.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 1.5795020548826268e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9510171361442683\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.988743442758271 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.5795020548826268e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9510171361442683\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.988743442758271 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 1.5795020548826268e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9510171361442683\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.988743442758271 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:27,734] Trial 70 finished with value: 0.6295263061371997 and parameters: {'num_leaves': 39, 'learning_rate': 0.0043692011459348, 'max_depth': 9, 'min_data_in_leaf': 16, 'subsample': 0.988743442758271, 'feature_fraction': 0.8890976049627062, 'lambda_l1': 1.5795020548826268e-07, 'lambda_l2': 2.8525607312192437e-05, 'n_estimators ': 800, 'bagging_fraction ': 0.9510171361442683, 'bagging_freq': 4, 'class_weight': 2.0103048824660403}. Best is trial 53 with value: 0.6319283975389351.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 8.641684937288648e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.976089285311081\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9944535495435488 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 8.641684937288648e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.976089285311081\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9944535495435488 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 8.641684937288648e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.976089285311081\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9944535495435488 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:28,109] Trial 71 finished with value: 0.6312635072692032 and parameters: {'num_leaves': 34, 'learning_rate': 0.003927667064271418, 'max_depth': 8, 'min_data_in_leaf': 26, 'subsample': 0.9944535495435488, 'feature_fraction': 0.8657439661191633, 'lambda_l1': 8.641684937288648e-08, 'lambda_l2': 7.494206308199106e-06, 'n_estimators ': 900, 'bagging_fraction ': 0.976089285311081, 'bagging_freq': 5, 'class_weight': 2.047462416556975}. Best is trial 53 with value: 0.6319283975389351.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 2.2400149358841078e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9396602576115904\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9870969665761603 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 2.2400149358841078e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9396602576115904\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9870969665761603 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001249 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 2.2400149358841078e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9396602576115904\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9870969665761603 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:28,458] Trial 72 finished with value: 0.6312128044417116 and parameters: {'num_leaves': 37, 'learning_rate': 0.003931443351305951, 'max_depth': 9, 'min_data_in_leaf': 26, 'subsample': 0.9870969665761603, 'feature_fraction': 0.9115410439840486, 'lambda_l1': 2.2400149358841078e-08, 'lambda_l2': 3.648987235361373e-06, 'n_estimators ': 800, 'bagging_fraction ': 0.9396602576115904, 'bagging_freq': 5, 'class_weight': 2.094612430469737}. Best is trial 53 with value: 0.6319283975389351.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 2.4271017119446014e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.93967773949379\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9654501581091365 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 2.4271017119446014e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.93967773949379\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9654501581091365 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 2.4271017119446014e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.93967773949379\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9654501581091365 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:28,807] Trial 73 finished with value: 0.631431437910612 and parameters: {'num_leaves': 37, 'learning_rate': 0.0036025204813351463, 'max_depth': 8, 'min_data_in_leaf': 26, 'subsample': 0.9654501581091365, 'feature_fraction': 0.9144334048597879, 'lambda_l1': 2.4271017119446014e-08, 'lambda_l2': 2.67708090628373e-06, 'n_estimators ': 900, 'bagging_fraction ': 0.93967773949379, 'bagging_freq': 4, 'class_weight': 2.0956821420222673}. Best is trial 53 with value: 0.6319283975389351.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 2.2326946124730182e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9460448439003315\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9642231997519085 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 2.2326946124730182e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9460448439003315\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9642231997519085 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 2.2326946124730182e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9460448439003315\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9642231997519085 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:29,164] Trial 74 finished with value: 0.6299366034859093 and parameters: {'num_leaves': 41, 'learning_rate': 0.0031464395956862273, 'max_depth': 8, 'min_data_in_leaf': 26, 'subsample': 0.9642231997519085, 'feature_fraction': 0.8843004344097761, 'lambda_l1': 2.2326946124730182e-08, 'lambda_l2': 2.5883778921070492e-06, 'n_estimators ': 900, 'bagging_fraction ': 0.9460448439003315, 'bagging_freq': 4, 'class_weight': 2.0944520358201486}. Best is trial 53 with value: 0.6319283975389351.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 1.500821743026597e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9670809623552883\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.983902030110583 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.500821743026597e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9670809623552883\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.983902030110583 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 1.500821743026597e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9670809623552883\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.983902030110583 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:29,564] Trial 75 finished with value: 0.6305223829609732 and parameters: {'num_leaves': 43, 'learning_rate': 0.003600170465471043, 'max_depth': 8, 'min_data_in_leaf': 26, 'subsample': 0.983902030110583, 'feature_fraction': 0.9112471966954854, 'lambda_l1': 1.500821743026597e-08, 'lambda_l2': 4.324466919175657e-06, 'n_estimators ': 900, 'bagging_fraction ': 0.9670809623552883, 'bagging_freq': 5, 'class_weight': 2.1655703320361024}. Best is trial 53 with value: 0.6319283975389351.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 7.484754428224274e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9962154065263523\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9573880427094217 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: 7.484754428224274e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9962154065263523\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9573880427094217 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 7.484754428224274e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9962154065263523\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9573880427094217 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:29,973] Trial 76 finished with value: 0.6281512166880625 and parameters: {'num_leaves': 31, 'learning_rate': 0.0033797605253699453, 'max_depth': 7, 'min_data_in_leaf': 31, 'subsample': 0.9573880427094217, 'feature_fraction': 0.8874296365613971, 'lambda_l1': 7.484754428224274e-08, 'lambda_l2': 6.337427585357465e-06, 'n_estimators ': 1000, 'bagging_fraction ': 0.9962154065263523, 'bagging_freq': 3, 'class_weight': 2.1232201694867214}. Best is trial 53 with value: 0.6319283975389351.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 2.6616197443880527e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9373639803577308\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9723507504406298 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 2.6616197443880527e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9373639803577308\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9723507504406298 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 2.6616197443880527e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9373639803577308\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9723507504406298 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:30,411] Trial 77 finished with value: 0.6289786436813849 and parameters: {'num_leaves': 39, 'learning_rate': 0.003776373936109449, 'max_depth': 8, 'min_data_in_leaf': 21, 'subsample': 0.9723507504406298, 'feature_fraction': 0.8456260476331691, 'lambda_l1': 2.6616197443880527e-08, 'lambda_l2': 1.2717533999098534e-06, 'n_estimators ': 900, 'bagging_fraction ': 0.9373639803577308, 'bagging_freq': 3, 'class_weight': 2.0571869385739032}. Best is trial 53 with value: 0.6319283975389351.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.9582805020633851\n",
      "[LightGBM] [Warning] Unknown parameter: 1.8711099293400008e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9383417736832568 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9582805020633851\n",
      "[LightGBM] [Warning] Unknown parameter: 1.8711099293400008e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9383417736832568 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9582805020633851\n",
      "[LightGBM] [Warning] Unknown parameter: 1.8711099293400008e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9383417736832568 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:30,787] Trial 78 finished with value: 0.6317827617578419 and parameters: {'num_leaves': 35, 'learning_rate': 0.004476853579279726, 'max_depth': 8, 'min_data_in_leaf': 36, 'subsample': 0.9383417736832568, 'feature_fraction': 0.936070395304059, 'lambda_l1': 1.8711099293400008e-07, 'lambda_l2': 2.402798492884111e-06, 'n_estimators ': 900, 'bagging_fraction ': 0.9582805020633851, 'bagging_freq': 4, 'class_weight': 2.250022198829456}. Best is trial 53 with value: 0.6319283975389351.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 8.194265626784675e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9589882170360278\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9369069121229616 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 8.194265626784675e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9589882170360278\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9369069121229616 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 8.194265626784675e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9589882170360278\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9369069121229616 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:31,117] Trial 79 finished with value: 0.6318237555332606 and parameters: {'num_leaves': 26, 'learning_rate': 0.004437799930213437, 'max_depth': 8, 'min_data_in_leaf': 36, 'subsample': 0.9369069121229616, 'feature_fraction': 0.9357917761154968, 'lambda_l1': 8.194265626784675e-08, 'lambda_l2': 1.955023337783153e-06, 'n_estimators ': 900, 'bagging_fraction ': 0.9589882170360278, 'bagging_freq': 4, 'class_weight': 2.2394472281754867}. Best is trial 53 with value: 0.6319283975389351.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 1.7796365677076344e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9694667564937\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9410257258520445 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.7796365677076344e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9694667564937\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9410257258520445 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 1.7796365677076344e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9694667564937\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9410257258520445 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:31,507] Trial 80 finished with value: 0.6275111384402947 and parameters: {'num_leaves': 25, 'learning_rate': 0.004505446984775108, 'max_depth': 7, 'min_data_in_leaf': 46, 'subsample': 0.9410257258520445, 'feature_fraction': 0.9389511611967203, 'lambda_l1': 1.7796365677076344e-07, 'lambda_l2': 1.6378684972701825e-06, 'n_estimators ': 1000, 'bagging_fraction ': 0.9694667564937, 'bagging_freq': 4, 'class_weight': 2.2401559463952077}. Best is trial 53 with value: 0.6319283975389351.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 7.616254315309348e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9565353079614802\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9550563683379939 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 7.616254315309348e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9565353079614802\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9550563683379939 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 7.616254315309348e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9565353079614802\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9550563683379939 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:31,980] Trial 81 finished with value: 0.6299308499735697 and parameters: {'num_leaves': 34, 'learning_rate': 0.004920189011352356, 'max_depth': 8, 'min_data_in_leaf': 41, 'subsample': 0.9550563683379939, 'feature_fraction': 0.9300117040930288, 'lambda_l1': 7.616254315309348e-08, 'lambda_l2': 2.469768321349658e-06, 'n_estimators ': 900, 'bagging_fraction ': 0.9565353079614802, 'bagging_freq': 4, 'class_weight': 2.2000289732086777}. Best is trial 53 with value: 0.6319283975389351.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 4.25224503520193e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9840889005325753\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9362332893715343 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 4.25224503520193e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9840889005325753\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9362332893715343 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 4.25224503520193e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9840889005325753\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9362332893715343 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:32,319] Trial 82 finished with value: 0.6322024085641031 and parameters: {'num_leaves': 30, 'learning_rate': 0.004219758189782658, 'max_depth': 8, 'min_data_in_leaf': 36, 'subsample': 0.9362332893715343, 'feature_fraction': 0.8937933398194204, 'lambda_l1': 4.25224503520193e-07, 'lambda_l2': 3.0176736592635215e-05, 'n_estimators ': 900, 'bagging_fraction ': 0.9840889005325753, 'bagging_freq': 3, 'class_weight': 2.1604336555878745}. Best is trial 82 with value: 0.6322024085641031.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 1.192618538252155e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9863643265317371\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9182617123685405 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.192618538252155e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9863643265317371\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9182617123685405 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 1.192618538252155e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9863643265317371\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9182617123685405 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:32,634] Trial 83 finished with value: 0.6298531775569868 and parameters: {'num_leaves': 27, 'learning_rate': 0.004322427680959831, 'max_depth': 7, 'min_data_in_leaf': 36, 'subsample': 0.9182617123685405, 'feature_fraction': 0.9675899631769782, 'lambda_l1': 1.192618538252155e-08, 'lambda_l2': 2.9362170895042246e-05, 'n_estimators ': 900, 'bagging_fraction ': 0.9863643265317371, 'bagging_freq': 3, 'class_weight': 2.2479688955993224}. Best is trial 82 with value: 0.6322024085641031.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 3.7199878560259113e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9526243027729121\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9369228607995367 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: 3.7199878560259113e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9526243027729121\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9369228607995367 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000928 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 3.7199878560259113e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9526243027729121\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9369228607995367 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:33,053] Trial 84 finished with value: 0.6273176765878795 and parameters: {'num_leaves': 31, 'learning_rate': 0.004770950478297562, 'max_depth': 6, 'min_data_in_leaf': 36, 'subsample': 0.9369228607995367, 'feature_fraction': 0.900082579432007, 'lambda_l1': 3.7199878560259113e-07, 'lambda_l2': 6.852174667460991e-05, 'n_estimators ': 1000, 'bagging_fraction ': 0.9526243027729121, 'bagging_freq': 2, 'class_weight': 2.1683129446632994}. Best is trial 82 with value: 0.6322024085641031.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 5.041845266071376e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9993952909419417\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9170776578298819 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 5.041845266071376e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9993952909419417\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9170776578298819 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 5.041845266071376e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9993952909419417\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9170776578298819 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:33,446] Trial 85 finished with value: 0.6313372241460529 and parameters: {'num_leaves': 28, 'learning_rate': 0.003605043969849012, 'max_depth': 8, 'min_data_in_leaf': 41, 'subsample': 0.9170776578298819, 'feature_fraction': 0.9156490609084897, 'lambda_l1': 5.041845266071376e-08, 'lambda_l2': 9.908987522022605e-07, 'n_estimators ': 900, 'bagging_fraction ': 0.9993952909419417, 'bagging_freq': 3, 'class_weight': 2.3229461723972595}. Best is trial 82 with value: 0.6322024085641031.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 1.4400406007439226e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9674017201592137\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9123258377901606 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 1.4400406007439226e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9674017201592137\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9123258377901606 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000782 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 1.4400406007439226e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9674017201592137\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9123258377901606 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:33,801] Trial 86 finished with value: 0.6298075090527921 and parameters: {'num_leaves': 22, 'learning_rate': 0.004133751733955712, 'max_depth': 8, 'min_data_in_leaf': 41, 'subsample': 0.9123258377901606, 'feature_fraction': 0.9178232592067469, 'lambda_l1': 1.4400406007439226e-07, 'lambda_l2': 9.139693607888611e-07, 'n_estimators ': 900, 'bagging_fraction ': 0.9674017201592137, 'bagging_freq': 2, 'class_weight': 2.3306668084700464}. Best is trial 82 with value: 0.6322024085641031.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 4.914278445860161e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9994338364656181\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8907720550195103 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 4.914278445860161e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9994338364656181\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8907720550195103 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 4.914278445860161e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 1000\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9994338364656181\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.8907720550195103 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:34,221] Trial 87 finished with value: 0.6313329090117983 and parameters: {'num_leaves': 30, 'learning_rate': 0.003598918948450769, 'max_depth': 8, 'min_data_in_leaf': 46, 'subsample': 0.8907720550195103, 'feature_fraction': 0.8961683003774585, 'lambda_l1': 4.914278445860161e-08, 'lambda_l2': 3.0093084592150967e-07, 'n_estimators ': 1000, 'bagging_fraction ': 0.9994338364656181, 'bagging_freq': 3, 'class_weight': 2.243585929350659}. Best is trial 82 with value: 0.6322024085641031.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 4.846436962671796e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9828632467913964\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9338382639451178 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 4.846436962671796e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9828632467913964\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9338382639451178 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 4.846436962671796e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 900\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9828632467913964\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9338382639451178 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:34,599] Trial 88 finished with value: 0.6267139173867546 and parameters: {'num_leaves': 27, 'learning_rate': 0.003258694382788176, 'max_depth': 7, 'min_data_in_leaf': 31, 'subsample': 0.9338382639451178, 'feature_fraction': 0.9363346039489495, 'lambda_l1': 4.846436962671796e-07, 'lambda_l2': 2.3692411677295106e-06, 'n_estimators ': 900, 'bagging_fraction ': 0.9828632467913964, 'bagging_freq': 3, 'class_weight': 2.2829364343050935}. Best is trial 82 with value: 0.6322024085641031.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 2.1536980969018327e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 0.962829158888462\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9676490825641553 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 2.1536980969018327e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 0.962829158888462\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9676490825641553 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 2.1536980969018327e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 0.962829158888462\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9676490825641553 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:35,003] Trial 89 finished with value: 0.6331524572891607 and parameters: {'num_leaves': 25, 'learning_rate': 0.00296161351483226, 'max_depth': 8, 'min_data_in_leaf': 36, 'subsample': 0.9676490825641553, 'feature_fraction': 0.8803742086096629, 'lambda_l1': 2.1536980969018327e-07, 'lambda_l2': 1.960534853398418e-05, 'n_estimators ': 800, 'bagging_fraction ': 0.962829158888462, 'bagging_freq': 4, 'class_weight': 2.4244840682793427}. Best is trial 89 with value: 0.6331524572891607.\n",
      "[I 2023-07-05 16:39:35,226] Trial 90 finished with value: 0.6179897947074879 and parameters: {'num_leaves': 23, 'learning_rate': 0.002698820236775463, 'max_depth': 3, 'min_data_in_leaf': 31, 'subsample': 0.9654233057735854, 'feature_fraction': 0.8789718195230879, 'lambda_l1': 2.2715553697452648e-07, 'lambda_l2': 2.456150160700913e-05, 'n_estimators ': 700, 'bagging_fraction ': 0.9086331425107969, 'bagging_freq': 4, 'class_weight': 2.1483804301572578}. Best is trial 89 with value: 0.6331524572891607.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 2.2715553697452648e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9086331425107969\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9654233057735854 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 2.2715553697452648e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9086331425107969\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9654233057735854 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 2.2715553697452648e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9086331425107969\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9654233057735854 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 3.6340651885013824e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9358112227608949\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9488364501291346 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 3.6340651885013824e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9358112227608949\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9488364501291346 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 3.6340651885013824e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9358112227608949\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9488364501291346 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:35,746] Trial 91 finished with value: 0.6323282666465294 and parameters: {'num_leaves': 26, 'learning_rate': 0.004553790795000927, 'max_depth': 8, 'min_data_in_leaf': 36, 'subsample': 0.9488364501291346, 'feature_fraction': 0.9088295108648875, 'lambda_l1': 3.6340651885013824e-08, 'lambda_l2': 4.0953920694127834e-06, 'n_estimators ': 800, 'bagging_fraction ': 0.9358112227608949, 'bagging_freq': 3, 'class_weight': 2.43559945328534}. Best is trial 89 with value: 0.6331524572891607.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 3.193660725496504e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9305817842363305\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9522028951850573 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 3.193660725496504e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9305817842363305\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9522028951850573 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 3.193660725496504e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9305817842363305\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9522028951850573 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:36,071] Trial 92 finished with value: 0.6332337256509559 and parameters: {'num_leaves': 25, 'learning_rate': 0.004260493067538696, 'max_depth': 8, 'min_data_in_leaf': 36, 'subsample': 0.9522028951850573, 'feature_fraction': 0.9058339838867653, 'lambda_l1': 3.193660725496504e-08, 'lambda_l2': 4.126176076140308e-06, 'n_estimators ': 800, 'bagging_fraction ': 0.9305817842363305, 'bagging_freq': 4, 'class_weight': 2.4245455888249845}. Best is trial 92 with value: 0.6332337256509559.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 1.0954868664711697e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9596149097826369\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9476241102142599 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 1.0954868664711697e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9596149097826369\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9476241102142599 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 1.0954868664711697e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9596149097826369\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9476241102142599 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:36,470] Trial 93 finished with value: 0.6321337260105505 and parameters: {'num_leaves': 25, 'learning_rate': 0.004395290013799156, 'max_depth': 8, 'min_data_in_leaf': 36, 'subsample': 0.9476241102142599, 'feature_fraction': 0.8908401217897581, 'lambda_l1': 1.0954868664711697e-07, 'lambda_l2': 4.850310798474885e-06, 'n_estimators ': 800, 'bagging_fraction ': 0.9596149097826369, 'bagging_freq': 2, 'class_weight': 2.4309720447583643}. Best is trial 92 with value: 0.6332337256509559.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 1.119296358809233e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9287769070237204\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9488187861744762 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 1.119296358809233e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9287769070237204\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9488187861744762 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 1.119296358809233e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9287769070237204\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9488187861744762 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:36,818] Trial 94 finished with value: 0.6327939415515065 and parameters: {'num_leaves': 24, 'learning_rate': 0.004503485220103209, 'max_depth': 8, 'min_data_in_leaf': 36, 'subsample': 0.9488187861744762, 'feature_fraction': 0.9013657088899424, 'lambda_l1': 1.119296358809233e-07, 'lambda_l2': 1.2108021971478608e-05, 'n_estimators ': 700, 'bagging_fraction ': 0.9287769070237204, 'bagging_freq': 2, 'class_weight': 2.456131609531087}. Best is trial 92 with value: 0.6332337256509559.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.9287067054716948\n",
      "[LightGBM] [Warning] Unknown parameter: 2.3640985949545355e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.949956479313269 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9287067054716948\n",
      "[LightGBM] [Warning] Unknown parameter: 2.3640985949545355e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.949956479313269 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9287067054716948\n",
      "[LightGBM] [Warning] Unknown parameter: 2.3640985949545355e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.949956479313269 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:37,183] Trial 95 finished with value: 0.6314828599271461 and parameters: {'num_leaves': 25, 'learning_rate': 0.00445376971710899, 'max_depth': 7, 'min_data_in_leaf': 36, 'subsample': 0.949956479313269, 'feature_fraction': 0.8887569479423759, 'lambda_l1': 2.3640985949545355e-07, 'lambda_l2': 5.757085723256039e-06, 'n_estimators ': 700, 'bagging_fraction ': 0.9287067054716948, 'bagging_freq': 1, 'class_weight': 2.4345594635911714}. Best is trial 92 with value: 0.6332337256509559.\n",
      "[I 2023-07-05 16:39:37,452] Trial 96 finished with value: 0.6298862602529388 and parameters: {'num_leaves': 20, 'learning_rate': 0.0046310208006802136, 'max_depth': 8, 'min_data_in_leaf': 41, 'subsample': 0.9039850952523526, 'feature_fraction': 0.9049623284329199, 'lambda_l1': 4.1308120685912114e-07, 'lambda_l2': 1.0896847192563292e-05, 'n_estimators ': 800, 'bagging_fraction ': 0.9185755673817978, 'bagging_freq': 2, 'class_weight': 2.478272494550883}. Best is trial 92 with value: 0.6332337256509559.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 4.1308120685912114e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9185755673817978\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9039850952523526 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 4.1308120685912114e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9185755673817978\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9039850952523526 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 4.1308120685912114e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9185755673817978\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9039850952523526 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:37,746] Trial 97 finished with value: 0.6320977665584286 and parameters: {'num_leaves': 24, 'learning_rate': 0.004153523606718871, 'max_depth': 8, 'min_data_in_leaf': 36, 'subsample': 0.9391381415062267, 'feature_fraction': 0.8781794866891427, 'lambda_l1': 1.1881535658078354e-07, 'lambda_l2': 4.936770573014319e-06, 'n_estimators ': 800, 'bagging_fraction ': 0.9577064837636792, 'bagging_freq': 2, 'class_weight': 2.4085381959493026}. Best is trial 92 with value: 0.6332337256509559.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.9577064837636792\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 1.1881535658078354e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9391381415062267 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9577064837636792\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 1.1881535658078354e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9391381415062267 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9577064837636792\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: 1.1881535658078354e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9391381415062267 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 9.651685623255915e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9579933311182859\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9338743888605222 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 9.651685623255915e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9579933311182859\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9338743888605222 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 9.651685623255915e-08\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9579933311182859\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9338743888605222 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:39:38,117] Trial 98 finished with value: 0.6290883200103563 and parameters: {'num_leaves': 24, 'learning_rate': 0.004136844777845171, 'max_depth': 7, 'min_data_in_leaf': 46, 'subsample': 0.9338743888605222, 'feature_fraction': 0.875953399766414, 'lambda_l1': 9.651685623255915e-08, 'lambda_l2': 4.743884384208893e-06, 'n_estimators ': 800, 'bagging_fraction ': 0.9579933311182859, 'bagging_freq': 2, 'class_weight': 2.3992945346944943}. Best is trial 92 with value: 0.6332337256509559.\n",
      "[I 2023-07-05 16:39:38,404] Trial 99 finished with value: 0.6323908360932213 and parameters: {'num_leaves': 26, 'learning_rate': 0.00458306008851503, 'max_depth': 8, 'min_data_in_leaf': 36, 'subsample': 0.9179091916407337, 'feature_fraction': 0.8973587303246061, 'lambda_l1': 7.191009569514902e-07, 'lambda_l2': 1.75467488391904e-06, 'n_estimators ': 700, 'bagging_fraction ': 0.9483962696093252, 'bagging_freq': 2, 'class_weight': 2.434250876449221}. Best is trial 92 with value: 0.6332337256509559.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 0.9483962696093252\n",
      "[LightGBM] [Warning] Unknown parameter: 7.191009569514902e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9179091916407337 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9483962696093252\n",
      "[LightGBM] [Warning] Unknown parameter: 7.191009569514902e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9179091916407337 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 9470, number of negative: 2400\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9483962696093252\n",
      "[LightGBM] [Warning] Unknown parameter: 7.191009569514902e-07\n",
      "[LightGBM] [Warning] Unknown parameter: 700\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9179091916407337 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797810 -> initscore=1.372660\n",
      "[LightGBM] [Info] Start training from score 1.372660\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "best_params = study.best_params\n",
    "best_score = study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "94dafe21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best parameters are:  {'num_leaves': 25, 'learning_rate': 0.004260493067538696, 'max_depth': 8, 'min_data_in_leaf': 36, 'subsample': 0.9522028951850573, 'feature_fraction': 0.9058339838867653, 'lambda_l1': 3.193660725496504e-08, 'lambda_l2': 4.126176076140308e-06, 'n_estimators ': 800, 'bagging_fraction ': 0.9305817842363305, 'bagging_freq': 4, 'class_weight': 2.4245455888249845}\n",
      "The best score is:  0.6332337256509559\n"
     ]
    }
   ],
   "source": [
    "print('the best parameters are: ', best_params)\n",
    "print('The best score is: ', best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f71000",
   "metadata": {},
   "source": [
    "Past parameters:\n",
    "- the best parameters are:  {'num_leaves': 45, 'learning_rate': 0.029704349076036314, 'max_depth': 9, 'min_data_in_leaf': 21, 'subsample': 0.6672871413439366, 'feature_fraction': 0.8731116044469396, 'lambda_l1': 0.7885863792026873, 'lambda_l2': 7.034545307172499, 'n_estimators ': 300, 'bagging_fraction ': 0.6497112995391534, 'bagging_freq': 3, 'class_weight': 1.0985561072882906}  |The best score is:  **0.6296647500278685**\n",
    "\n",
    "- the best parameters are:  {'num_leaves': 30, 'learning_rate': 0.048345246765815086, 'max_depth': 8, 'min_data_in_leaf': 36, 'subsample': 0.6901903386991659, 'feature_fraction': 0.9200133987323398, 'lambda_l1': 1.0189868698753211e-06, 'lambda_l2': 1.4853721407129861e-06, 'n_estimators ': 700, 'bagging_fraction ': 0.6719118111644993, 'bagging_freq': 3, 'class_weight': 1.9528305943641768}|The best score is:  **0.6297352305540272**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a540afd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9305817842363305\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9522028951850573 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9305817842363305\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9522028951850573 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6243\n",
      "[LightGBM] [Info] Number of data points in the train set: 11870, number of used features: 32\n",
      "[LightGBM] [Warning] Unknown parameter: 800\n",
      "[LightGBM] [Warning] Unknown parameter: 0.9305817842363305\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] bagging_fraction is set=, subsample=0.9522028951850573 will be ignored. Current value: bagging_fraction=\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Start training from score 0.797810\n",
      "Train Accuracy score is: 0.797809604043808\n",
      "Test Accuracy score is: 0.8035714285714286\n",
      "ROCAUC score is: 0.6300897907519482\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       583\n",
      "           1       0.80      1.00      0.89      2385\n",
      "\n",
      "    accuracy                           0.80      2968\n",
      "   macro avg       0.40      0.50      0.45      2968\n",
      "weighted avg       0.65      0.80      0.72      2968\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEECAYAAAAxqm/oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAem0lEQVR4nO3de3RU5b3/8fdMkgkxFyNGQSoBAgS1qykERC2QI5QYflgFgRASVwQDKHiK5SJyv1RQwB9BkRpbEIoGQoICFoUqAkpaDqU2SLg1IuFqkbtgJpALzD5/cBhFDTOByWR25vNaa9bK7OzZ+ztZrg9fn/08e1sMwzAQERHTsdZ2ASIicn0U4CIiJqUAFxExKQW4iIhJKcBFREwqsLYL+KGcbXNruwTxQRsO1HYF4osW9v7dDR/jF/Gj3N5357bMGz6fJ6kDFxExKZ/rwEVEvMpS2wVcPwW4iPg3i3kTXAEuIv7NvPmtABcRP6cOXETEnAzz5rcCXET8nAJcRMSkTDyEonngIiImpQ5cRPybeRtwBbiI+DmreRNcAS4ifs3MjyRTgIuIfzPxRUwFuIj4N/PmtwJcRPydeRNcAS4i/s3Ek6kV4CLi1wwTj4Gb+N8eERH/pg5cRPybiTtwBbiI+Dfz5rcCXET8mxbyiIiYlZbSi4iYlMbARUTMSUMoIiJmZd4GXAEuIn7OxEMoWsgjImJS6sBFxK8ZJp6Fog5cRMSk1IGLiF8z882sFOAi4t/Mm98KcBHxcwpwERFz8tQQSmVlJePHj+c///kPFRUVDB06lBYtWjB27FgsFgstW7ZkypQpWK1Wli9fTm5uLoGBgQwdOpTOnTtTVlbG6NGjOX36NKGhocyaNYv69etf85y6iCki/s1Sjdc1rF69msjISHJycliwYAHTpk1jxowZDB8+nJycHAzDYMOGDZw8eZLs7Gxyc3NZuHAhc+bMoaKigmXLlhEbG0tOTg49e/YkKyvLZenqwEXEz7nfgefl5ZGXl+d8n5KSQkpKCgDdunUjKSnJ+buAgAB2795N+/btAUhISGDz5s1YrVbatGmDzWbDZrMRHR1NUVERBQUFDBo0yLmvAlxExAWjGiMo3w/sHwoNDQXAbrfz7LPPMnz4cGbNmoXl/4ZoQkNDKSkpwW63Ex4eftXn7Hb7Vduv7OuKhlBExL95aAgF4Ouvv+aJJ56gR48ePPLII1it30VsaWkpERERhIWFUVpaetX28PDwq7Zf2dcVBbiI+DnPJPipU6fIyMhg9OjR9OnTB4B77rmHrVu3ApCfn0+7du2Ii4ujoKCA8vJySkpKKC4uJjY2lvj4eDZt2uTct23bti4r1xCKiPg1w0Nt7B//+Ee+/fZbsrKynOPXEyZMYPr06cyZM4eYmBiSkpIICAggPT2dtLQ0DMNgxIgRBAcHk5qaypgxY0hNTSUoKIjMzEyX57QYhuFTt8PN2Ta3tksQH7ThQG1XIL5oYe/f3fAxmvee7va+xSsm3vD5PEkduIj4Ny3kERExp+rMQvE1CnAR8W8KcBERszJvgivARcSveWoWSm0wcekiIv5NHbiI+Dc90EFExJzMPAtFQygiIialDlxE/JuJn0qvAPdBhsNgzaJNHD98moDAAB59qjP1G95c22WJF035dSrnKysAOFX6Lev3fU56my44DIPj9m9YXLAeA+gcE0eHJvdgYPD+v//JjmO650B1+dS9RKpJAe6Div61n4uVlxj4Qm+++vIY65Zspt9z3Wu7LPGSQGsAAP8/f4Vz23/f/zDvF/2TnccOMvjeJOLuaEbx6a/p3DyO36/PISgggGmJ6Yz+qwK82szbgNdsgDscjqvuhyvuOfzFMVr8MhqAO1s25Oj+k7VckXhT45ujsAUEMbJjT6wWKyt3/w+Hz54kNCgYgHqBNi45HNgrypi6fikOw+DWehGcryyv5cpNSgH+nSNHjjBjxgx27dpFYGAgDoeD2NhYxo0bR7NmzTx9ujqp/EIFwTfZnO8tVguOSw6sAfrH0B9UXLrIR3sLyD+4mwZhkQzv0IPV/95KWusH+c3d7blQWUHRya8AcBgGXZrH0ePu+9lQXFjLlYu3eTzAJ0yYwKhRo/jlL3/p3LZ9+3bGjRtHbm6up09XJwWH2Ki4UOl8bxiGwtuPHLef5YT9rPNne0UZg+5NYtK6bI6WnKFzTBwpcZ1Yuv1TADYW72DT/l2M6NiTVrfdyRf/F+7iJhPPA/d4KlRUVFwV3gCtW7f29GnqtMaxDfly+yEAvvryGA0a31rLFYk3dWx6DylxCQBE1gslJMjGcftZLly8fFHzbFkpNwXVo0FYJM/c/zAAlwwHlY5L+Njt/U3BsLj/8jUe78BbtWrFuHHj6NSpE+Hh4ZSWlrJp0yZatWrl6VPVWXffG8P+nUdYOPnyRaweT3ep5YrEm/52YDcZ7R5i7H8lY2Dw53+tx2Kx8HT7/4fDcHDR4eCtbes5fb6Er86dYvyDfQHYeewge0/9p5arNyEfDGZ3efyJPIZhsH79egoKCrDb7YSFhREfH09iYqLz6czXoifyyE/RE3nkp3jiiTzRGTPd3vfworE3fD5P8ngHbrFYSExMJDEx0dOHFhGpAeZtwTUPXET8m3nzWwEuIn5OAS4iYk6+OLvEXZpcLCJiUurARcS/mXghjwJcRPybefNbQygiImalDlxE/JuJ21gTly4i4t/UgYuIfzPxGLgCXET8mjv3aPJVGkIRETEpdeAi4t/M24ArwEXEz5k4wF0OoXz55Zd8/vnnFBYW0r9/f7Zs2eKNukREvMJicf/la1wG+JQpU7DZbLzxxhuMGDGCP/zhD96oS0REXHA5hBIYGEjLli2prKykdevWXLp0yRt1iYh4hw921u5yGeAWi4VRo0aRkJDA2rVrCQkJ8UZdIiLeYeIAdzmE8sorr9CnTx/69+9P/fr1eeWVV7xRl4iIV1iq8XJHYWEh6enpAOzevZtOnTqRnp5Oeno6a9euBWD58uX06tWLvn378sknnwBQVlbGsGHDSEtLY/DgwZw5c8bluVx24DabjW3btvHRRx/x4IMPcu7cOSIjI938KiIivs1i9VwLvmDBAlavXu0cqdizZw9PPvkkGRkZzn1OnjxJdnY2K1asoLy8nLS0NDp06MCyZcuIjY1l2LBhrFmzhqysLCZOnHjN87nswMePH0/jxo05ePAgUVFRTJgw4Qa/oohI3RQdHc28efOc73ft2sWnn37K448/zvjx47Hb7ezYsYM2bdpgs9kIDw8nOjqaoqIiCgoK6NSpEwAJCQluzfhzGeBnz56lT58+BAYGEh8fj2EYN/D1RER8TDXGUPLy8ujVq5fzlZeXd9WhkpKSCAz8bmAjLi6O559/nqVLl9K4cWNef/117HY74eHhzn1CQ0Ox2+1XbQ8NDaWkpMRl6W4t5CkuLgbg2LFjWK1afS8idUd1BlBSUlJISUlxe//ExEQiIiKcP0+bNo127dpRWlrq3Ke0tJTw8HDCwsKc20tLS52fuxaXaTxhwgTGjx/Pnj17ePbZZxk7dqzbxYuI+DxPX8X8noEDB7Jjxw4AtmzZws9//nPi4uIoKCigvLyckpISiouLiY2NJT4+nk2bNgGQn59P27ZtXR7fZQfeqlWrH/1vgohIXVGTKyynTp3KtGnTCAoKIioqimnTphEWFkZ6ejppaWkYhsGIESMIDg4mNTWVMWPGkJqaSlBQEJmZma5rN1wManfp0uWq2y2GhYXxl7/85ca/WRVyts2tsWOLeW04UNsViC9a2Pt3N3yMFs/PdnvffS8/d8Pn8ySXHfiHH34IgGEY7Nq1y/leRERql8sxcJvNhs1mIzg4mLZt27Jnzx5v1CUi4hVmvpmVyw48MzPTOYRy4sQJzUIRkbrFB4PZXS4DPCYmxvnzXXfd5ZxoLiJSF1hMnOBVBvjf//53AG677barthcWFtKxY8earUpExEt8cWjEXVUG+Jo1a6r8kAJcROqKOhngM2bM+MntJ06cqLFiRES8ri4G+BWvvfYaOTk5VFZWUlZWRtOmTa/ZnYuImImJ89v1NML8/Hzy8/N55JFHWLt2LQ0aNPBGXSIi3lGDS+lrmssOPDIyEpvNRmlpKU2aNOHChQveqEtExCs8eDtwr3MZ4A0bNuTdd98lJCSEzMxM7Ha7N+oSEfGOuhzg06ZN4+jRo3Tr1o1Vq1bpkWoiUqeYOL9dj4H37t2bTz/9FID09HRatGhR0zWJiHiNmZfSuwzw+fPnU1ZWRv/+/Rk7diwFBQXeqEtERFxwGeBRUVEMHDiQefPmUV5eztChQ71Rl4iIV5i5A3c5Bv7ee++xatUqHA4HvXv3rnKBj4iIGVl8MZnd5DLAi4qKmDx5Ms2bN/dGPSIiXmXi/HYd4HoGpoiIb3LrqfQiInVVne7ARUTqMhPnd9UBPm7cuCo/pAuZIlJnmDjBq5xG2L17d7p37865c+eIiYmhT58+tGrVioqKCm/WJyJSo6wW91++psoA79SpE506daKsrIzBgwfTtm1bBgwYwJkzZ7xZn4hIzarLdyM8f/48W7Zs4Re/+AWff/45lZWV3qhL5Cr/fPFwbZcgvqj3jR/CB3PZbS5XYr744ossW7aMlJQUli9frptZiUidUqdXYjZv3pwRI0Zw+PBhWrVqRVRUlDfqEhHxDh8MZne5DPAlS5bw8ccfc+7cOR577DEOHTrE5MmTvVGbiEiN88WLk+5yOYSyZs0aFi9eTHh4OP3796ewsNAbdYmIeIl5r2K67MANwwC+u+GLzWar2YpERLzIF8e23eUywB9++GEef/xxjh49yuDBg+natas36hIR8Y66HOCpqan86le/Yu/evTRr1oxGjRp5oy4REa8wcX5XPQZ+8uRJDhw4QFpaGgEBAdx1110EBQWRkZHhzfpERGpUnZxGWFhYyFtvvcWBAweYPHkyhmFgtVrp2LGjN+sTEalRvhjM7qoywLt27UrXrl3ZtGkT7du3JyQkhOPHj9OgQQNv1iciUqNMnN+upxHu3LmTuXPnApdXZc6fP7/GixIR8RrzziJ0HeAbN250PpXntddeY+PGjTVelIiIt5h5DNxlgFssFuctZCsrK53zwkVE6gITN+CupxH269ePRx55hNjYWPbv38+gQYO8UZeIiHf4YjK7yWWAJycn8+tf/5ojR47QuHFj6tev7426RES8wtP3QiksLGT27NlkZ2dz6NAhxo4di8VioWXLlkyZMgWr1cry5cvJzc0lMDCQoUOH0rlzZ8rKyhg9ejSnT58mNDSUWbNmuczbKgM8KyuLZ555hpEjRzqX0V+RmZnpmW8qIlLbPDi4vWDBAlavXk1ISAhw+fGTw4cP57777mPy5Mls2LCB1q1bk52dzYoVKygvLyctLY0OHTqwbNkyYmNjGTZsGGvWrCErK4uJEyde83xVBniXLl2Ay0MoIiJ1lScb8OjoaObNm8fzzz8PwO7du2nfvj0ACQkJbN68GavVSps2bbDZbNhsNqKjoykqKqKgoMA5RJ2QkEBWVpbL81UZ4EVFRRQVFXniO4mI+K5qJHheXh55eXnO9ykpKaSkpDjfJyUl8dVXXznfG4bhHMEIDQ2lpKQEu91OeHi4c5/Q0FDsdvtV26/s60qVAV5cXAxcHs+pV68ebdq0YefOnVy8eJGePXu6+XVFRHxbdTrwHwa2K1brdxP9SktLiYiIICwsjNLS0qu2h4eHX7X9yr4uj1/VL0aNGsWoUaMICgpi/vz5DB06lKysLC5evOh28SIivs5idf9VXffccw9bt24FID8/n3bt2hEXF0dBQQHl5eWUlJRQXFxMbGws8fHxbNq0yblv27ZtXR7f5SyUM2fO8O233xIREcE333zD2bNnq/8tRER8VE3OIhwzZgyTJk1izpw5xMTEkJSUREBAAOnp6aSlpWEYBiNGjCA4OJjU1FTGjBlDamoqQUFBbk0WsRguVuZ89NFHzJ49m7CwMOx2Oy+99BL33nuvx77gD+Vsm1tjxxbzmjFIT6WXH9u57cZnxD2U9arb+657ZvgNn8+TXHbgSUlJJCUlcfr0aSIiIggKCvJGXSIi4oLLAP/ss8/4/e9/z6VLl+jWrRuNGjUiOTnZG7WJiNQ4X7zHibtcDsu/+uqrLFmyhKioKIYMGcKyZcu8UZeIiFeY+WZWLjtwq9VKZGQkFouF4OBgQkNDvVGXiIhX+GIwu8tlgEdHR5OZmcnZs2eZP3++nokpInWKifPb9RDKlClTaNSoEW3btiUkJIRp06Z5oy4REe8w8f1kXXbgQ4YMYdGiRd6oRUTE6+r0EEp4eDgbNmygadOmzmWhzZo1q/HCRES8wcT57d5KzMWLFzvfWywW3n777ZqsSUTEe0zcgl8zwO12O/Pnz3fe21ZEpK7x9AMdvKnKi5hLlizh0UcfpUePHvztb3/zZk0iIl5j5nngVQb4Bx98wIcffkhubi5vvfWWN2sSERE3VDmEcuVpEfXr16eystKbNYmIeI0vdtbucnkREy4/VUJEpC4ycX5XHeD79u1j1KhRGIbh/PkKPdRYROqKOtmBv/rqq86f9WBjEamr6mSAX3mSsohIXWbmAL+Op7yJiIgvcOsipohIXWXmDlwBLiJ+zcT5rQAXEf9mNfFAsolLFxHxb+rARcSvaQxcRMSkTJzfCnAR8W/qwEVETEoBLiJiUgpwERGTMnF+K8B9keEwWLNoE8cPnyYgMIBHn+pM/YY313ZZUoMCA628MCWFRo3qYwsKZP6b6zl85BRTJiZjscAXe48y4+VVOBwG/dMfpHu31jgcBgsWbWDjJ7sAWP/hZA4fPglA4Y5DzP3D2tr8SqahDlw8quhf+7lYeYmBL/Tmqy+PsW7JZvo91722y5Ia9JvubTl77jzjJy3j5ptv4p2ckfy76D+89vpaCrbtZ/rUfjz4Xz/ns8/28Xi/jnTvMYObQmy8kzuSjZ/sonHjW/l30VcMG76otr+K6Zg4vxXgvujwF8do8ctoAO5s2ZCj+0/WckVS0z76uJB163c431+65GDE6MU4HAaBgQHcGhXO6dN2LpRVcPTYN9wUYiMkxIbDcflhK/fc3Zjbb7uZhX8aSnl5JS9n/oWDh/TfjTvUgYtHlV+oIPgmm/O9xWrBccmBNUALZ+uqCxcqALjppmDmvNyfeVl/xeEwuOOOW1jwxtPY7WUcPHQCgOPHzvLeu89jDbCw8M8bATh16lsW/nkD69bvoE3rZsyYnkZq+txa+z5mYuan0ivAfVBwiI2KC989h9QwDIW3H2jQIJK5mQPIfed/WPvh5wB8/fU3/KbnTHr1vI/RIx9l/YadREVF0O2RFwH40+tP8fn2A+zec4SLFx0AfL79ALffrmsmblOAfyc9Pf1HD0E2DAOLxUJubq6nT1cnNY5tyN5tB/n5Ay346stjNGh8a22XJDXs1vphzM96ipdmrWLrP78E4LVXMpg9ZzWHj5yi9Hw5hmHwbcl5yssrqai4CEBJyQXCw0MY+tRDnD13nj+/9QmxLe/g62Nna/HbmIuJ89vzAf7cc88xceJEXn/9dQICAjx9eL9w970x7N95hIWTVwDQ4+kutVyR1LRBGb8mIjyEpwd15elBXQF47fW/Mv33/aisvERZWQVTpi3n1KkSdt13hKVvPYthGGzbfoAt/9jL7t1HmDE9jYSOd3PxkoNJU9QsucvMY+AWowYeOf/mm2/SpEkTEhMTq/3ZnG0at5MfmzHocG2XID5o57Ybf8D6Uyvdz5z5vX53w+fzpBoZAx80aFBNHFZExOPM3IHrIqaI+DXNQhERMSlPduA9e/YkPDwcgDvvvJMhQ4YwduxYLBYLLVu2ZMqUKVitVpYvX05ubi6BgYEMHTqUzp07X9f5FOAi4tc8ld/l5eUAZGdnO7cNGTKE4cOHc9999zF58mQ2bNhA69atyc7OZsWKFZSXl5OWlkaHDh2w2WxVHbpKCnAR8WvV6cDz8vLIy8tzvk9JSSElJQWAoqIiLly4QEZGBhcvXmTkyJHs3r2b9u3bA5CQkMDmzZuxWq20adMGm82GzWYjOjqaoqIi4uLiql27AlxE/Fp1OvDvB/YP1atXj4EDB5KcnMzBgwcZPHiwcw0MQGhoKCUlJdjtducwy5Xtdrv9umpXgIuIX/PURcxmzZrRpEkTLBYLzZo1IzIykt27dzt/X1paSkREBGFhYZSWll61/fuBXh1any0ifs1icf91Le+++y4zZ84E4Pjx49jtdjp06MDWrVsByM/Pp127dsTFxVFQUEB5eTklJSUUFxcTGxt7XbWrAxcRv+api5h9+vRh3LhxpKamYrFYeOmll7jllluYNGkSc+bMISYmhqSkJAICAkhPTyctLQ3DMBgxYgTBwcHXdU4FuIj4NU9NI7TZbGRm/nhl6JIlS360rW/fvvTt2/eGz6kAFxG/ZuJ1PApwEfFvWkovImJSWkovImJSFhO34ApwEfFr5o1vBbiI+DkTN+AKcBHxbybObwW4iPg3XcQUETEpBbiIiEmZOL8V4CLi33QRU0TEpEyc3wpwEfFv6sBFREwqQAEuImJOJs5vBbiI+DcNoYiImJSJ81sBLiL+TR24iIhJmTi/FeAi4t+s1tqu4PopwEXEr5k4vxXgIuLfNAYuImJSJs5vBbiI+Dd14CIiJmXi/FaAi4h/0wMdRERMSkMoIiImZeL8VoCLiH9TBy4iYlJayCMiYlK6iCkiYlIaQhERMSkT57cCXET8mzpwERGTUoCLiJiUifNbAS4i/i3AxAmuABcRv+apIRSHw8HUqVP54osvsNlsTJ8+nSZNmnjm4FUw8xx2EZEbZsFw+3Ut69evp6Kigry8PEaNGsXMmTNrvHZ14CLi1zzVgRcUFNCpUycAWrduza5duzxz4GvwuQBPi/9dbZcgPihtW21XIHVVdTInLy+PvLw85/uUlBRSUlIAsNvthIWFOX8XEBDAxYsXCQysuZj1uQAXEfFV3w/sHwoLC6O0tNT53uFw1Gh4g8bARUQ8Ij4+nvz8fAC2b99ObGxsjZ/TYhjGtUfmRUTEpSuzUPbu3YthGLz00ks0b968Rs+pABcRMSkNoYiImJQCXETEpBTgIiImpQD3QQ6Hg8mTJ5OSkkJ6ejqHDh2q7ZLERxQWFpKenl7bZYiP0DxwH/T9Jbnbt29n5syZvPHGG7VdltSyBQsWsHr1akJCQmq7FPER6sB9UG0syRXfFx0dzbx582q7DPEhCnAfVNWSXPFvSUlJNb6yT8xFAe6DamNJroiYjwLcB9XGklwRMR+1dT4oMTGRzZs3069fP+eSXBGRH9JSehERk9IQioiISSnARURMSgEuImJSCnAREZNSgIuImJQCXK7b/Pnz6dixI+Xl5VXu88UXX/DZZ59V+9hjx451zoW/Hh06dLjuz4qYhQJcrtv7779P9+7dWbNmTZX7rFu3jn379nmxKhH/oQCX67J161aio6Pp168fS5cuBS7f6rRv374kJyfz29/+luPHj7Nq1SoWL17Mjh076NKli7Nbnz17NitXruTSpUtMmDCBgQMH0qtXL1599dWfPF9lZSWJiYmcP38egDfffJPFixezd+9eMjIyGDBgAL169WLbtm1XfS49PZ3i4mIAli1b5rwZVHZ2NikpKfTr14+3334buPyPTXJyMqmpqTz33HM4HA6P/91EPEkrMeW6vPPOOyQnJxMTE4PNZqOwsJBJkybxyiuv0Lx5c5YuXcqpU6d47LHHiIqKIi4u7ieP8/XXX9O6dWuSk5MpLy8nISGB4cOH/2i/oKAgHnroIdatW0fPnj1Zu3YtCxcuZMuWLYwZM4ZWrVrx/vvvs3LlSuLj469Z+759+1i7di05OTlYLBYGDBhAx44d+eCDDxgwYAAPP/ww7733Hna7nYiICE/8uURqhAJcqu3cuXPk5+dz5swZsrOzsdvtLFmyhNOnTzufwv34448DsHHjxp88xpUFwJGRkezcuZN//OMfhIWFUVFRUeV5k5OTmTp1KjExMTRt2pRbbrmF22+/naysLOrVq0dpaelVd3Gs6px79+7l6NGjDBgwwPl9Dh8+zLhx4/jTn/7EsmXLiImJoWvXrtX+24h4k4ZQpNpWr15N7969WbRoEQsXLmT58uVs3ryZ4OBgDh48CFy+wPnxxx9jsVicQxE2m40TJ05gGAZFRUUArFy5kvDwcDIzM8nIyKCsrIyq7u7QtGlTDMPgzTffJDk5GYAXX3yRZ599llmzZhEbG/ujz9psNk6ePAnAnj17AIiJiaFFixa8/fbbZGdn06tXL2JjY8nLy2PYsGEsWbIEgI8//tizfzgRD1MHLtX2zjvv8PLLLzvfh4SE8NBDDxEVFcX48eOxWq3cdtttDBgwgKCgIF5++WWaN2/OoEGDeOqpp/jZz37mHJp44IEHGDlyJAUFBYSEhNCkSRNOnDhR5bn79OnD3Llzuf/++wF49NFHeeaZZ7j11ltp2LAh33zzzVX7P/HEE7zwwgvccccd3H777QDcddddPPDAA6SmplJRUUFcXBwNGjQgLi6OJ598ksjISEJDQ3nwwQc9/JcT8SzdzEpExKQ0hCIiYlIKcBERk1KAi4iYlAJcRMSkFOAiIialABcRMSkFuIiISf0vSfwDRjXWLBEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEECAYAAADAoTRlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAABFTklEQVR4nO3deVyU1f7A8c8szMCwi/uGgqLmhkupmUumaVqWomKmltWv7XZts7RFo6uhZovXLFstc0mtLJcsTc1MzVsiWFqKKy6FooIwLLM+vz+ISZRdZmO+79fr3mbmYZ7nexj8cjjPOd+jUhRFQQghhE9RuzsAIYQQrifJXwghfJAkfyGE8EGS/IUQwgdJ8hdCCB+kdXcAFWG327HZqjYpSaNRVfm93kra7Bukzb7hatrs56cp9ZhXJH+bTSErK69K7w0LM1T5vd5K2uwbpM2+4WraXKdOcKnHZNhHCCF8kCR/IYTwQZL8hRDCB3nFmH9JbDYrmZkZWK3mMr/uzBkVvlbBwh1t1mp1hIfXQaPx2h8pIXyK1/5LzczMwN/fQGBgfVQqValfp9GosdnsLozM/VzdZkVRyM3NJjMzg9q1G7jsukKIqvPaYR+r1UxgYEiZiV+4hkqlIjAwpNy/woQQnsNpyX/v3r2MGzfuite3bNlCXFwc8fHxrFy58qquIYnfc8hnIUT10aYnEbz+fsI/6Y7m3e7o9y+t/mtU+xmB999/nzVr1hAQEFDsdYvFwsyZM/n8888JCAjgzjvv5MYbb6ROnTrOCEMIIbyCNj2JwK3Pos08gqLYUCvWfw7mQPDWyQCY2t5VfdestjNdomnTprz55ps888wzxV4/cuQITZs2JTQ0FIAuXbqwe/dubrnlljLPp9GoCAszFHvtzBkVGk3F/nCp6NdVxp49u5k8+UmWLFlJvXr1AXj77XlERjZjyJChFTrHpk0bePnll1i5crXjF+D06S/Sv//N9OjRs8qxvfHGHO68cywBAQZ27drJwIG3VMt5y6NSXfk5uYpGo3bbtd1F2uz9VKd+RrXlP6hP7nS8VlK2UoCgtG8J6Pl/1XZtpyT/gQMHcurUqSteNxqNBAf/s+IsMDAQo9FY7vlKWuGrKEqFbmo66+anzWZHq/Vj+vQE5s59C5VKhd2uYLdXLC6A1au/JC4uni+//Jz77nsQKGxXZc5RkieeeBqbzc6ePbv58cet9O8/sFrOWx5FqfpK7KslKz99Q01qs37/UkePvrRB00vn7BkjB2GqZNvLWuHr0tk+QUFB5ObmOp7n5uYW+2VwNR5csfeK1/q3qsPoLo0psNh4bNW+K47f2rYet7WrT1aehclrfy927N34juVes0uXrtjtCqtWrSQuLr7YsU8/XcLmzRvRaDR07NiJRx6ZWOz4n3+eJjs7m3HjJnDvvXdx9933odX+83GYTAVMn/4i589nULduPVJSklm9+ltSUw/wxhtz0Gg06HQ6nnnmBRTFzuTJTxASEkqPHj3ZtWsnkyY9yyefLOTw4UOsXr0KgNWrV7Fs2ScYjUYmTZpCeHgtpk17lnr16vHXX39x0003c+zYEVJTD3L99Tfw4IP/Kvd7IIQoX7FhHUClWFEptiuSvlL0f5ccUEKbYuz0r2od8gEXz/aJjo4mLS2NrKwszGYzu3fvplOnTq4ModpNmjSFFSuWcfLkCcdrR44cZsuW73jnnYW8885CTp06yY4dPxZ737p1qxkyZChBQUG0a9eBH37YUuz46tVf0rBhQxYsWMi99z5IZuYFAGbPfpknn3yG+fPfY9iwEcyf/zoAFy6c54033uKuu+52nGP8+Hvp0qUrt98+HIBWrVozb947jBgRz/r16wD466/TTJkyjVdeeYMPPniHf//7Cd5772PWrVtd/d8sIXyQfv9Swr64Hb/zv6Oym1DbTagvS/wK//TybSo1ikaPtXZbsuJWY3s0pdoTP7io57927Vry8vKIj49nypQp3HfffSiKQlxcHPXq1auWa5TVU/f305R5PMzgV6GefklCQ8OYOPEpEhMTaN++8Bxpacdp27a9oyffsWMsx44doWfPXgDYbDY2bvyGBg0asmPHj+TkXOSLLwp73kXS0o7Rrdv1AERGNiMsLByAc+cyaNmy1d/n7cw778wHoEGDhvj5+ZUZa6tWbQCoVSsCk6ng7/c1IigoCD8/P2rVqkVISOH9GJm9I0TVadOTCNizAO2ZJDR5GaUO68A/SV/R+JPf4V7yrn/OFSE6L/k3btzYMZXztttuc7zer18/+vXr56zLusUNN/Rm27bvWb9+HY88MpHIyGYsX74Eq9WKRqMhJSWZQYOGOL7+p5920Lr1NcyYMdvx2ujRwzl8+JDjeVRUNPv2/Urv3n05ffoUFy9mAVC7dh0OHz5EixYtSUnZQ5MmTQFQqa78I06tVmO3/zNqWFJClyQvRNU5kvy5fWAzoejDsAc1RHfyB+DKsfwr1t0roKggvfGt+N3+jitCdvDaFb6e5rHHniIp6RcAoqNb0K9ffx5+uPAvnA4dOtK7d1/H165d+yW33XZHsfffdtvtfPHFP+sebr31dl5++SX+9a//o379+uh0OgAmT36eN954BUVR0Gg0TJkytdSYGjVqzNGjh1m5cln1NVQIH6RNT8Lv9E+oTNloz+3HHhCB358/ozFeNrElLwNV5qESz+EY1kGNDRVGewBnwzoRceOT+DW+1rkNKIFK8YLCNxaL7Yo7/OnpadSvH1nue721vMNvv+0lPz+f667rzsmTJ3jqqX+zcmXFxuHd1eaKfibOUJNmgVSUtNn5DDsT0e9fgsacXez18oZxVJc8vlRBzHBSYmeS+F0qk/u3pFXdoHJjcFY9f+n5e6iGDRuRkPA8H330HlarlSefnOzukISo0RxDOH/uQm0xoigKasUGlDx8c/kN28uPF7H7BXEypCtfB41k1IDbaQF8eGes24dcJfl7qIiI2rz55rvuDkMIn2DYmYgh+W2g/F59SY8B7BoD9pBGWOu0x++vn1FZ8smIiuOx83fwv7QsOjUKYajFhr+fxu2JHyT5CyF8mDY9ieB1E9CYLlQ46duCG2NpcB3ajN9Q5WWgUmkoaBNfbJaOza7wWcqfvPXjMdSqHCbf1ILhHRug9oCkX0SSvxDCZxSbnWPKRmPOLn9Gzt/suhAK2o6t0FTMrHwL7+48TucmoTzbvyX1Q/yvOvbqJslfCFHjFM3OsTTqgf9vi9AdWvP3itrC1F5eOQUFNYpfIIp/KNba7cjv/DDW+l3KvKbVZuebP84ypG09IgJ1LB7bmUah/h4xxFMSSf5CiBrDsDMR/b7FaCw5Vxyr6LBOQcxwjAPmVeq6f5zJYfqGVA5l5FI7SEePZrVoHBZQ/hvdyGs3c3G3iRMf4vffC+sFWSwWBg7sw7Jlix3HH330AQ4dSuXFF5/FYrGQnp7O9u3bHMfS0o6Xef5z5zK46aaebNmyyfHa+vVrWbDgzauKe/36tWzfXrgA5YsvVlTbeYVwNW16EgFJ89GmJ6Hfv5Twd1pgSH4brSUHFVzxv0spl/0PCod1suJWVyrxF1hsvLntGBOWJpOZZ2HO0Gvo0azW1TfOBXyq53/pn4Ll/QlXnmuv7c7evSlcc0079u5N5rrrevDTT9sZM2YcJpOJM2fO0LJlDC+9NBOAPXt+IS3tODfc0LtC5//66zWMHHknq1atpF+//lcV66UGD/5ntfWiRQuvKEgnhKfT71+KIelNNDnFF1iV1LMvaxGTTR9W+L4SbthW1NOrf2dXWia3t6/PY72jCPb3npTqPZGWQX/gc/z/WF7iMZWqcDNzlTkH7bk/ADugxlq7DYqu9AUQBW1GY2o9otTj117bjUWLPuDOO8fy0087uO22O1iwYB5Go5HU1AN06tQZgBEjbmPx4pUsWfIxBQUFtG/fAYCFC98jM/MC+fn5JCS8TKNGjR3nVhSFDRvW89ZbH5CSsoejRw8TFdWi2PU//vgDtm37nrCwcAoKCrj//odo2bIV06dPJS8vF6vVxv/938N06XIt48aNokmTSPz8/GjaNJKIiAguXrxIdvZFXn11Ftdc05b9+3/jiSf+RVZWJnfcMYLbbx/O+PHxdOzYmaNHD9O0aSTh4bXYuzcZPz8/Xn11XrEqpEK4gmrZCIKPFRZBLG0hVbHXVBrMjW9Ae2onKsWGog/F0rBbhcbwS2M0WfHTqNFr1dzTrQnjrm3MdZHhVTqXO/nMsI/KlA3Y//6Bsf/9vOpiYlqRlnYcRVHYuzeZ2NjOdO3ajd27/0dychLduvVwfK1arWbs2HsYMGAQN9zQB4Drr7+BefPeoXv369m6dXOxc+/e/TNRUS0IDw9nyJChrFr1WbHjhw6lsmvXTt5//xNmznyV8+fPAbBo0Yd07dqNBQs+ZPr0WcyaNR273U5+fj733HMfL72U6DjH3XffR0hIKJMmTQFAq9Xy+uvzSUx8lc8++xSAvLw8BgwYyFtvvc/evcm0b9+Bt956H6vVyrFjR67q+ydEZRl2JqI5tqXEYRy4chjH0qAbWcNXkT10KRceOcb5f53gwv2/kTP4gyon/h1HLzB6URIf/JQGQJcmYV6Z+KGG9PxNrUeU2ksvKnWgTU8ibHU8is0CGj9ybp5/VUM/arWaFi1i2LVrJ7VqRaDT6eje/Xp27vyRw4cPMXLk6DLfX1RhMyIigvPnzxc7tnbtV/z11588+eS/sVotHDqUykMP/dtxPC3tGG3atEWj0aDRaGjduo3j9ZtvHgRAnTp1MRgCycrKBKBp02ZlxhMT0xqVSkWtWhEUFBRcEmdrAIKCgmnWLAqA4OBgTCbZrF24jjY9iYDkd0pdVWtu0gfN+d9Rm7KxhbfA2Cfxqod2L5WVZ+H1rUf45o+zNI8w0Ds6otrO7S41IvlXhLV+F7JuX1FtY/5QOPSzePFH9O8/EIAOHWL56KP30Wg0jtLIRQqHn+zFnpckKyuL/ft/Y+XK1Wg0GgBmz57BN9+sIzAwEIDmzaP54osV2O12rFYrqakHAYiMbM7evSm0aXMNGRlnycnJLrNE86VlnUqfjuaZ09SEbyjaBMXv/O8lJv7KzL2vqv8dz2Tq+gNkm6zc370pE7o1Raf1/kETn0n+UPgLoDp7A9de243Zs2cwdep/APDz8yM4ONhRb/9S0dEt+OSThcTEtC7znN9+u46+ffs5Ej/AbbfdwYwZLzo2aomObkH37j158MF7CA0NQ6vVotVqGT9+AjNn/ocffthMQYGJZ555vsxx+WbNmvOf/0yla9frqtJ8IZwqaOOj+B/6Cii5jk5VpmRWRUSQjqbhAUzp35IWdQKdfj1XkaqeXigz8wLff7+Z4cNHYjabGTduFP/97zvUr1+4kbxU9fQNNa3Nl26AoirIQm23lLr61hrekqwx3zslDkVRWP1bOgfPGpncv6XjNXct1pKqnsIhNDSMAwd+5/77x6NSwa233uFI/EJ4o0s3M4eyN0ExN+lD9tClTonjVFY+L393iN0nsujSJJQCDyrEVt0k+XshtVrNc8+96O4whKiy4jV2jGjMWUDZc/WttduiGvIa2UHtqj0em11hRfJp3t5+HK1axbMDWnJH+/oeVYitunl18nfnn2KiOC8YPRQeQJuehGFnIrq//gdUfGFWXqdHyLv+OcLCDOCEoa6sfAvv/5TGtU3DmNK/JfWC9dV+DU/jtclfq9WRm5tNYGCI/AJwM0VRyM3NRqvVuTsU4cFC1txV6t62RRyF1VQa7MFNUPzDyL/mTkxt76r2eCw2O9/8fpZb2xUWYls6rgsNQvQ+k0+8NvmHh9chMzMDozGrzK8rWuHrS9zRZq1WR3h4HZdeU3g+w85E9Ae/gIIsNHZThconW+rGcnHkOqfGtT89h+kbDnLkXB51g3V0b1aLhqGeV3bZmbw2+Ws0WmrXblDu19W0GREV4YttFp5Fm55E8MZ/o8k5Ue7Qjl1jQDHUqnDp5KtRYLHxzo40Pt1zitqBOl67oy3dvaQQW3Xz2uQvhPAMRZucq4CCtmNRG//C/9CX5Q/t+AWS3+5upy7QutxTX+3n5xNZDOtQn4m9owjS+24K9N2WCyGuSsiau/A7uc2xQQqAIfntCt3ELbqB6wqXFmK7r0fhCt2uTcNccm1PJslfCFEhhp2J6P9YAWo1mHLR2PJKrZNfUsVNW3BjlwztXOrHI+eZtekQt1xTj0d7Nadz4zCXXNcbSPIXQpTLsDMRQ/Lbjufl9e4vfWxp0I3c659zWcIHyMwz89r3R9hwIIMWtQO5sWVtl13bW0jyF0KUybAzkYC/E395Sb8gZjj2wProU7/EHtLU5UkfYNfxC0xdfxCjycoD10dyz3VN8NN4fyG26ibJXwhRIsPORPTJ76LBBpS9ecrlvXtX3sS9XJ0gPc1rBTC5f0uia9ecQmzVTZK/EOIKoZ/dit/ZlCuqaRY9t6u0KGHNsYZFu3QMvyR2ReGr39JJPWtkyt8J/73RsW6Lx1tI8hdCOFze279cYa9fRfbwL9ya8IuczMzn5e9SSTp5ka6XFGIT5ZPkL4QPK9osRZt9ErvdhsZWuDiwtB2zCtqOo6D1CLcnfptd4dM9p3lnR2EhtucHtOT29vV9pjRDdXBK8rfb7SQkJHDw4EF0Oh0zZswgMvKfOu9r1qzho48+Qq1WExcXx5gxY5wRhhCiDJfW2oErk0GxVbj+EWQPWej2pF8kK9/Cwl0n6BYZzuSbWlDXBwqxVTenJP9NmzZhNptZsWIFKSkpzJo1iwULFjiOv/LKK6xbtw6DwcCQIUMYMmQIoaGhZZxRCFGdwpbeiDbrUIlj+sWmbKr9yO/4f269gVvEbLWzYvdJBkTXKizENr4z9YN9pxBbdXNK8k9KSqJXr14AxMbGsm/fvmLHW7VqRU5ODlqtVsoyC+Eihp2J6H/7GLW1cHFWSUM7/1TVVGNqeYdLtkmsiH1/ZTN9QypHz+cRGteO7s1q0SDEtwqxVTenJH+j0UhQUJDjuUajwWq1OvaTbdmyJXFxcQQEBDBgwABCQkLKPJ9Goyqs410FGo26yu/1VtJm31CZNquWjUBzbEvh48uOFSV8m18wao0We3R/lDveRQuEVVewVZRntjJ38yE+/imNesH+fHh3V3q38K0FW8762XZK8g8KCiI3N9fx3G63OxL/gQMH2Lp1K5s3b8ZgMPD000/zzTffcMstt5R6PptNqXKVSl+scClt9g0VaXNRSQZNwfkyF2hdsRm6h3wv//XZr/x8Iou4jg14tFdzGtcLkc+5Ely+h2/nzp35/vvvGTx4MCkpKcTExDiOBQcH4+/vj16vR6PRUKtWLbKzs50RhhA+Sb9/KYafX0Wddw4VSrk19F1ZZK0icgqs+GlU+PtpuL9HJPf1aCo1eZzAKcl/wIAB7Nixg9GjR6MoComJiaxdu5a8vDzi4+OJj49nzJgx+Pn50bRpU4YNG+aMMITwOaXtlnX5zVwFNYqhNrnXPeWUXbKq6ofD55m9+RC3tKnHv3s3p1NjmQjiLCrFC7a5slhsMuxTCdJm3xAWZsB44MfCefrnDwK2K27kFrn0H7m5SR+yhy51TZAVdCHPzKtbjvDdwQxa1gnkhZtjuKb+lUMWvvo5e82wjxDCeQw7E9H/+jFqWwFh2B2vlze8o/gFY2o+wGNm8BTZeewC09YfIM9i46Gekdx9bRO0UojN6ST5C+FFSqq5UxLH8I7aD3PkTW6vv1OWesF6omsHMrl/C6IipBCbq0jyF8ILaNOTCNr4GNqc4xXaKQs8c3gHCguxrdr7F6kZRp4bEEN07UDeje/o7rB8jiR/ITyYNj2JoO8eQ5t9ZdK/YlgHQKXBFtEaY59Ej+zpp13I4+WNqSSfzqZbZBgmqx29VoZ43EGSvxAeSpueRNgXtwOlj+fbNQYsTXt79LAOgNWusHT3Kd7beRy9VsO0gTHc2raerO53I0n+QniooB8K596XVmHT1n0imV2ecWlMVXUx38Inv5zk+ua1mHxTC2oHSSE2d5PkL4SH0aYnEfzNg2jy0kveCD20OTn95xLUupfHrMQtidlqZ93+dO7o0KCwENu4ztSXejweQ5K/EB5Ev38pwVsnAyUN9ajI7/SwR63GLc2vf2YzY0Mqxy7k0SgsgG6R4ZL4PYwkfyE8RNB3E/FPXQWUPNRj7DvLo1bjliTPbGPBjuOs2HOaesF65sW1o1tkuLvDEiWQ5C+EG2nTkwjYswDtqe1oLMZSx/fNTfp4fOIHmLR6P7+cyGJUbEMe6dWMQJ2kGE8ln4wQLqZNT8KwMxFtxm+orf+M2ZdYX1/jT36Hez16qCe7wIJOo8bfT8MDPSJ5oEcksVKTx+NJ8hfChUob2rlUUeL3tGqbJdly6ByvbD7MkGvq8u/eUZL0vYgkfyGcxDGkc24f2ExgykFjK6jQCl1PT/zncs3M2XyYLYfOEVMnkJtb1XV3SKKSJPkLUc2KtkvUlDKkU+TyhG8z1MFar4vHL9ja8XchtgKLjUduaMa4ro2lEJsXkuQvRDUI+m4iuiPfgt2CWrEApQ/rgPet0L1UgxA9MXWDmNyvBc0ifGvrzJqk3ORvNBp5//33ycjIoG/fvrRq1YrIyEhXxCaEx9KmJ+F3+ic0F1LxS12F5u/XK1p0DUrYOtFD2RWFz1P+JDUjlxdujiEqIpAFIzu4OyxxlcpN/s899xy9e/fml19+oXbt2jz//PMsWbLEFbEJ4VEcY/hnktDkZRQ7Vl7St2sMKPpA0Oix1m7nNT394xfymLEhlb1/ZtO9WbgUYqtByk3+WVlZjBgxgjVr1tC5c2e8YOMvIardpUXWoPyZOo7nfoHkt7vbo2/elsRqs7N49yk++CkNfz8NLw6KYcg1UoitJqnQmP+RI0cASE9PR62W3/rCt4SsuQu/kz9UeEjHW27cliXbZGXJ7lP0io5gUr8W1A7UuTskUc3KTf4vvPACzz33HEeOHGHixIkkJCS4ICwhPEP4wk5o8osP8Vye8O2oUKFgD2xAzqB3vDbhm6x21uxLJ65jA2oZdCwb34V6wVJ9s6YqN/mfPn2aFStWOJ6vX7+ea665xqlBCeFuRfvkamx5pfT41Sj+4RS0ife6IZ2SpJy6yPSNqZzIzKdpeGEhNkn8NVupyf/7779nz549fP311yQnJwNgt9vZvHkzgwcPdlmAQrha6Mpb8cu4cp/cS3v8F+O+9Noe/qVyzVbe+vE4n6X8ScMQPfPj2kshNh9RavJv3bo1WVlZ6PV6mjdvDoBKpWLIkCEuC04IVwtf1B2N8VSxOvoq/kn81tptPXaLxKqYtPp3kk5kMbpzIx7u2QyDTlP+m0SNoFLKmb5jt9uL3eQ9e/Ysdeu6dim3xWIjq4qbVoSFGar8Xm8lba48w85E9MnvosFWamVNTyu5UNU2X8y3oNcWFmLbe/oiKpWKDg1DnBBh9ZOf7cqpUye41GPljvnPnz+fZcuWYbFYKCgooFmzZnz99ddVCkQITxS08d/4H/qy1GGegrbjKGg9okb09jenZvxdiK0eE/tE0bGRFGLzVeXO29y2bRvbtm3jtttuY/369dSrV88VcQnhdEHfTaTW283LTPw5fWdj7DvT6xP/OaOJp1fvZ8raP6gXrGdQGynE5uvK7fmHhYWh0+nIzc0lMjKS/Px8V8QlRLXT71+K/++fojamo847iwo7UPoG6XmdHvGKDVTKs/3oeaatP4jZZuffvZozpmtjtGpZrOXryk3+9evX5/PPPycgIIDXXnsNo9HoiriEqDba9CQCtz6L3/nfgfJX59qCG5PX5d81IvEDNAoN4Jr6QTzdrwWRtaQQmyhUoRu+f/31F6GhoXz55Zdcf/31REdHuyo+QG74Vpa0+R+GnYkYkt8GStoQvfhMHlCR4wX75BYprc02u8LKlD85nGFk6sBWbojMeeRnu3LKuuFb6pi/1Wpl48aN/PzzzzRq1IigoCAGDRrEm2++WaUghHC1osSv4sqhHeWSx1A4hTMr7iuvSfylOXo+l/9bvpfXvz/C+VwLJqvd3SEJD1XqsM+kSZPQaDRkZGRw+PBhGjduzPPPP8/48eNdGZ8QlXbpME9p4/mKRo+lYXcsjXpgadTD62/oWmx2PvnlJB/uOoHBT8N/BrdiUOu6UohNlKrU5H/ixAlWrVqF2WwmLi4OPz8/PvnkE5cP+QhRGZfukXspx+YphrrkXveU1/fwL5djsvJp0mn6tqjNpH7R1DJIITZRtlKTf1BQEAA6nQ673c7ChQsJCwur0EntdjsJCQkcPHgQnU7HjBkzim0A8+uvvzJr1iwURaFOnTrMmTMHvV7qiIirc/nq3CJFid9SN5aLI9e5OiynKbDYWJl8mhGxDall0PHp3V2oEyT/jkTFVKikc0RERIUTP8CmTZswm82sWLGClJQUZs2axYIFCwBQFIWpU6cyb948IiMj+eyzzzh9+jRRUVFVaoAQAKp5HdAaTxV77dJhHmt4yxqV+PecymLmpsMcP59Hs1oGrosMl8QvKqXU5H/48GGeeuopFEVxPC7y2muvlXnSpKQkevXqBUBsbCz79u1zHDt27BhhYWEsWrSI1NRU+vTpU27i12hUhIVVbYqaRqOu8nu9la+1WbWgG5qckhO/otFhv/YhuCmBMJdHVv1yCqy8+t1Blv18kibhASy651quj45wd1gu42s/2+C8Npea/OfOnet4PHr06Eqd1Gg0OoaNADQaDVarFa1WS2ZmJsnJyUydOpXIyEgeeugh2rVrR48ePUo9n82myFTPSvCVNmvTkwjaMglN5qESb+wW2yO3hnw/Hl65l6STFxnTpRGTB7fBnGf2ic+6iK/8bF/K5bV9rrvuuipdDArvF+Tm5jqe2+12tNrCS4WFhREZGUmLFi0A6NWrF/v27Ssz+QtxOf3+pQRvnQIoJSb+nL6za8xN3aw8C/5+hYXYHr6hOSqgfcMQDDot5jyzu8MTXsopezJ27tyZbdu2AZCSkkJMTIzjWJMmTcjNzSUtLQ2A3bt307JlS2eEIWogbXoSIaviCN46mZqe+BVFYeOBs4z8eDfv7iz899KhYQjtvaQCp/BsFbrhW1kDBgxgx44djB49GkVRSExMZO3ateTl5REfH8/LL7/suJ/QqVMn+vbt64wwRA1SuI/udlTYgNLr8RTEDK8Rif9sjonZmw+z7ch5rqkfzJBrpKCiqF7llnc4c+YMc+bMITMzk4EDB9KqVSs6duzoqvgAKe9QWTWpzfr9SzH88DwaxQqUXKIBQPELIr/deI+qt19VPx45z9T1B7DaFR7q2Yw7OzdCU0Ihtpr0OVeUtLlyqlTeocjUqVOJi4vDbDbTtWtXXn755SoFIURl6PcvJfyDDgRvnYxGsZZZosHcpA+2Z07UiMQP0CQsgA4NQ/h0fBfGdm1cYuIX4mqVm/xNJhM9evRApVIRFRUli7GEU2nTkwj++j6Ct05Ga7pQZtIvrMezmuyhS10faDWy2RWWJZ0i4duDADSLMDAvrj1NwgPcHJmoycod89fpdPz444/Y7XZSUlLQ6WTZuKh+2vQkgjY+hjbnOFD68A7UrJLLR87lMmNjKvv+yuGGqFqYrHb0WqfMwxCimHKT//Tp05k9ezaZmZksXLiQhIQEF4QlfEnhtM3JAKVunA5gC21OTv+5Xl+EDQoLsX3880kW7jpBkF7LjMGtubl1HSnEJlym3OS/YcMGEhISCA2VvT5F9dKmJxH03WNos4+XuMGKoyZPg27kXv9cjUj6RXJMVlbsOc1NMbV56sZowqUQm3CxcpO/1WplwoQJNG/enFGjRtGtWzdXxCVquEurb5Y8bVNFQduxNWbjdCgsxPblb+mM+rsQ2/K7u1Bb6vEINyl3qmeRX3/9lQ8//JA//viDjRs3OjuuYmSqZ+V4cpu16UkErxmLxpJT6rh+VYZ3PLnNALtPZDFjYyqnLxbw1oj2XBcZftXn9PQ2O4O0uXKqVN6hSEFBARs2bOCrr75CURQmTpxYpSCEbytriOfyRVqOejw1gNFkZd62o3z5azqNw/x5Z1QHujQJc3dYQpSf/IcOHcrAgQNJSEgoVpNfiIq4NOlDGYu01H7kd/y/GjNXv8ik1ftJPnWRcV0b88D1kfj7adwdkhBAGcm/qArnl19+iZ+fHwBmc2ERKZnuKcpj2JmIfu+HaOwmoOypmzWtt5+ZZybAT4O/n4Z/3dActVpF2/ql//kthDuUmvwnT57Ma6+9xm233YZKpaLo1oBKpWLz5s0uC1B4F8PORPS/fojGZipzBg+ALbABOYPeqTE3dBVFYcOBDF7dcpjb2tXnsT5RUoRNeKxSk3/Rhi1z586lQ4cOjtf/97//OT8q4ZUMOxMxJL8NlLNIqwbN1y9yJsfErE2H2H70Au0aBHNrWynEJjxbqcl/9+7dHD58mI8//pgJEyYAhXX5ly5dyrp1NWc7PFF9AlLeBUqvuFkTkz7AD4fP8+I3B7DZFZ7oG0V8p5ILsQnhSUpN/iEhIZw7dw6z2UxGRgZQOOTz9NNPuyw44T0MOxNRKbZiK3SL2P0jyB6ysMYl/SKR4QF0bBTC0/1a0DhM6vEI71DuPP+zZ89St25dV8VTIpnnXzmubrNhZyIByW87irC5YwaPK9tstSt8mnSKw+dyeemW1i65ZknkZ9s3uHye/8SJE5k3bx7Dhw+/4tj27durFIioecKW9EV78fAVY/x24MLDx9wRklMdyjAyfUMqf5wx0ic6QgqxCa9VavKfN69w6p0kelESw85E9MnvosFW4hi/OebKToM3M1vtfPS/E3z080lC/bXMvLUNN8XUlkJswmuV22X55Zdf2LZtGz/88AP9+/dn7dq1rohLeLCiWT3aUhK/LbhxjZq3D5BrtvL53r8Y2LoOK+7pSv9WUoFTeLdyk/+cOXNo1qwZn3zyCZ9++inLly93RVzCgwX8uvCK1y7dVStz/C7XBuQk+RYby5JOYbMrhP9diO2lW1oTFuDn7tCEuGrllnfQ6/VERESg1WqpU6eOY5Wv8D3a9CQMO15GZSsocVZPTt/ZNWKDFYCf0zJ5+btD/HmxgJZ1Arm2aTgRgbKyXdQc5Sb/oKAgJkyYwJgxY1i6dCkNGjRwRVzCw2jTkwj7Yhgq7FccU4CLcatrxFTOnAIr//3hKKv3pdM0PIB34zvQuXGYu8MSotqVm/z/+9//cuLECVq0aMGhQ4cYOXKkK+ISHiZ40+NwWeIv6vWbYobXiMQP8PSa/aScusj4a5vwfz2aSiE2UWOVm/wvXLjAvHnzOHLkCM2aNePZZ5+lcePGrohNeIjQz25Fc/FYiUM95iZ9vP7m7vlcMwadhgA/DY/2ao5GraJNPSnEJmq2cm/4vvDCC9x+++18+umnDBs2jOeff94VcQkPYdiZiN/ZlCvn8fsFkhW3muyhS90SV3VQFIX1v58h/uPdvLsjDYB2DUIk8QufUG7P32QycdNNNwHQv39/PvroI6cHJdxPv38p/r9/ivZsSrHXi3r9uT2nefVQT3p2ATM3HWLnsUzaNwjh9vb13R2SEC5VbvK32WwcPHiQVq1acfDgQZnb7AP0+5cSvHUyUHKRtrxOj3j1rJ4fDp9j2vqDKChMujGaEbENpRCb8DnlJv8XXniB5557joyMDOrWrcuMGTNcEZdwo8CfXyu1JLO5SR+v3W1LURRUKhWRtQx0bhLK0/1a0DDU391hCeEWZSZ/o9FI8+bN+eKLL1wVj/AAqoILjsfFSjIb6njlGL/VrrB0d2EhtumDW9OsloE3hrVzd1hCuFWpN3yXLFnC0KFDuf322/nxxx9dGZNwA216EqHLbybi3RiwW4sdU/h75e6EZPcEdxVSzxqZsDSZ+T8eo8Biw2S9cp2CEL6o1J7/unXr+PbbbzEajTzzzDP06tXLlXEJFypcwHU78E9J5kt7/EYvXLlrstpZuCuNRb+cItRfy+zb2tAvpo67wxLCY5Sa/HU6HTqdjlq1amGxWFwZk3CxkK8Ld2q7dJzfrjFgbXgtpujBXpf4AfLMVlb9ms6gNnV5ok8UoVKPR4hiyr3hC1DOfi9XsNvtJCQkcPDgQXQ6HTNmzCAyMvKKr5s6dSqhoaFMmjSpUucX1cOwMxH9bx+jtuZdsYDLHD3I6xZv5ZltfLH3T8Z0aUy4QcfKe7oQbpB6PEKUpNTkf/jwYZ566ikURXE8LlK0uXtpNm3ahNlsZsWKFaSkpDBr1iwWLFhQ7GuWL19Oamoq11577VU2QVSWNj2J4HUT0JgulHjcpjF4XeL/8fA5nv/yN9KzTbSpF0zXpmGS+IUoQ6nJf+7cuY7Ho0ePrtRJk5KSHPcIYmNj2bdvX7HjycnJ7N27l/j4eI4ePVqpc4urc/n4/qWKev05d3zq0piuxsV8C3N/OMq6/WeIDA/g/dEd6dgo1N1hCeHxSk3+1113XZVPajQaCQoKcjzXaDRYrVa0Wi1nz55l/vz5zJ8/n2+++aZC59NoVISFGaoUi0ajrvJ7vVVZbVYvewIoefEWgC2iFUGtvefm/iNf/I89J7J4pG80j/SOQu9DhdjkZ9s3OKvNFRrzr6ygoCByc3Mdz+12O1pt4aW+/fZbMjMzeeCBB8jIyKCgoICoqKgS9wouYrMpsoF7JZTW5rBlN6LOPFpigTYFFda6Hbk4ch14+PfrXK6ZwL8Lsf3r+ki0vZrTLaYuWVl55Ls7OBeSn23f4PIN3K9G586d+f777xk8eDApKSnExMQ4jo0fP57x48cDsGrVKo4ePVpm4hdX79Ix/pKGerxlKqeiKKzbf4a5Pxzl1rb1eKJvNG0bhLg7LCG8UrnJ/8yZM8yZM4fMzEwGDhxIq1at6NixY5nvGTBgADt27GD06NEoikJiYiJr164lLy+P+Pj4agtelC/ou4n4p64CSh7qMcUM94rE/+fFAmZ+d4hdaZnENgphWAfZVEiIq1Fu8p86dSoTJkzg7bffpmvXrkyZMoWVK1eW+R61Ws1//vOfYq9FR0df8XXS43ce7V+7Cf72ITR56WXW6fGGWT3fHzrHi98cQIWKp/u1YERsA9RSYFCIq1JuPX+TyUSPHj1QqVRERUWh1+tdEZe4Cqo9HxO26g60lyX+S1fuFsQM9/g6PUXrS6IiDFzXNJzl93RhVKeGkviFqAbl9vx1Oh0//vgjdrudlJQUdDqZO+2pDDsT0f/6IRqbqdTevqLWkd/xfo+uzGm12Vm8+xRHzuUyY0gbImsZePWOtu4OS4gapdzkP336dGbPnk1mZiYLFy4kISHBBWGJitKmJ2HYmYj2zB7U9sIyHKVN4yyIGe7xwzwHzuQwfUMqqRm59I+pg9lqR6ct9w9UIUQllZv869evzxtvvOGKWEQllbVgC/5J/LbABuQMesejd94qsNj4YNcJlvxykjCDjjlDr6Fvy9ruDkuIGqvc5H/DDTc4HmdlZdGkSZMKL84SzhWydhxQ+kpdKLyp6+lj+wAFFjtrfktnSNt6PNYnihB/KcQmhDOVm/y3b9/ueHz69Gnmz5/v1IBE+bTpSQR/dSdq25UF2YrY9eHk9pji0dM4c81Wvkj5i7u6NibM4MfKe7oSZpCkL4QrVGqRV6NGjaQWj5uVNNRTlPjtGgOWpr3R9n6czCDP3qlq57ELzPzuEGdyTLRtEEyXJmGS+IVwoXKT/5NPPunYtP3s2bNEREQ4PShRMsMPz+P/+zLgyqEem18wmQ/8ARQuB/fUEg1Z+Rbmbj3C17+fpXktAx/cGUuHhrJKVwhXKzf5Dx48mJCQwn+cer2edu08u0dZUwVufZaA/YtLncmTM3SJq0OqkmfW/M6vf2ZzX/em3NutqczkEcJNyk3+H374IZ9+6j0lfmsi/f6l+O9fUuKMHrtfENlDl3r0TJ5zRhMGnRaDTsNjfaLwU6uIqRtU/huFEE5TbvIPDQ1l0aJFNG/eHLW6sJd26Qwg4VyGnYkYkt927K1bjErj0YlfURTW7jvDGz8cYWi7+oWF2OqXXmVQCOE65Sb/8PBwDhw4wIEDBxyvSfJ3DW16Eobktx3Pi34B2LUGzK3iKGg9wmMT/6msfGZ+d4ifT2TRqXEow6UQmxAepdTk//jjjzN37lxmzpzpynjEJYI3PQ5wRa8/94YXPXoK55ZD53hx/QE0ahVT+rdgWAcpxCaEpyk1+V+4UPL+rsI19PuXorl47LIbvCqMfWd5bOJXFAWVSkWL2oH0aF6LJ/tGUT/E391hCSFKUGryP3nyJK+//nqJx5588kmnBSQKBfx+5U12uy7YIxO/xWbnk19OcvRcHjOGtKZpeACvDL3G3WEJIcpQavL39/enefPmroxF/E2bnoT6/EHHc8fGK23HuiegMvyensOMjakcysjl5lZ1sNgUdFoZ4hHC05Wa/GvXrs2wYcNcGYug9J23bCHNPKoMc4HFxns701iadIqIQB2v3t6WPi1kAaAQ3qLU5C+LuVwvfFF3NMZTJc7nNzfp5fJ4ylJgsbNu/xmGtqvPxN5RBPs7ZTtoIYSTlPovdvLkya6Mw+eFf9QJTV5GKSt41Zhaj3B9UJcxmqx8nvIn465tUliIbUJXwgKkHo8Q3ki6a27i2ITlbAqqMnbesoU2J6f/XLfP599+9DwzvzvEuVwz7RuGFBZik8QvhNeS5O8GpVXmvHw+f16nR9w+zp+ZZ+a174+w4UAGUREGZg+9hnYNpBCbEN5Okr8bXLp4q8iliV9R+2HsPcMjpnVOXvM7v/2VwwM9IrmnWxP8NFKITYiaQJK/G6gvHnc8vrxejzW8JVljvndpPJc7m2MiSF9YiO2JG6Px06hpUTvQrTEJIaqXdONczLAzEdVlKV8BFL9A8jo94tbErygKX/76F6M+3s27O48D0KZesCR+IWog6fm70KUVOuGfXr+x72y3D/Gcysrn5Y2p7D55ka5NQhkZ29Ct8QghnEuSv4vo9y8tlviL2LQGtyf+zakZvPjNQbRqFc8NaMkd7es7dm8TQtRMkvxdQL9/KUHbphZ7zVGyof09Lo/HEcPfhdha1gnihqhaPNE3mnrBerfFI4RwHUn+Tqbfv5TgrcUXzBUlfkvdWLdM5bTY7Hz8v5McPZ9H4q2Fhdhm3SaF2ITwJXLD18kCLttw/dLEf3HkOpfHs/+vbMYt2cN7P6WhUYPFdsX+YEIIHyA9f2ey5qPKOV28ZIPWQH77e1ze4y+w2HhnRxqf7jlF7UAdr9/Rll7RUohNCF8lyd8JtOlJ6NK+R3d8I5r8cyioATuotVy8/VO3lGoosNr55o8zDOvQgEd7NSdILx+9EL5MMkA106YnEbZqGCh2APKuewpzk974nf4JS6MeLk38RpOVlcl/Mv66JoQF+PHZhK6E+Es9HiGEk5K/3W4nISGBgwcPotPpmDFjBpGRkY7j69atY9GiRWg0GmJiYkhISECtrhm3H4K2PguK3VGuQXf0W/KufcLlvf1tR84za9Mhzuea6diosBCbJH4hRBGnZNxNmzZhNptZsWIFTz31FLNmzXIcKygoYO7cuXzyyScsX74co9HI99+7t5xBdVJfPF5sjF998YRLr5+ZZ+bxlSk89dV+Qv39+GhMJ7o0CXNpDEIIz+eUnn9SUhK9ehVuPhIbG8u+ffscx3Q6HcuXLycgIAAAq9WKXl/23HKNRkVYmKFKsWg06iq/tyqUBh3h5E//FGmLGeTS6z/8+W/sPZXFY/1a8ECvKHTamvEXVXlc/Tl7Ammzb3BWm52S/I1GI0FBQY7nGo0Gq9WKVqtFrVZTu3ZtABYvXkxeXh49e/Ys83w2m0JWVl6VYgkLM1T5vVURoglBCyjaAExRt2Ds+wY4+fpnckwE/12I7bFezYgIM1BHryHPWIDrWu5erv6cPYG02TdcTZvr1Aku9ZhTuoVBQUHk5uY6ntvtdrRabbHns2fPZseOHbz55ps1ppSA/rdF6I5vKKzNb83H0rCbU69nVxRW7f2T+I93886O4wC0rhdMy3qlf+BCCAFOSv6dO3dm27ZtAKSkpBATE1Ps+LRp0zCZTLz99tuO4Z+awLCnsHZP0a8y/ZH1TrvWicx8Hl75KzM3Heaa+sGM6iSF2IQQFeeUYZ8BAwawY8cORo8ejaIoJCYmsnbtWvLy8mjXrh2ff/45Xbt25e677wZg/PjxDBgwwBmhuIz+0Fq0xtPFijWbogc75VqbDmaQ8O1B/DQqpt4cw23t6tWYv56EEK7hlOSvVqv5z3/+U+y16Ohox+MDBw4447Juo09dTdDmx7HWakVeu/Hoj23EFD242qt1FhVia1U3iN7RETzRN4o6QVKITQhRebLIq4q06Un4nf4JbXoy+uMbANBcPI6tTjuy299drdcyW+0s/N8Jjl/IY+atbWgSHkDirW2q9RpCCN8iyb8KClfxDgfF5nhNBSg2M36nf6rWBV2//ZnN9I2pHDufx+Br6mKxKei0MsQjhLg6kvyrIHBnIig2xypex+brKhWWRj2q5Rr5FhsLth9n+Z7T1A3WM3d4O3o2r1Ut5xZCCEn+VaA5/0fxSp1//zcv9qFq6/WbrHY2HsxgRGxD/tWrGYE6+aiEENVHMkolac+koDYbi83qsQU3Jq/Lv6/6Bm9OgZUVyae5p1vTwkJs93Ql2F8+IiFE9ZPMUgmqgkxCvn0Qe3BDCpoNQH9iK6aoW6qlNv/WQ+eYvfkwmXlmOjcJpXPjMEn8QginkexSQUEbH0V/eB0qxUbWyHVY63asltIJ53PNvLrlMJtSz9GyTiCvD2tLG1mhK4RwMkn+FRC2tC/arMOOG7v+ez/EOGBetZx7ytrf2Z+ew8M9mzH+2sZoNb5RiE0I4V6S/Mth2JnoSPxFdGlXV4I6PbuAYH8tgTotk25sgZ9WRVRE4NUFKoQQlSDdzDLo9y8lIOWdKzZfN0feWKXz2RWFlcl/Ev9xEu/uSAOgVb0gSfxCCJeTnn8pDDsTMSS/fcXrNpWmSkM+xy/k8fLGVFJOZ9MtMozRnRtVR5hCCFElkvxLoE1PciT+y3v9ptgHK32+7w5mkPDNAfRaDdMGxnBrWynEJoRwL0n+JQjcXliU7vLEXxAzvFLTOosKsbWpF8SNLWvzeN9oagfqqjdYIYSoAkn+JdCe2+94XJT4c/rOrvAiLpPVzoe70jh+IZ/Zt7WhcVgAM4ZIITYhhOeQG76X0R9ag9pWABTv8Vc08e89fZGxi5P46H8nMeg0WGxK+W8SQggXk57/JVS5Zwn64TksdWMxN+yO/tiGCq/gzTPbeHv7MVYm/0m9YD3z4trRo5kUYhNCeCZJ/kUUheCtz6Cy5pPTfy628Bbk9Xyhwm+32OxsTj3HyNiGPCKF2IQQHk4y1N/0Bz5Df3wTxhsSsIW3qNB7LuZbWJF8mnu7RxIa4MdnE7oSpJdvqRDC80mmAtQ5pwna/iLmht3J73Bvhd6zJTWD2ZsPczHfQtemYXRuHCaJXwjhNSRbKQrBWyahstvIuel1UJV9D/yc0cQrW47w/aFztKobxLy49rSqG+SiYIUQonr4dPLXpicR/N1EtNlpmJr0xh7StNz3PLvuD35Pz+HRXs25q2tjtGpZrCWE8D4+m/y16UmEfXEHoKAAupPbMOxMLHFmz1/ZBYQUFWLr1wK9Vk2zWgZXhyyEENXGZ+f5G355A1BQ8c9KXv3Rb4p9jV1RWLHnNPEf7+adokJsdYMk8QshvJ5P9vxVpmz8Tu9yPHfU7Ym6xfHa8fN5zNiYyt4/s+nRLJwxXaQQmxCi5vC95G/JJ+TrCahsZuCSMs1N+jiGfDYeOEvCtwcx+Gl46ZZW3NKmrhRiE0LUKL6V/G0WQjY8hN9fP5Nz81tgzkF/ZD2m6MGY2t6FXVFQq1RcUz+Ym2Lq8HifKCKkEJsQogbyneSv2Ane/AT6tM3k9JmFqeVQAExt76LAYuP9bcc4kZnHK0OvoXFYANMHt3ZzwEII4Ty+ccNXUQj6cRr+h77C2H0KBe3GOg4ln7rIXYv38MkvJwn198Nql0JsQoiazyd6/oafXyPgt4/Ji32Q/M7/AiDXbGX+tmN8vvcvGob6M39Ee7pFhrs5UiGEcI0anfy16UloNrxF4OGN5LeJJ/f6F+DvG7dWm8IPR85zZ+dGPHxDMwL8NG6OVgghXKfGJn9tehJhq+JQKVYUVBS0HkVWgZXle05zf49/CrFJ9U0hhC9ySuaz2+0kJCRw8OBBdDodM2bMIDIy0nF8y5YtvPXWW2i1WuLi4hg1alS1xxCwZwEo1r+fKRi3zyf+/CNcLLDSLTKcTo1DJfELIXyWU274btq0CbPZzIoVK3jqqaeYNWuW45jFYmHmzJksXLiQxYsXs2LFCjIyMqo9BnVuerHn59LTqBes55O7OtGpcWi1X08IIbyJU5J/UlISvXr1AiA2NpZ9+/Y5jh05coSmTZsSGhqKTqejS5cu7N69u9pjsDS6/p8nCpgbXc/CMZ2IkQqcQgjhnGEfo9FIUNA/SVaj0WC1WtFqtRiNRoKDgx3HAgMDMRqNZZ5Po1ERFla5ejrq0Ih/nqhUdG3dHHutwEqdw1tpNOpKf7+8nbTZN0ibq49Tkn9QUBC5ubmO53a7Ha1WW+Kx3NzcYr8MSmKzKWRl5VUqBm1EV8K0/ig2C2j8yI7oirWS5/BWYWGGSn+/vJ202TdImyunTp3Sc6tThn06d+7Mtm3bAEhJSSEmJsZxLDo6mrS0NLKysjCbzezevZtOnTpVewzW+l3Iun0F9j7PkXX7Cqz1u1T7NYQQwls5pec/YMAAduzYwejRo1EUhcTERNauXUteXh7x8fFMmTKF++67D0VRiIuLo169es4IA2v9Lthb9/KZHr8QQlSUSlEUj69nYLHYqvxnj/yZ6Bukzb5B2lw5Lh/2EUII4dkk+QshhA+S5C+EED5Ikr8QQvggSf5CCOGDvGK2jxBCiOolPX8hhPBBkvyFEMIHSfIXQggfJMlfCCF8kCR/IYTwQZL8hRDCB0nyF0IIH1Rjkr/dbmfatGnEx8czbtw40tLSih3fsmULcXFxxMfHs3LlSjdFWb3Ka/O6desYOXIko0ePZtq0adjtdjdFWn3Ka3ORqVOn8uqrr7o4uupXXnt//fVXxowZw5133snEiRMxmUxuirT6lNfmNWvWMGzYMOLi4li2bJmbonSOvXv3Mm7cuCted0r+UmqIDRs2KJMnT1YURVGSk5OVhx56yHHMbDYr/fv3V7KyshSTyaQMHz5cOXv2rLtCrTZltTk/P1+56aablLy8PEVRFOWJJ55QNm3a5JY4q1NZbS7y6aefKqNGjVLmzJnj6vCqXVnttdvtytChQ5Xjx48riqIoK1euVI4cOeKWOKtTeZ9xz549lczMTMVkMjn+XdcE7733nnLrrbcqI0eOLPa6s/JXjen5e8Km8a5WVpt1Oh3Lly8nICAAAKvVil6vd0uc1amsNgMkJyezd+9e4uPj3RFetSurvceOHSMsLIxFixYxduxYsrKyiIqKcleo1aa8z7hVq1bk5ORgNptRFAWVSuWOMKtd06ZNefPNN6943Vn5q8Yk/9I2jS86VtlN471BWW1Wq9XUrl0bgMWLF5OXl0fPnj3dEmd1KqvNZ8+eZf78+UybNs1d4VW7stqbmZlJcnIyY8aM4aOPPmLXrl389NNP7gq12pTVZoCWLVsSFxfHkCFD6Nu3LyEhIe4Is9oNHDjQsdf5pZyVv2pM8q/uTeO9QVltLno+e/ZsduzYwZtvvlkjekhltfnbb78lMzOTBx54gPfee49169axatUqd4VaLcpqb1hYGJGRkbRo0QI/Pz969ep1RS/ZG5XV5gMHDrB161Y2b97Mli1buHDhAt988427QnUJZ+WvGpP8PWHTeFcrq80A06ZNw2Qy8fbbbzuGf7xdWW0eP348q1atYvHixTzwwAPceuutDB8+3F2hVouy2tukSRNyc3MdN0R3795Ny5Yt3RJndSqrzcHBwfj7+6PX69FoNNSqVYvs7Gx3heoSzspfTtnA3R08ZdN4Vyqrze3atePzzz+na9eu3H333UBhchwwYICbo7465X3ONU157X355Zd56qmnUBSFTp060bdvX3eHfNXKa3N8fDxjxozBz8+Ppk2bMmzYMHeH7BTOzl9S0lkIIXxQjRn2EUIIUXGS/IUQwgdJ8hdCCB8kyV8IIXyQJH8hhPBBNWaqp6g5Tp06xdChQ2nbtq3jtW7duvHoo4+W+PVTpkxh8ODB9O7du0rX69evHw0aNECtVqMoCmFhYcyaNavYKtPyvPfee3Tv3p1WrVqxZs0aRo4cyapVqwgNDeWmm2666rhsNht5eXlMnz6d9u3bl/qeJUuWMHbs2CpdT/gWSf7CI7Vo0YLFixe77HoLFy501D6aM2cOq1atYvz48RV+/wMPPAAU/uL67LPPGDlyZLUsMLs0rh9//JH58+fz7rvvlvr1CxYskOQvKkSSv/AaNpuNadOmkZ6eTmZmJr179+bxxx93HD927BjPPvssWq0WjUbDK6+8Qr169Xjttdf45ZdfUBSFe+65h1tuuaXUa9jtdnJycmjevDkWi4XnnnuOkydPYrPZmDBhAoMHD2bp0qV89dVXqNVqOnfuzOTJkx1/fWzcuJHDhw8zf/58FEWhdu3aHD9+nNatWzNs2DAyMjJ48MEHWbVqVaXiAvjzzz8ddWy+/fZbli5d6jj23//+lxUrVnDx4kUSEhJ4/vnnefHFF0lLS8Nut/P444/TrVu3q/sARI0iyV94pMOHDxera/7qq69isViIjY1l5MiRmEymK5L/zp07adu2LVOmTGH37t1cvHiRAwcOcOrUKZYvX47JZGLUqFH07NnzimJg9957L2q1GpVKRYcOHbjjjjtYvnw54eHhzJkzB6PRyPDhw+nevTurVq1i6tSpxMbGsmzZsmJFxx566CFSU1N59NFHHRUaR40axUsvvcSwYcNYvXo1w4cP54cffqhwXCaTibNnz9KrVy8mT54MwPHjx3nvvfcICAhg2rRpbN++nYcffpglS5aQkJDAsmXLCA8PJzExkczMTMaOHcvXX39d3R+T8GKS/IVHKmnYx2g08ttvv7Fr1y6CgoIwm83Fjo8YMYL333+f+++/n+DgYJ544glSU1PZv3+/4xeJ1Wot1oMucunwSpEjR45w/fXXA4XFtaKjozl58iQzZ85k4cKFvPrqq8TGxlLeIvno6GhsNhunT59m/fr1fPzxx6xYsaJScb3++uucOnWKiIgIACIiIpg8eTKBgYEcPXqU2NjYYu9LTU0lKSmJX3/91XH+zMxMwsPDy4xV+A6Z7SO8xqpVqwgODua1117j3nvvpaCgoFji3bx5M126dGHRokUMGjSIDz74gKioKLp168bixYtZtGgRt9xyC40bN67Q9aKjox11041GI6mpqTRu3JiVK1fy0ksvsWTJEv744w+Sk5Md71Gr1SXumDZixAjmzJlDixYtCAkJqXRcjz/+OGfPnmXZsmXk5OQwb9483njjDWbMmIFer3d8H4r+GxUVxZAhQ1i8eDHvv/8+gwYNIjQ0tELtFr5Bkr/wGj169GDbtm2MHj2ahIQEIiMjOXv2rON4u3btmDt3LmPGjGH58uWMHTuWfv36YTAYGDNmjOMGbEVn8YwaNYqsrCzuvPNOxo8fz6OPPkpERAStWrVixIgRjB8/nlq1atGxY0fHeyIiIrBYLMyZM6fYuQYNGsT27dsZOXIkQKXjUqvVvPzyyyxYsIC8vDw6d+7MsGHDuOuuu/D393d8H6Kjo5k0aRKjR4/m6NGjjB07ltGjR9OoUSPUavnnLv4hhd2EEMIHSVdACCF8kCR/IYTwQZL8hRDCB0nyF0IIHyTJXwghfJAkfyGE8EGS/IUQwgf9PyRTZU68Afy0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = lgb.Dataset(X_train, label=y_train)\n",
    "val = lgb.Dataset(X_val, label=y_val)\n",
    "lgbm2 = lgb.train(best_params, train, valid_sets=val, early_stopping_rounds=100, verbose_eval=False)\n",
    "\n",
    "evaluate_lgbm(lgbm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba21f3b",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7111c208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define the search space for XGBoost parameters\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'booster': 'gbtree',\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 10),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.01),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
    "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1.0, 2.5),  \n",
    "    }\n",
    "\n",
    "    # Train and evaluate the XGBoost model\n",
    "    model = xgb.XGBClassifier(**params, random_state=5)\n",
    "    model.fit(X_train, y_train)\n",
    "    pos_probs = model.predict_proba(X_val)[:, 1]\n",
    "    score = roc_auc_score(y_val, pos_probs)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f88fe28d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:41:03,933] A new study created in memory with name: no-name-2c61a860-a482-4ff7-a006-3c20c7beb2c0\n",
      "[I 2023-07-05 16:41:04,742] Trial 0 finished with value: 0.6166941756475398 and parameters: {'max_depth': 4, 'learning_rate': 0.003254356356784512, 'subsample': 0.7527081152941175, 'colsample_bytree': 0.9407097009467185, 'lambda': 0.00010615385374293511, 'alpha': 0.005772185107222336, 'scale_pos_weight': 1.422071073337925}. Best is trial 0 with value: 0.6166941756475398.\n",
      "[I 2023-07-05 16:41:05,109] Trial 1 finished with value: 0.6132381127041148 and parameters: {'max_depth': 2, 'learning_rate': 0.0010045945351528842, 'subsample': 0.5434955172021464, 'colsample_bytree': 0.5041944311611444, 'lambda': 0.03697629805015268, 'alpha': 0.1975468255408901, 'scale_pos_weight': 2.239022679241227}. Best is trial 0 with value: 0.6166941756475398.\n",
      "[I 2023-07-05 16:41:05,548] Trial 2 finished with value: 0.6128842716952365 and parameters: {'max_depth': 3, 'learning_rate': 0.007949052027816766, 'subsample': 0.5643099159008012, 'colsample_bytree': 0.5516146080057673, 'lambda': 6.995679927518229e-05, 'alpha': 6.900450777363759e-07, 'scale_pos_weight': 2.2351299705792744}. Best is trial 0 with value: 0.6166941756475398.\n",
      "[I 2023-07-05 16:41:06,162] Trial 3 finished with value: 0.6149278473593176 and parameters: {'max_depth': 4, 'learning_rate': 0.0015480523385731466, 'subsample': 0.8473668361367214, 'colsample_bytree': 0.6965873674692418, 'lambda': 0.015442132814357001, 'alpha': 0.0003780594874469805, 'scale_pos_weight': 2.323883275710233}. Best is trial 0 with value: 0.6166941756475398.\n",
      "[I 2023-07-05 16:41:06,941] Trial 4 finished with value: 0.6213757367192754 and parameters: {'max_depth': 6, 'learning_rate': 0.0016658533744066477, 'subsample': 0.960942245639226, 'colsample_bytree': 0.529648949168845, 'lambda': 0.0004512893724459488, 'alpha': 2.634676501037853e-08, 'scale_pos_weight': 1.4595454433315806}. Best is trial 4 with value: 0.6213757367192754.\n",
      "[I 2023-07-05 16:41:07,582] Trial 5 finished with value: 0.6145722083778332 and parameters: {'max_depth': 5, 'learning_rate': 0.001476790132037757, 'subsample': 0.5901451775170391, 'colsample_bytree': 0.5356464643369395, 'lambda': 0.5258561102155132, 'alpha': 6.932647275978472e-08, 'scale_pos_weight': 1.2858981806657415}. Best is trial 4 with value: 0.6213757367192754.\n",
      "[I 2023-07-05 16:41:08,351] Trial 6 finished with value: 0.616621897148775 and parameters: {'max_depth': 6, 'learning_rate': 0.0012669953632989124, 'subsample': 0.569202674986926, 'colsample_bytree': 0.536888978169202, 'lambda': 2.6471650806141123e-05, 'alpha': 1.0320507298850191e-06, 'scale_pos_weight': 1.5844566548465402}. Best is trial 4 with value: 0.6213757367192754.\n",
      "[I 2023-07-05 16:41:10,432] Trial 7 finished with value: 0.6211574628448961 and parameters: {'max_depth': 10, 'learning_rate': 0.0013187086201593152, 'subsample': 0.9545995134900456, 'colsample_bytree': 0.8159735335359194, 'lambda': 7.094170971043101e-07, 'alpha': 4.6380402852549995e-08, 'scale_pos_weight': 1.7837831425676018}. Best is trial 4 with value: 0.6213757367192754.\n",
      "[I 2023-07-05 16:41:11,128] Trial 8 finished with value: 0.6235771743781711 and parameters: {'max_depth': 5, 'learning_rate': 0.004206958862172562, 'subsample': 0.6033239647257204, 'colsample_bytree': 0.640360831047304, 'lambda': 6.022925316183255e-07, 'alpha': 4.414034102757725e-06, 'scale_pos_weight': 1.0767138916184895}. Best is trial 8 with value: 0.6235771743781711.\n",
      "[I 2023-07-05 16:41:11,430] Trial 9 finished with value: 0.613888619192998 and parameters: {'max_depth': 2, 'learning_rate': 0.006736840129437709, 'subsample': 0.8474695410023989, 'colsample_bytree': 0.6021276465623997, 'lambda': 0.003718085605302558, 'alpha': 1.824436077286675e-07, 'scale_pos_weight': 1.4320383282833498}. Best is trial 8 with value: 0.6235771743781711.\n",
      "[I 2023-07-05 16:41:13,107] Trial 10 finished with value: 0.6223937488088431 and parameters: {'max_depth': 9, 'learning_rate': 0.004390134923253369, 'subsample': 0.6536797752570845, 'colsample_bytree': 0.66786953314216, 'lambda': 2.136115570515184e-08, 'alpha': 1.570773183406857e-05, 'scale_pos_weight': 1.0436356344639117}. Best is trial 8 with value: 0.6235771743781711.\n",
      "[I 2023-07-05 16:41:14,865] Trial 11 finished with value: 0.6217914279858032 and parameters: {'max_depth': 9, 'learning_rate': 0.004383779998809408, 'subsample': 0.6618228849296024, 'colsample_bytree': 0.6689347129917168, 'lambda': 1.4103895323995995e-08, 'alpha': 1.4943727746002031e-05, 'scale_pos_weight': 1.018406654264974}. Best is trial 8 with value: 0.6235771743781711.\n",
      "[I 2023-07-05 16:41:16,616] Trial 12 finished with value: 0.622043503745177 and parameters: {'max_depth': 8, 'learning_rate': 0.004928144495399129, 'subsample': 0.6629518303184139, 'colsample_bytree': 0.7582116445889336, 'lambda': 1.4148490542212538e-08, 'alpha': 1.1181748864775412e-05, 'scale_pos_weight': 1.0238544235729785}. Best is trial 8 with value: 0.6235771743781711.\n",
      "[I 2023-07-05 16:41:17,945] Trial 13 finished with value: 0.6170555681413638 and parameters: {'max_depth': 8, 'learning_rate': 0.0027898410176796736, 'subsample': 0.5167618431254724, 'colsample_bytree': 0.6585148760873647, 'lambda': 8.263758572881064e-07, 'alpha': 0.00010048786455555845, 'scale_pos_weight': 1.1686406708262118}. Best is trial 8 with value: 0.6235771743781711.\n",
      "[I 2023-07-05 16:41:19,315] Trial 14 finished with value: 0.6273352967194192 and parameters: {'max_depth': 7, 'learning_rate': 0.008798540003404307, 'subsample': 0.6449259349403595, 'colsample_bytree': 0.6265680095162243, 'lambda': 2.3824463532880096e-07, 'alpha': 2.9408396880917975e-06, 'scale_pos_weight': 1.1900694334787294}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:20,603] Trial 15 finished with value: 0.6263305896271365 and parameters: {'max_depth': 7, 'learning_rate': 0.009225777157205782, 'subsample': 0.6176230037016943, 'colsample_bytree': 0.5916855187758127, 'lambda': 9.241592412881364e-07, 'alpha': 1.2636128722095773e-06, 'scale_pos_weight': 1.2429201862790022}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:21,778] Trial 16 finished with value: 0.6183885850315185 and parameters: {'max_depth': 7, 'learning_rate': 0.009180916930726245, 'subsample': 0.7164881380697938, 'colsample_bytree': 0.5958430957141272, 'lambda': 7.115192944499126e-06, 'alpha': 1.1669898682521492e-08, 'scale_pos_weight': 1.2534685865297888}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:23,154] Trial 17 finished with value: 0.62298923733598 and parameters: {'max_depth': 7, 'learning_rate': 0.009588022427191062, 'subsample': 0.5197571391998961, 'colsample_bytree': 0.7406161473367883, 'lambda': 1.3160418476647074e-07, 'alpha': 4.332361628495994e-07, 'scale_pos_weight': 1.7461686637371674}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:24,344] Trial 18 finished with value: 0.6194465121129414 and parameters: {'max_depth': 7, 'learning_rate': 0.006562635636901439, 'subsample': 0.5020405848317758, 'colsample_bytree': 0.5985962838867135, 'lambda': 4.373088442436697e-06, 'alpha': 1.9974238233451285e-06, 'scale_pos_weight': 1.2614404807881883}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:25,722] Trial 19 finished with value: 0.6212502382313703 and parameters: {'max_depth': 8, 'learning_rate': 0.009958046897490988, 'subsample': 0.6375935891627682, 'colsample_bytree': 0.5916784886786004, 'lambda': 1.5626175060029105e-07, 'alpha': 2.43041952102579e-07, 'scale_pos_weight': 1.2014706926627503}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:26,437] Trial 20 finished with value: 0.6199833867331197 and parameters: {'max_depth': 5, 'learning_rate': 0.006863046706113572, 'subsample': 0.7142598388398901, 'colsample_bytree': 0.5009364557279137, 'lambda': 4.653864996041152e-06, 'alpha': 8.286014490657908e-05, 'scale_pos_weight': 1.5891572006906842}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:27,334] Trial 21 finished with value: 0.6230805743443693 and parameters: {'max_depth': 5, 'learning_rate': 0.005521366612581062, 'subsample': 0.595594696596017, 'colsample_bytree': 0.6325764315624341, 'lambda': 5.054731360543295e-07, 'alpha': 2.781160400168271e-06, 'scale_pos_weight': 1.1201129688775773}. Best is trial 14 with value: 0.6273352967194192.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:41:28,255] Trial 22 finished with value: 0.6256283015271978 and parameters: {'max_depth': 6, 'learning_rate': 0.008045981922568755, 'subsample': 0.6318698973282046, 'colsample_bytree': 0.6296501662896861, 'lambda': 1.2051288809310523e-07, 'alpha': 5.792058249259608e-06, 'scale_pos_weight': 1.1489601372708562}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:29,235] Trial 23 finished with value: 0.6207557957646956 and parameters: {'max_depth': 7, 'learning_rate': 0.008276464878691518, 'subsample': 0.6397275561874975, 'colsample_bytree': 0.5694029399170818, 'lambda': 1.0489935658771904e-07, 'alpha': 1.1876275444637273e-07, 'scale_pos_weight': 1.326216342933935}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:30,131] Trial 24 finished with value: 0.6243912963742084 and parameters: {'max_depth': 6, 'learning_rate': 0.007980958824136136, 'subsample': 0.6136985878133129, 'colsample_bytree': 0.622740645168122, 'lambda': 5.4621467126103496e-08, 'alpha': 8.597790686411702e-07, 'scale_pos_weight': 1.1917461760929267}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:30,982] Trial 25 finished with value: 0.6223106824744419 and parameters: {'max_depth': 6, 'learning_rate': 0.00993136023337224, 'subsample': 0.551795052378475, 'colsample_bytree': 0.5788996906099537, 'lambda': 5.4589730206541236e-08, 'alpha': 4.486397067519744e-06, 'scale_pos_weight': 1.0047778842544375}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:32,536] Trial 26 finished with value: 0.6193397125401398 and parameters: {'max_depth': 9, 'learning_rate': 0.006216608931423797, 'subsample': 0.6852673702653002, 'colsample_bytree': 0.6310616391073585, 'lambda': 1.9545501731010145e-06, 'alpha': 4.603076662055035e-07, 'scale_pos_weight': 1.1664314014300996}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:33,886] Trial 27 finished with value: 0.6239191487678494 and parameters: {'max_depth': 8, 'learning_rate': 0.0077171502974221345, 'subsample': 0.6172063195365584, 'colsample_bytree': 0.6976572761214505, 'lambda': 1.8239194630758834e-07, 'alpha': 3.888798204093554e-05, 'scale_pos_weight': 1.3073304559060204}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:35,160] Trial 28 finished with value: 0.6214390253550097 and parameters: {'max_depth': 7, 'learning_rate': 0.005630812098801152, 'subsample': 0.5689579065414323, 'colsample_bytree': 0.5628361851868361, 'lambda': 1.8698065245407882e-06, 'alpha': 2.7614974965632853e-06, 'scale_pos_weight': 1.361301798856478}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:36,012] Trial 29 finished with value: 0.6182760319463774 and parameters: {'max_depth': 4, 'learning_rate': 0.007341756279601869, 'subsample': 0.7456780261465036, 'colsample_bytree': 0.9689326803789009, 'lambda': 1.3875090328624148e-05, 'alpha': 0.0013299450175788849, 'scale_pos_weight': 1.113610479881842}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:38,272] Trial 30 finished with value: 0.6158937182433089 and parameters: {'max_depth': 10, 'learning_rate': 0.008809743219826133, 'subsample': 0.685798169712576, 'colsample_bytree': 0.8276875194355674, 'lambda': 3.1247334933256405e-07, 'alpha': 9.237602811685283e-06, 'scale_pos_weight': 1.3842458970354894}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:39,420] Trial 31 finished with value: 0.6225771420146643 and parameters: {'max_depth': 6, 'learning_rate': 0.008039362497665412, 'subsample': 0.6156345899393245, 'colsample_bytree': 0.6207885796572132, 'lambda': 4.7709884369244304e-08, 'alpha': 7.84154604253641e-07, 'scale_pos_weight': 1.1848375918750482}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:40,437] Trial 32 finished with value: 0.6243844640783054 and parameters: {'max_depth': 6, 'learning_rate': 0.008489335510446368, 'subsample': 0.6175915841189963, 'colsample_bytree': 0.6111960026520271, 'lambda': 3.033861631441382e-08, 'alpha': 1.48912312804232e-06, 'scale_pos_weight': 1.185534918701615}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:41,521] Trial 33 finished with value: 0.6231215681197881 and parameters: {'max_depth': 6, 'learning_rate': 0.00720769410795068, 'subsample': 0.5841953153129278, 'colsample_bytree': 0.5670729643113278, 'lambda': 1.0686802480800701e-08, 'alpha': 2.2867189534137467e-07, 'scale_pos_weight': 1.0960821215225212}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:42,806] Trial 34 finished with value: 0.6227537029245822 and parameters: {'max_depth': 7, 'learning_rate': 0.008570369434959743, 'subsample': 0.5284422365676437, 'colsample_bytree': 0.6474733955508619, 'lambda': 7.602095526502427e-08, 'alpha': 7.986069349610266e-07, 'scale_pos_weight': 1.2413541303294293}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:43,464] Trial 35 finished with value: 0.6139821137685146 and parameters: {'max_depth': 4, 'learning_rate': 0.0075706115871352, 'subsample': 0.5647560780808869, 'colsample_bytree': 0.5316922292018303, 'lambda': 2.5574252793509795e-07, 'alpha': 3.886349429172381e-05, 'scale_pos_weight': 1.48461377855517}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:44,237] Trial 36 finished with value: 0.6171720767662383 and parameters: {'max_depth': 5, 'learning_rate': 0.005643861661337571, 'subsample': 0.5510822012236675, 'colsample_bytree': 0.5560124815085996, 'lambda': 4.6740574751156935e-08, 'alpha': 0.31569935939157284, 'scale_pos_weight': 1.3525805390797214}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:44,754] Trial 37 finished with value: 0.6157660621882766 and parameters: {'max_depth': 3, 'learning_rate': 0.00992603559607043, 'subsample': 0.621955270504308, 'colsample_bytree': 0.5164344057433898, 'lambda': 1.4064931684615417e-06, 'alpha': 6.862813975845753e-08, 'scale_pos_weight': 1.109614017601536}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:45,942] Trial 38 finished with value: 0.6238882236390246 and parameters: {'max_depth': 6, 'learning_rate': 0.006306089546009695, 'subsample': 0.5874286257318079, 'colsample_bytree': 0.6868019634769895, 'lambda': 3.364896872350095e-07, 'alpha': 5.415451670942156e-06, 'scale_pos_weight': 1.278023628721538}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:47,387] Trial 39 finished with value: 0.6222966582881142 and parameters: {'max_depth': 8, 'learning_rate': 0.008442046026575892, 'subsample': 0.6408749363879864, 'colsample_bytree': 0.6205519858384334, 'lambda': 0.00012986178495915372, 'alpha': 0.05366937155871797, 'scale_pos_weight': 1.501066929094751}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:48,302] Trial 40 finished with value: 0.619712971653164 and parameters: {'max_depth': 5, 'learning_rate': 0.007615916954352825, 'subsample': 0.5436933936075267, 'colsample_bytree': 0.5816800048511801, 'lambda': 9.401285082983647e-08, 'alpha': 1.3825971744808295e-06, 'scale_pos_weight': 1.2241335883198559}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:49,381] Trial 41 finished with value: 0.6248109431804698 and parameters: {'max_depth': 6, 'learning_rate': 0.008799628429592346, 'subsample': 0.6083712039342641, 'colsample_bytree': 0.6210508699984635, 'lambda': 2.5116045869967872e-08, 'alpha': 1.8866090720409578e-06, 'scale_pos_weight': 1.1592057081493532}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:50,480] Trial 42 finished with value: 0.621442980894743 and parameters: {'max_depth': 7, 'learning_rate': 0.00896197835416305, 'subsample': 0.5959521087172167, 'colsample_bytree': 0.5502819663789007, 'lambda': 1.1000729589223274e-08, 'alpha': 1.4723368540730383e-06, 'scale_pos_weight': 1.0884337365291896}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:51,354] Trial 43 finished with value: 0.6239263406582738 and parameters: {'max_depth': 6, 'learning_rate': 0.0068781330534732005, 'subsample': 0.5827429275160676, 'colsample_bytree': 0.6109364928167724, 'lambda': 3.401958116246317e-08, 'alpha': 3.9906257735921794e-07, 'scale_pos_weight': 1.0040578046217434}. Best is trial 14 with value: 0.6273352967194192.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:41:52,432] Trial 44 finished with value: 0.6210265704391728 and parameters: {'max_depth': 6, 'learning_rate': 0.007835696292853212, 'subsample': 0.6731489281661845, 'colsample_bytree': 0.6577966757336335, 'lambda': 2.6134451150169335e-08, 'alpha': 4.7634882542343725e-06, 'scale_pos_weight': 1.3024157835814265}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:53,493] Trial 45 finished with value: 0.620998881661039 and parameters: {'max_depth': 7, 'learning_rate': 0.008966044773148931, 'subsample': 0.6353251719038915, 'colsample_bytree': 0.528355873836991, 'lambda': 2.5723202480749966e-07, 'alpha': 1.0496931933049068e-07, 'scale_pos_weight': 1.1724226670093336}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:54,381] Trial 46 finished with value: 0.618125361841987 and parameters: {'max_depth': 5, 'learning_rate': 0.006117696108631957, 'subsample': 0.655125044951816, 'colsample_bytree': 0.6344561057062329, 'lambda': 5.400372724375986e-07, 'alpha': 7.001350125770765e-07, 'scale_pos_weight': 1.4179989042035674}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:55,916] Trial 47 finished with value: 0.6249127084299744 and parameters: {'max_depth': 8, 'learning_rate': 0.00717266068699526, 'subsample': 0.6170677879139679, 'colsample_bytree': 0.5938460512042883, 'lambda': 1.0708961392549872e-07, 'alpha': 3.688743700167015e-08, 'scale_pos_weight': 1.0620273181652469}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:57,603] Trial 48 finished with value: 0.6237843008223927 and parameters: {'max_depth': 9, 'learning_rate': 0.007029331175503793, 'subsample': 0.6771420517247483, 'colsample_bytree': 0.5832361586081931, 'lambda': 1.0694691485925305e-06, 'alpha': 3.3179030422285316e-08, 'scale_pos_weight': 1.0559674195176731}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:41:59,182] Trial 49 finished with value: 0.6243402339521955 and parameters: {'max_depth': 8, 'learning_rate': 0.009341984314512474, 'subsample': 0.5727887387085966, 'colsample_bytree': 0.5459692278550599, 'lambda': 1.3698616858630023e-07, 'alpha': 1.5848321460449334e-08, 'scale_pos_weight': 1.1300921185858088}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:42:00,618] Trial 50 finished with value: 0.6255189847927477 and parameters: {'max_depth': 8, 'learning_rate': 0.005086365300259332, 'subsample': 0.6057026348401989, 'colsample_bytree': 0.5991846986380607, 'lambda': 2.655540630511112e-08, 'alpha': 3.60131306085919e-08, 'scale_pos_weight': 1.0628809861576616}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:42:01,894] Trial 51 finished with value: 0.6215990449169517 and parameters: {'max_depth': 8, 'learning_rate': 0.006895048855106514, 'subsample': 0.5997222013756464, 'colsample_bytree': 0.598317943808279, 'lambda': 2.1983324190556684e-08, 'alpha': 4.0740868653939636e-08, 'scale_pos_weight': 1.0609041449067553}. Best is trial 14 with value: 0.6273352967194192.\n",
      "[I 2023-07-05 16:42:03,497] Trial 52 finished with value: 0.6276441884131454 and parameters: {'max_depth': 9, 'learning_rate': 0.004980436729921733, 'subsample': 0.6504444946250395, 'colsample_bytree': 0.6014546837780884, 'lambda': 8.1172388261155e-08, 'alpha': 2.1480928905069642e-08, 'scale_pos_weight': 1.2356491054936276}. Best is trial 52 with value: 0.6276441884131454.\n",
      "[I 2023-07-05 16:42:05,060] Trial 53 finished with value: 0.6217223858377294 and parameters: {'max_depth': 9, 'learning_rate': 0.003493228525644323, 'subsample': 0.6533929704437955, 'colsample_bytree': 0.5911159747710223, 'lambda': 7.351407127702219e-08, 'alpha': 1.0140860287131407e-08, 'scale_pos_weight': 1.2408342910662449}. Best is trial 52 with value: 0.6276441884131454.\n",
      "[I 2023-07-05 16:42:06,674] Trial 54 finished with value: 0.6158581183857083 and parameters: {'max_depth': 10, 'learning_rate': 0.005231079204798958, 'subsample': 0.7002539408518852, 'colsample_bytree': 0.6452890668644129, 'lambda': 3.9116288324035766e-07, 'alpha': 2.3411383934402506e-08, 'scale_pos_weight': 1.0559161368532886}. Best is trial 52 with value: 0.6276441884131454.\n",
      "[I 2023-07-05 16:42:08,202] Trial 55 finished with value: 0.6219910029450791 and parameters: {'max_depth': 9, 'learning_rate': 0.004642335835083622, 'subsample': 0.631512107378073, 'colsample_bytree': 0.5700903294202762, 'lambda': 1.8137037936988445e-07, 'alpha': 6.579529272096509e-08, 'scale_pos_weight': 1.2789898046506574}. Best is trial 52 with value: 0.6276441884131454.\n",
      "[I 2023-07-05 16:42:09,396] Trial 56 finished with value: 0.6268347411458839 and parameters: {'max_depth': 8, 'learning_rate': 0.006044590882112804, 'subsample': 0.6467965653080312, 'colsample_bytree': 0.6026669455519671, 'lambda': 8.536410142827438e-07, 'alpha': 1.354586608113478e-07, 'scale_pos_weight': 1.0021112079894527}. Best is trial 52 with value: 0.6276441884131454.\n",
      "[I 2023-07-05 16:42:10,654] Trial 57 finished with value: 0.6229824050400768 and parameters: {'max_depth': 7, 'learning_rate': 0.005003826847572687, 'subsample': 0.653612296912697, 'colsample_bytree': 0.6718933165040343, 'lambda': 7.141402771284556e-07, 'alpha': 1.3022558608997666e-07, 'scale_pos_weight': 1.0000932368555127}. Best is trial 52 with value: 0.6276441884131454.\n",
      "[I 2023-07-05 16:42:11,851] Trial 58 finished with value: 0.620741411983847 and parameters: {'max_depth': 8, 'learning_rate': 0.003836737390229585, 'subsample': 0.6679859833441838, 'colsample_bytree': 0.5430366559226967, 'lambda': 2.92355015119437e-06, 'alpha': 3.9977534906686374e-07, 'scale_pos_weight': 1.1488493543007434}. Best is trial 52 with value: 0.6276441884131454.\n",
      "[I 2023-07-05 16:42:13,247] Trial 59 finished with value: 0.6261428812870606 and parameters: {'max_depth': 9, 'learning_rate': 0.0057897890964198635, 'subsample': 0.697108748063568, 'colsample_bytree': 0.6041420948096107, 'lambda': 9.220717654874629e-07, 'alpha': 1.8133139309548623e-07, 'scale_pos_weight': 1.2162555778704272}. Best is trial 52 with value: 0.6276441884131454.\n",
      "[I 2023-07-05 16:42:14,661] Trial 60 finished with value: 0.6220618430657591 and parameters: {'max_depth': 9, 'learning_rate': 0.00589287062632748, 'subsample': 0.697612928850251, 'colsample_bytree': 0.6403418671072215, 'lambda': 1.004756014087836e-06, 'alpha': 1.244743776681336e-07, 'scale_pos_weight': 1.2080753559737143}. Best is trial 52 with value: 0.6276441884131454.\n",
      "[I 2023-07-05 16:42:16,483] Trial 61 finished with value: 0.6259242478181603 and parameters: {'max_depth': 10, 'learning_rate': 0.0063407639842781045, 'subsample': 0.6469734053392551, 'colsample_bytree': 0.60222285875432, 'lambda': 5.34091876558881e-07, 'alpha': 2.111876310391254e-07, 'scale_pos_weight': 1.1308290875344433}. Best is trial 52 with value: 0.6276441884131454.\n",
      "[I 2023-07-05 16:42:18,154] Trial 62 finished with value: 0.6226469033517805 and parameters: {'max_depth': 10, 'learning_rate': 0.006366446666946807, 'subsample': 0.6457302593443165, 'colsample_bytree': 0.6099888038501403, 'lambda': 2.8186573771333802e-06, 'alpha': 1.7721714127980484e-07, 'scale_pos_weight': 1.3367615221491829}. Best is trial 52 with value: 0.6276441884131454.\n",
      "[I 2023-07-05 16:42:19,780] Trial 63 finished with value: 0.6209309182965288 and parameters: {'max_depth': 10, 'learning_rate': 0.006470782334831479, 'subsample': 0.662026644900133, 'colsample_bytree': 0.5812949581675688, 'lambda': 5.403861883624864e-07, 'alpha': 3.2774390627425003e-07, 'scale_pos_weight': 1.2282223079647998}. Best is trial 52 with value: 0.6276441884131454.\n",
      "[I 2023-07-05 16:42:21,446] Trial 64 finished with value: 0.6151026102966296 and parameters: {'max_depth': 9, 'learning_rate': 0.005914778849569475, 'subsample': 0.7155920887437905, 'colsample_bytree': 0.5670748849151851, 'lambda': 6.678793031551014e-06, 'alpha': 2.479226147845229e-07, 'scale_pos_weight': 1.1233873117662916}. Best is trial 52 with value: 0.6276441884131454.\n",
      "[I 2023-07-05 16:42:23,142] Trial 65 finished with value: 0.6213390580781111 and parameters: {'max_depth': 10, 'learning_rate': 0.005455373648866949, 'subsample': 0.6312250031639739, 'colsample_bytree': 0.6095093336859971, 'lambda': 1.1373637786131494e-06, 'alpha': 5.07600229295079e-07, 'scale_pos_weight': 1.2859681146727135}. Best is trial 52 with value: 0.6276441884131454.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:42:24,561] Trial 66 finished with value: 0.6193932921238012 and parameters: {'max_depth': 9, 'learning_rate': 0.0081031345760025, 'subsample': 0.6918941495777425, 'colsample_bytree': 0.6517551219486659, 'lambda': 1.9044411915032658e-07, 'alpha': 9.547094951615759e-08, 'scale_pos_weight': 1.143055069929624}. Best is trial 52 with value: 0.6276441884131454.\n",
      "[I 2023-07-05 16:42:26,425] Trial 67 finished with value: 0.6174331423886426 and parameters: {'max_depth': 10, 'learning_rate': 0.006710014115487663, 'subsample': 0.6763465402719526, 'colsample_bytree': 0.6282981473964055, 'lambda': 4.687921174156081e-07, 'alpha': 1.8973788763272876e-07, 'scale_pos_weight': 1.2277246495517988}. Best is trial 52 with value: 0.6276441884131454.\n",
      "[I 2023-07-05 16:42:27,465] Trial 68 finished with value: 0.6190869175917235 and parameters: {'max_depth': 7, 'learning_rate': 0.004730604541793358, 'subsample': 0.662737886284712, 'colsample_bytree': 0.5526765021010928, 'lambda': 1.8393566053242725e-06, 'alpha': 9.893652957726463e-07, 'scale_pos_weight': 1.0999560343683161}. Best is trial 52 with value: 0.6276441884131454.\n",
      "[I 2023-07-05 16:42:28,916] Trial 69 finished with value: 0.6216828304403954 and parameters: {'max_depth': 9, 'learning_rate': 0.009515529864722247, 'subsample': 0.6352593861193494, 'colsample_bytree': 0.5759583154670433, 'lambda': 1.1590164227302843e-05, 'alpha': 1.8692606484538515e-08, 'scale_pos_weight': 1.3913505193727074}. Best is trial 52 with value: 0.6276441884131454.\n",
      "[I 2023-07-05 16:42:30,289] Trial 70 finished with value: 0.6217730886652211 and parameters: {'max_depth': 7, 'learning_rate': 0.007306122770868815, 'subsample': 0.7225779534755852, 'colsample_bytree': 0.6742313915770516, 'lambda': 2.601080668094204e-07, 'alpha': 6.640102368542228e-08, 'scale_pos_weight': 1.3034494286093352}. Best is trial 52 with value: 0.6276441884131454.\n",
      "[I 2023-07-05 16:42:31,829] Trial 71 finished with value: 0.6297470971732274 and parameters: {'max_depth': 8, 'learning_rate': 0.00521268948874685, 'subsample': 0.6096278572284558, 'colsample_bytree': 0.6038128629036056, 'lambda': 4.9252793204530354e-08, 'alpha': 2.1151261530754417e-08, 'scale_pos_weight': 1.0438152138943535}. Best is trial 71 with value: 0.6297470971732274.\n",
      "[I 2023-07-05 16:42:33,241] Trial 72 finished with value: 0.6236731861153364 and parameters: {'max_depth': 8, 'learning_rate': 0.005413158131451548, 'subsample': 0.6266412772581834, 'colsample_bytree': 0.6075267745840127, 'lambda': 6.271101348428592e-08, 'alpha': 1.6647478599182514e-08, 'scale_pos_weight': 1.0297938101160664}. Best is trial 71 with value: 0.6297470971732274.\n",
      "[I 2023-07-05 16:42:34,865] Trial 73 finished with value: 0.6224160436691586 and parameters: {'max_depth': 9, 'learning_rate': 0.005885684957380074, 'subsample': 0.650614326359412, 'colsample_bytree': 0.5863804243473484, 'lambda': 1.4405090484366188e-07, 'alpha': 5.982983830096991e-08, 'scale_pos_weight': 1.18893264434599}. Best is trial 71 with value: 0.6297470971732274.\n",
      "[I 2023-07-05 16:42:36,533] Trial 74 finished with value: 0.6229651445030584 and parameters: {'max_depth': 8, 'learning_rate': 0.00646139161237668, 'subsample': 0.6000402411087835, 'colsample_bytree': 0.6376345891379236, 'lambda': 5.784973743084226e-07, 'alpha': 2.8336147065625913e-08, 'scale_pos_weight': 1.0902560704922615}. Best is trial 71 with value: 0.6297470971732274.\n",
      "[I 2023-07-05 16:42:38,444] Trial 75 finished with value: 0.6144503058351403 and parameters: {'max_depth': 10, 'learning_rate': 0.007648525246492725, 'subsample': 0.6441515750431648, 'colsample_bytree': 0.5591246254321843, 'lambda': 9.546264050650376e-08, 'alpha': 2.6065216944921508e-06, 'scale_pos_weight': 1.1471249525134863}. Best is trial 71 with value: 0.6297470971732274.\n",
      "[I 2023-07-05 16:42:40,088] Trial 76 finished with value: 0.6209079042471709 and parameters: {'max_depth': 9, 'learning_rate': 0.004517198050594737, 'subsample': 0.6797742119117643, 'colsample_bytree': 0.6287583457490362, 'lambda': 3.2426601739654767e-07, 'alpha': 2.7261039967805355e-07, 'scale_pos_weight': 1.0306236966477538}. Best is trial 71 with value: 0.6297470971732274.\n",
      "[I 2023-07-05 16:42:41,681] Trial 77 finished with value: 0.6242902503137462 and parameters: {'max_depth': 8, 'learning_rate': 0.008284973224703155, 'subsample': 0.6266008439299986, 'colsample_bytree': 0.6017107570366885, 'lambda': 7.087001087617023e-07, 'alpha': 5.437493325560658e-07, 'scale_pos_weight': 1.2032765047216551}. Best is trial 71 with value: 0.6297470971732274.\n",
      "[I 2023-07-05 16:42:42,812] Trial 78 finished with value: 0.6271835478314652 and parameters: {'max_depth': 7, 'learning_rate': 0.0048833859923467825, 'subsample': 0.6092170685750129, 'colsample_bytree': 0.6159264267365571, 'lambda': 1.6876567056247078e-08, 'alpha': 9.571190013183647e-08, 'scale_pos_weight': 1.1291293846913715}. Best is trial 71 with value: 0.6297470971732274.\n",
      "[I 2023-07-05 16:42:43,926] Trial 79 finished with value: 0.6267977029101985 and parameters: {'max_depth': 7, 'learning_rate': 0.004879971039514382, 'subsample': 0.5877086319150997, 'colsample_bytree': 0.6154928125605689, 'lambda': 1.4357184580639737e-08, 'alpha': 9.320860544966386e-08, 'scale_pos_weight': 1.2657390848232328}. Best is trial 71 with value: 0.6297470971732274.\n",
      "[I 2023-07-05 16:42:45,234] Trial 80 finished with value: 0.6193727952360918 and parameters: {'max_depth': 7, 'learning_rate': 0.004243182904877766, 'subsample': 0.5830269221018456, 'colsample_bytree': 0.6576316993925818, 'lambda': 1.8170199419941668e-08, 'alpha': 9.530667518951521e-08, 'scale_pos_weight': 1.2569062026511173}. Best is trial 71 with value: 0.6297470971732274.\n",
      "[I 2023-07-05 16:42:46,307] Trial 81 finished with value: 0.6242647191027397 and parameters: {'max_depth': 7, 'learning_rate': 0.0048427551583460566, 'subsample': 0.6024898812482231, 'colsample_bytree': 0.6172982669375922, 'lambda': 3.9266871420807906e-08, 'alpha': 5.605171908764595e-08, 'scale_pos_weight': 1.1034600613170422}. Best is trial 71 with value: 0.6297470971732274.\n",
      "[I 2023-07-05 16:42:47,661] Trial 82 finished with value: 0.6260418352265985 and parameters: {'max_depth': 7, 'learning_rate': 0.005128290548447995, 'subsample': 0.616974687815635, 'colsample_bytree': 0.5903886874666849, 'lambda': 1.1482569088427504e-08, 'alpha': 2.0321283591476548e-07, 'scale_pos_weight': 1.3343145754234018}. Best is trial 71 with value: 0.6297470971732274.\n",
      "[I 2023-07-05 16:42:48,756] Trial 83 finished with value: 0.6272964605111276 and parameters: {'max_depth': 7, 'learning_rate': 0.005184512132955694, 'subsample': 0.6164871573366152, 'colsample_bytree': 0.5866131369878818, 'lambda': 1.017612183202797e-08, 'alpha': 2.437954296432746e-08, 'scale_pos_weight': 1.326583128257974}. Best is trial 71 with value: 0.6297470971732274.\n",
      "[I 2023-07-05 16:42:49,877] Trial 84 finished with value: 0.6210524612447006 and parameters: {'max_depth': 7, 'learning_rate': 0.00413184552871011, 'subsample': 0.5742978311319525, 'colsample_bytree': 0.5735883099214063, 'lambda': 1.442013975398777e-08, 'alpha': 1.2629576737954471e-08, 'scale_pos_weight': 1.2640707329255136}. Best is trial 71 with value: 0.6297470971732274.\n",
      "[I 2023-07-05 16:42:51,112] Trial 85 finished with value: 0.6289279408538933 and parameters: {'max_depth': 8, 'learning_rate': 0.0053494567622734855, 'subsample': 0.6093824921306783, 'colsample_bytree': 0.5659325308229565, 'lambda': 3.886781449424532e-08, 'alpha': 2.4583783395981624e-08, 'scale_pos_weight': 1.1828991856496904}. Best is trial 71 with value: 0.6297470971732274.\n",
      "[I 2023-07-05 16:42:52,553] Trial 86 finished with value: 0.6212218302641941 and parameters: {'max_depth': 8, 'learning_rate': 0.005293904961340329, 'subsample': 0.5576676276517752, 'colsample_bytree': 0.5173350496623965, 'lambda': 4.2998918256539744e-08, 'alpha': 2.7048372074148382e-08, 'scale_pos_weight': 1.1816197011333323}. Best is trial 71 with value: 0.6297470971732274.\n",
      "[I 2023-07-05 16:42:53,707] Trial 87 finished with value: 0.6199085910727065 and parameters: {'max_depth': 7, 'learning_rate': 0.004901650505443357, 'subsample': 0.5921967097264297, 'colsample_bytree': 0.5569073934324108, 'lambda': 1.9283233197296892e-08, 'alpha': 2.0436622147032593e-08, 'scale_pos_weight': 1.3591448636908223}. Best is trial 71 with value: 0.6297470971732274.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:42:55,026] Trial 88 finished with value: 0.6258771409358808 and parameters: {'max_depth': 8, 'learning_rate': 0.0044803370796311125, 'subsample': 0.6127885985869358, 'colsample_bytree': 0.5754793545977726, 'lambda': 1.0191992752977592e-08, 'alpha': 4.112816329890419e-08, 'scale_pos_weight': 1.0799816438727838}. Best is trial 71 with value: 0.6297470971732274.\n",
      "[I 2023-07-05 16:42:56,026] Trial 89 finished with value: 0.6212840401163647 and parameters: {'max_depth': 7, 'learning_rate': 0.005582557920802096, 'subsample': 0.5740570284577253, 'colsample_bytree': 0.5420257659525688, 'lambda': 6.926283061161393e-08, 'alpha': 1.4278491324847202e-08, 'scale_pos_weight': 1.0295728992041686}. Best is trial 71 with value: 0.6297470971732274.\n",
      "[I 2023-07-05 16:42:57,187] Trial 90 finished with value: 0.6237069880003309 and parameters: {'max_depth': 7, 'learning_rate': 0.004832258012768027, 'subsample': 0.5908399478299476, 'colsample_bytree': 0.6200977155012153, 'lambda': 3.541431559377676e-08, 'alpha': 2.5031269078817346e-08, 'scale_pos_weight': 1.311743368699147}. Best is trial 71 with value: 0.6297470971732274.\n",
      "[I 2023-07-05 16:42:58,385] Trial 91 finished with value: 0.6258541268865228 and parameters: {'max_depth': 8, 'learning_rate': 0.005201597635330254, 'subsample': 0.6201313689792696, 'colsample_bytree': 0.5854737898266756, 'lambda': 1.521760235924851e-08, 'alpha': 7.870719193901592e-08, 'scale_pos_weight': 1.2208257298721592}. Best is trial 71 with value: 0.6297470971732274.\n",
      "[I 2023-07-05 16:42:59,926] Trial 92 finished with value: 0.6267487980553128 and parameters: {'max_depth': 8, 'learning_rate': 0.005654527007625774, 'subsample': 0.6071461882226065, 'colsample_bytree': 0.5633820852900652, 'lambda': 5.1277838347147095e-08, 'alpha': 1.0123860740710305e-08, 'scale_pos_weight': 1.167430295546789}. Best is trial 71 with value: 0.6297470971732274.\n",
      "[I 2023-07-05 16:43:01,416] Trial 93 finished with value: 0.6268555976281145 and parameters: {'max_depth': 8, 'learning_rate': 0.005573912671631359, 'subsample': 0.6121711871487185, 'colsample_bytree': 0.566388220170673, 'lambda': 6.069312151842343e-08, 'alpha': 1.0184278383960218e-08, 'scale_pos_weight': 1.1666806395510276}. Best is trial 71 with value: 0.6297470971732274.\n",
      "[I 2023-07-05 16:43:02,891] Trial 94 finished with value: 0.6232150626953048 and parameters: {'max_depth': 8, 'learning_rate': 0.005575378214046678, 'subsample': 0.6050957525410531, 'colsample_bytree': 0.566700231317525, 'lambda': 4.835983853811665e-08, 'alpha': 1.2103343431356686e-08, 'scale_pos_weight': 1.1598061483356314}. Best is trial 71 with value: 0.6297470971732274.\n",
      "[I 2023-07-05 16:43:04,145] Trial 95 finished with value: 0.6217320948898022 and parameters: {'max_depth': 8, 'learning_rate': 0.005259551165797468, 'subsample': 0.5566516919456126, 'colsample_bytree': 0.5484582927925218, 'lambda': 2.061187254147091e-08, 'alpha': 1.0243126000900037e-08, 'scale_pos_weight': 1.1211434767540873}. Best is trial 71 with value: 0.6297470971732274.\n",
      "[I 2023-07-05 16:43:05,311] Trial 96 finished with value: 0.6281979639758208 and parameters: {'max_depth': 8, 'learning_rate': 0.004702520264754515, 'subsample': 0.6095375156853291, 'colsample_bytree': 0.5302549356498598, 'lambda': 8.40874688048263e-08, 'alpha': 3.771639591029059e-08, 'scale_pos_weight': 1.1701365512193884}. Best is trial 71 with value: 0.6297470971732274.\n",
      "[I 2023-07-05 16:43:05,661] Trial 97 finished with value: 0.6142629570895858 and parameters: {'max_depth': 2, 'learning_rate': 0.004659172618041442, 'subsample': 0.5926436697138037, 'colsample_bytree': 0.5157195075347693, 'lambda': 8.71314089649756e-08, 'alpha': 4.099294846789376e-08, 'scale_pos_weight': 1.081445661359653}. Best is trial 71 with value: 0.6297470971732274.\n",
      "[I 2023-07-05 16:43:06,776] Trial 98 finished with value: 0.6176129396492516 and parameters: {'max_depth': 8, 'learning_rate': 0.006127521428523629, 'subsample': 0.5803660355288761, 'colsample_bytree': 0.5310282382283608, 'lambda': 3.239098872065017e-08, 'alpha': 4.805782153844921e-08, 'scale_pos_weight': 1.2498822767362923}. Best is trial 71 with value: 0.6297470971732274.\n",
      "[I 2023-07-05 16:43:07,761] Trial 99 finished with value: 0.6185500429715454 and parameters: {'max_depth': 7, 'learning_rate': 0.004335975668005385, 'subsample': 0.5666749767380175, 'colsample_bytree': 0.5353854698307633, 'lambda': 2.8611523867929626e-08, 'alpha': 2.2328801528574093e-08, 'scale_pos_weight': 1.0314326309178377}. Best is trial 71 with value: 0.6297470971732274.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=75)\n",
    "best_params = study.best_params\n",
    "best_score = study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8e25a787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy score is: 0.8009267059814659\n",
      "Test Accuracy score is: 0.8032345013477089\n",
      "ROCAUC score is: 0.6297470971732274\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.00      0.01       583\n",
      "           1       0.80      1.00      0.89      2385\n",
      "\n",
      "    accuracy                           0.80      2968\n",
      "   macro avg       0.60      0.50      0.45      2968\n",
      "weighted avg       0.72      0.80      0.72      2968\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(**best_params, random_state=5)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "evaluate_model(xgb_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaafeb27",
   "metadata": {},
   "source": [
    "# Deep Learning (Neural Network) - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2265a4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BertzCT</th>\n",
       "      <th>ExactMolWt</th>\n",
       "      <th>HeavyAtomMolWt</th>\n",
       "      <th>Chi1</th>\n",
       "      <th>Chi1n</th>\n",
       "      <th>Chi1v</th>\n",
       "      <th>Chi2n</th>\n",
       "      <th>Chi2v</th>\n",
       "      <th>Chi3v</th>\n",
       "      <th>Chi4n</th>\n",
       "      <th>...</th>\n",
       "      <th>PEOE_VSA14</th>\n",
       "      <th>PEOE_VSA6</th>\n",
       "      <th>PEOE_VSA7</th>\n",
       "      <th>PEOE_VSA8</th>\n",
       "      <th>SMR_VSA10</th>\n",
       "      <th>SMR_VSA5</th>\n",
       "      <th>SlogP_VSA3</th>\n",
       "      <th>VSA_EState9</th>\n",
       "      <th>fr_COO</th>\n",
       "      <th>fr_COO2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6788</th>\n",
       "      <td>-0.479488</td>\n",
       "      <td>-0.631739</td>\n",
       "      <td>-0.633457</td>\n",
       "      <td>4.825699</td>\n",
       "      <td>2.793756</td>\n",
       "      <td>2.793756</td>\n",
       "      <td>1.932542</td>\n",
       "      <td>1.932542</td>\n",
       "      <td>1.438134</td>\n",
       "      <td>0.895230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.393687</td>\n",
       "      <td>5.687386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>-0.633683</td>\n",
       "      <td>-0.596321</td>\n",
       "      <td>-0.577001</td>\n",
       "      <td>5.947265</td>\n",
       "      <td>3.675670</td>\n",
       "      <td>3.675670</td>\n",
       "      <td>2.757262</td>\n",
       "      <td>2.757262</td>\n",
       "      <td>1.708684</td>\n",
       "      <td>0.955337</td>\n",
       "      <td>...</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.938611</td>\n",
       "      <td>25.304306</td>\n",
       "      <td>9.531400</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3551</th>\n",
       "      <td>-0.513457</td>\n",
       "      <td>-0.613643</td>\n",
       "      <td>-0.651981</td>\n",
       "      <td>5.036581</td>\n",
       "      <td>3.414884</td>\n",
       "      <td>3.414884</td>\n",
       "      <td>2.703542</td>\n",
       "      <td>2.703542</td>\n",
       "      <td>1.827002</td>\n",
       "      <td>1.029291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.15204</td>\n",
       "      <td>17.696186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.103966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8301</th>\n",
       "      <td>-0.635423</td>\n",
       "      <td>-0.538873</td>\n",
       "      <td>-0.525580</td>\n",
       "      <td>5.092224</td>\n",
       "      <td>2.925131</td>\n",
       "      <td>2.925131</td>\n",
       "      <td>2.116586</td>\n",
       "      <td>2.116586</td>\n",
       "      <td>1.611120</td>\n",
       "      <td>0.757462</td>\n",
       "      <td>...</td>\n",
       "      <td>12.062229</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.907600</td>\n",
       "      <td>12.462662</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>-0.795743</td>\n",
       "      <td>-0.835799</td>\n",
       "      <td>-0.821568</td>\n",
       "      <td>2.642734</td>\n",
       "      <td>1.049739</td>\n",
       "      <td>1.049739</td>\n",
       "      <td>0.504904</td>\n",
       "      <td>0.504904</td>\n",
       "      <td>0.142577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.752550</td>\n",
       "      <td>6.544756</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>29.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       BertzCT  ExactMolWt  HeavyAtomMolWt      Chi1     Chi1n     Chi1v  \\\n",
       "6788 -0.479488   -0.631739       -0.633457  4.825699  2.793756  2.793756   \n",
       "1962 -0.633683   -0.596321       -0.577001  5.947265  3.675670  3.675670   \n",
       "3551 -0.513457   -0.613643       -0.651981  5.036581  3.414884  3.414884   \n",
       "8301 -0.635423   -0.538873       -0.525580  5.092224  2.925131  2.925131   \n",
       "281  -0.795743   -0.835799       -0.821568  2.642734  1.049739  1.049739   \n",
       "\n",
       "         Chi2n     Chi2v     Chi3v     Chi4n  ...  PEOE_VSA14  PEOE_VSA6  \\\n",
       "6788  1.932542  1.932542  1.438134  0.895230  ...    0.000000    0.00000   \n",
       "1962  2.757262  2.757262  1.708684  0.955337  ...    5.969305    0.00000   \n",
       "3551  2.703542  2.703542  1.827002  1.029291  ...    0.000000   12.15204   \n",
       "8301  2.116586  2.116586  1.611120  0.757462  ...   12.062229    0.00000   \n",
       "281   0.504904  0.504904  0.142577  0.000000  ...    5.969305    0.00000   \n",
       "\n",
       "      PEOE_VSA7  PEOE_VSA8  SMR_VSA10   SMR_VSA5  SlogP_VSA3  VSA_EState9  \\\n",
       "6788   0.000000  12.393687   5.687386   0.000000    0.000000    30.000000   \n",
       "1962   0.000000   0.000000  11.938611  25.304306    9.531400    47.000000   \n",
       "3551  17.696186   0.000000   0.000000   6.103966    0.000000    36.166667   \n",
       "8301   0.000000   0.000000  17.907600  12.462662    9.589074    39.500000   \n",
       "281    0.000000   0.000000  11.752550   6.544756    9.589074    29.666667   \n",
       "\n",
       "      fr_COO  fr_COO2  \n",
       "6788       0        0  \n",
       "1962       1        1  \n",
       "3551       0        0  \n",
       "8301       1        1  \n",
       "281        1        1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_data.drop(['id','EC1','EC2', 'EC3', 'EC4', 'EC5', 'EC6'], axis=1)\n",
    "y = train_data['EC1']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y, test_size=.2, random_state=2)\n",
    "cols_not = [i for i in X_train.columns if i not in high_value_cols]\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_sc=pd.DataFrame(scaler.fit_transform(X_train[high_value_cols]),index=X_train.index,columns=high_value_cols)\n",
    "val_sc=pd.DataFrame(scaler.fit_transform(X_val[high_value_cols]),index=X_val.index,columns=high_value_cols)\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# X_train=pd.DataFrame(scaler.fit_transform(X_train),index=X_train.index,columns=X_train.columns)\n",
    "# X_val=pd.DataFrame(scaler.fit_transform(X_val),index=X_val.index,columns=X_val.columns)\n",
    "\n",
    "X_train = pd.concat([train_sc, X_train[cols_not]], axis=1)\n",
    "X_val = pd.concat([val_sc, X_val[cols_not]], axis=1)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9568cab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "3009293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32).reshape(-1, 1)\n",
    "y_val = torch.tensor(y_val.values, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2b941b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(len(hidden_sizes) - 1):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))\n",
    "        self.output = nn.Linear(hidden_sizes[-1], num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = torch.relu(hidden_layer(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "16448fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(params):\n",
    "    # Create an instance of the MLP\n",
    "    model = MLP(**params)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    evaluate_MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "75e13431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_MLP():\n",
    "    # Evaluation on the validation set\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_outputs = model(X_val)\n",
    "        probs = torch.sigmoid(val_outputs)\n",
    "        pos_probs = probs[:, 0]\n",
    "#         val_predictions = torch.argmax(val_outputs, dim=1)\n",
    "#         val_probs = torch.softmax(val_outputs, dim=1)[:, 1].numpy()\n",
    "        score = roc_auc_score(y_val, pos_probs)\n",
    "        acc = accuracy_score(y_val, val_outputs)\n",
    "        train_acc = accuracy_score(y_val, model(X_train))\n",
    "        print(\"ROC score is \",score)\n",
    "        print(\"Train score is \",score)\n",
    "        print(\"Val accuracy score is \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "3b106d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define the hyperparameters to optimize\n",
    "    input_size = 31\n",
    "    num_hidden_layers = 3\n",
    "    hidden_sizes = []\n",
    "    for i in range(num_hidden_layers):\n",
    "        hidden_sizes.append(trial.suggest_int(f\"hidden_size_{i}\", 4, 10))\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\",0.0001, 0.01)\n",
    "    num_classes = 1\n",
    "#     hidden_sizes.append(9)\n",
    "#     hidden_sizes.append(6)\n",
    "\n",
    "    # Create an instance of the MLP\n",
    "    model = MLP(input_size, hidden_sizes, num_classes)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation on the validation set\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_outputs = model(X_val)\n",
    "        probs = torch.sigmoid(val_outputs)\n",
    "        pos_probs = probs[:, 0]\n",
    "#         val_predictions = torch.argmax(val_outputs, dim=1)\n",
    "#         val_probs = torch.softmax(val_outputs, dim=1)[:, 1].numpy()\n",
    "#         score = roc_auc_score(y_val, pos_probs)\n",
    "        pred_labels = (val_outputs >= 0.5).float()\n",
    "        score = (pred_labels == y_val).sum().item() / len(y_val)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270659b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:50:37,845] A new study created in memory with name: no-name-987e985b-139e-4705-9c25-3566a7ee69f1\n",
      "[I 2023-07-05 16:50:38,199] Trial 0 finished with value: 0.7075471698113207 and parameters: {'hidden_size_0': 8, 'hidden_size_1': 10, 'hidden_size_2': 6, 'learning_rate': 0.009024620765141036}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:38,523] Trial 1 finished with value: 0.6721698113207547 and parameters: {'hidden_size_0': 10, 'hidden_size_1': 4, 'hidden_size_2': 9, 'learning_rate': 0.0011190273815927384}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:38,869] Trial 2 finished with value: 0.6960916442048517 and parameters: {'hidden_size_0': 8, 'hidden_size_1': 10, 'hidden_size_2': 9, 'learning_rate': 0.001607048139655296}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:39,216] Trial 3 finished with value: 0.6721698113207547 and parameters: {'hidden_size_0': 9, 'hidden_size_1': 7, 'hidden_size_2': 5, 'learning_rate': 0.0031952144729771137}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:39,533] Trial 4 finished with value: 0.7014824797843666 and parameters: {'hidden_size_0': 8, 'hidden_size_1': 10, 'hidden_size_2': 6, 'learning_rate': 0.009104849258036247}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:39,876] Trial 5 finished with value: 0.6721698113207547 and parameters: {'hidden_size_0': 10, 'hidden_size_1': 5, 'hidden_size_2': 5, 'learning_rate': 0.0003210361808643579}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:40,192] Trial 6 finished with value: 0.6701482479784366 and parameters: {'hidden_size_0': 9, 'hidden_size_1': 8, 'hidden_size_2': 6, 'learning_rate': 0.003894952046011236}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:40,508] Trial 7 finished with value: 0.6721698113207547 and parameters: {'hidden_size_0': 7, 'hidden_size_1': 6, 'hidden_size_2': 10, 'learning_rate': 0.00040791772764489393}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:40,869] Trial 8 finished with value: 0.682277628032345 and parameters: {'hidden_size_0': 10, 'hidden_size_1': 5, 'hidden_size_2': 7, 'learning_rate': 0.007908258212268354}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:41,258] Trial 9 finished with value: 0.6735175202156334 and parameters: {'hidden_size_0': 5, 'hidden_size_1': 6, 'hidden_size_2': 7, 'learning_rate': 0.0013791038401485933}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:41,641] Trial 10 finished with value: 0.6714959568733153 and parameters: {'hidden_size_0': 5, 'hidden_size_1': 9, 'hidden_size_2': 4, 'learning_rate': 0.00010601681693389738}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:42,153] Trial 11 finished with value: 0.7018194070080862 and parameters: {'hidden_size_0': 7, 'hidden_size_1': 10, 'hidden_size_2': 6, 'learning_rate': 0.009761163223610385}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:42,533] Trial 12 finished with value: 0.6907008086253369 and parameters: {'hidden_size_0': 6, 'hidden_size_1': 9, 'hidden_size_2': 8, 'learning_rate': 0.00993102132676423}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:42,890] Trial 13 finished with value: 0.6721698113207547 and parameters: {'hidden_size_0': 7, 'hidden_size_1': 9, 'hidden_size_2': 5, 'learning_rate': 0.004469963633752021}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:43,261] Trial 14 finished with value: 0.6839622641509434 and parameters: {'hidden_size_0': 6, 'hidden_size_1': 10, 'hidden_size_2': 6, 'learning_rate': 0.005197897314211337}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:43,590] Trial 15 finished with value: 0.6721698113207547 and parameters: {'hidden_size_0': 4, 'hidden_size_1': 8, 'hidden_size_2': 4, 'learning_rate': 0.0026155219917874018}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:43,941] Trial 16 finished with value: 0.7035040431266847 and parameters: {'hidden_size_0': 8, 'hidden_size_1': 8, 'hidden_size_2': 8, 'learning_rate': 0.0060780121882721685}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:44,348] Trial 17 finished with value: 0.6721698113207547 and parameters: {'hidden_size_0': 8, 'hidden_size_1': 8, 'hidden_size_2': 8, 'learning_rate': 0.005778954929445784}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:44,812] Trial 18 finished with value: 0.6971024258760108 and parameters: {'hidden_size_0': 9, 'hidden_size_1': 7, 'hidden_size_2': 8, 'learning_rate': 0.0020236524582301373}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:45,213] Trial 19 finished with value: 0.6913746630727763 and parameters: {'hidden_size_0': 8, 'hidden_size_1': 9, 'hidden_size_2': 7, 'learning_rate': 0.003547288201405338}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:45,625] Trial 20 finished with value: 0.7024932614555256 and parameters: {'hidden_size_0': 6, 'hidden_size_1': 7, 'hidden_size_2': 10, 'learning_rate': 0.005740097538398149}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:46,096] Trial 21 finished with value: 0.6997978436657682 and parameters: {'hidden_size_0': 6, 'hidden_size_1': 7, 'hidden_size_2': 10, 'learning_rate': 0.005025548143558231}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:46,485] Trial 22 finished with value: 0.7068733153638814 and parameters: {'hidden_size_0': 7, 'hidden_size_1': 8, 'hidden_size_2': 9, 'learning_rate': 0.005859285011602366}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:46,885] Trial 23 finished with value: 0.703167115902965 and parameters: {'hidden_size_0': 7, 'hidden_size_1': 8, 'hidden_size_2': 9, 'learning_rate': 0.002229426333881558}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:47,251] Trial 24 finished with value: 0.6974393530997305 and parameters: {'hidden_size_0': 8, 'hidden_size_1': 9, 'hidden_size_2': 8, 'learning_rate': 0.00686191765984547}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:47,639] Trial 25 finished with value: 0.6997978436657682 and parameters: {'hidden_size_0': 9, 'hidden_size_1': 8, 'hidden_size_2': 9, 'learning_rate': 0.006878195169988105}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:47,963] Trial 26 finished with value: 0.6920485175202157 and parameters: {'hidden_size_0': 7, 'hidden_size_1': 6, 'hidden_size_2': 8, 'learning_rate': 0.004070335701214645}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:48,336] Trial 27 finished with value: 0.6896900269541779 and parameters: {'hidden_size_0': 8, 'hidden_size_1': 9, 'hidden_size_2': 7, 'learning_rate': 0.002754901289890348}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:48,715] Trial 28 finished with value: 0.7035040431266847 and parameters: {'hidden_size_0': 9, 'hidden_size_1': 8, 'hidden_size_2': 9, 'learning_rate': 0.0074715346110566985}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:49,042] Trial 29 finished with value: 0.694743935309973 and parameters: {'hidden_size_0': 7, 'hidden_size_1': 4, 'hidden_size_2': 7, 'learning_rate': 0.003250396125758473}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:49,389] Trial 30 finished with value: 0.6997978436657682 and parameters: {'hidden_size_0': 10, 'hidden_size_1': 7, 'hidden_size_2': 8, 'learning_rate': 0.006069514092324422}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:49,771] Trial 31 finished with value: 0.7072102425876011 and parameters: {'hidden_size_0': 9, 'hidden_size_1': 8, 'hidden_size_2': 9, 'learning_rate': 0.007831498004861721}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:50,212] Trial 32 finished with value: 0.7008086253369272 and parameters: {'hidden_size_0': 8, 'hidden_size_1': 8, 'hidden_size_2': 9, 'learning_rate': 0.008051131451452037}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:50,591] Trial 33 finished with value: 0.6721698113207547 and parameters: {'hidden_size_0': 9, 'hidden_size_1': 10, 'hidden_size_2': 10, 'learning_rate': 0.004562989269137924}. Best is trial 0 with value: 0.7075471698113207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-05 16:50:50,951] Trial 34 finished with value: 0.6967654986522911 and parameters: {'hidden_size_0': 8, 'hidden_size_1': 9, 'hidden_size_2': 9, 'learning_rate': 0.009322489566327223}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:51,312] Trial 35 finished with value: 0.7024932614555256 and parameters: {'hidden_size_0': 9, 'hidden_size_1': 7, 'hidden_size_2': 9, 'learning_rate': 0.00638109822371926}. Best is trial 0 with value: 0.7075471698113207.\n",
      "[I 2023-07-05 16:50:51,655] Trial 36 finished with value: 0.6933962264150944 and parameters: {'hidden_size_0': 8, 'hidden_size_1': 10, 'hidden_size_2': 8, 'learning_rate': 0.0033141171336116197}. Best is trial 0 with value: 0.7075471698113207.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "best_params = study.best_params\n",
    "best_score = study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ed1d3333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best parameters are:  {'hidden_size_0': 8, 'hidden_size_1': 6, 'hidden_size_2': 7, 'learning_rate': 0.004896156970946585}\n",
      "The best score is:  0.7099056603773585\n"
     ]
    }
   ],
   "source": [
    "print('the best parameters are: ', best_params)\n",
    "print('The best score is: ', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "02eefef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_sizes': [8, 9], 'learning_rate': 0.00972285452944221}"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {}\n",
    "params['hidden_sizes'] = []\n",
    "# params['learning_rate'] = 0\n",
    "for k,v in best_params.items():\n",
    "    if k=='learning_rate':\n",
    "        params['learning_rate'] = v\n",
    "        break\n",
    "    params['hidden_sizes'].append(v)\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cac8c0f",
   "metadata": {},
   "source": [
    "Past parameters:\n",
    "- the best parameters are:  {'hidden_size_0': 11, 'hidden_size_1': 9, 'hidden_size_2': 6, 'learning_rate': 0.009705484202909563}|The best score is:  0.7008737156354401\n",
    "- the best parameters are:  {'hidden_size_0': 10, 'hidden_size_1': 7, 'hidden_size_2': 6, 'learning_rate': 0.005500430897896138}|The best score is:  0.698981523696188"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7f86d4",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2b3b7b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>BertzCT</th>\n",
       "      <th>Chi1</th>\n",
       "      <th>Chi1n</th>\n",
       "      <th>Chi1v</th>\n",
       "      <th>Chi2n</th>\n",
       "      <th>Chi2v</th>\n",
       "      <th>Chi3v</th>\n",
       "      <th>Chi4n</th>\n",
       "      <th>EState_VSA1</th>\n",
       "      <th>...</th>\n",
       "      <th>PEOE_VSA14</th>\n",
       "      <th>PEOE_VSA6</th>\n",
       "      <th>PEOE_VSA7</th>\n",
       "      <th>PEOE_VSA8</th>\n",
       "      <th>SMR_VSA10</th>\n",
       "      <th>SMR_VSA5</th>\n",
       "      <th>SlogP_VSA3</th>\n",
       "      <th>VSA_EState9</th>\n",
       "      <th>fr_COO</th>\n",
       "      <th>fr_COO2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14838</td>\n",
       "      <td>344.632371</td>\n",
       "      <td>7.283603</td>\n",
       "      <td>4.473966</td>\n",
       "      <td>5.834958</td>\n",
       "      <td>3.412257</td>\n",
       "      <td>4.651530</td>\n",
       "      <td>2.096558</td>\n",
       "      <td>1.116433</td>\n",
       "      <td>49.458581</td>\n",
       "      <td>...</td>\n",
       "      <td>13.512441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.809272</td>\n",
       "      <td>24.539800</td>\n",
       "      <td>4.794537</td>\n",
       "      <td>47.304082</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14839</td>\n",
       "      <td>1432.410201</td>\n",
       "      <td>10.663869</td>\n",
       "      <td>7.079026</td>\n",
       "      <td>8.065215</td>\n",
       "      <td>5.297097</td>\n",
       "      <td>5.297097</td>\n",
       "      <td>3.924155</td>\n",
       "      <td>2.569694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.947374</td>\n",
       "      <td>98.323987</td>\n",
       "      <td>9.606882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.378235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14840</td>\n",
       "      <td>83.352608</td>\n",
       "      <td>3.931852</td>\n",
       "      <td>1.774215</td>\n",
       "      <td>1.774215</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>0.467830</td>\n",
       "      <td>0.170838</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>...</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.420822</td>\n",
       "      <td>11.752550</td>\n",
       "      <td>13.344559</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>24.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14841</td>\n",
       "      <td>150.255712</td>\n",
       "      <td>5.912790</td>\n",
       "      <td>3.548812</td>\n",
       "      <td>3.548812</td>\n",
       "      <td>2.595128</td>\n",
       "      <td>2.595128</td>\n",
       "      <td>1.642813</td>\n",
       "      <td>0.694113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>59.935299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.744066</td>\n",
       "      <td>32.290168</td>\n",
       "      <td>4.794537</td>\n",
       "      <td>26.778866</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14842</td>\n",
       "      <td>1817.276351</td>\n",
       "      <td>24.910940</td>\n",
       "      <td>15.540529</td>\n",
       "      <td>20.047314</td>\n",
       "      <td>12.535886</td>\n",
       "      <td>17.730988</td>\n",
       "      <td>11.979618</td>\n",
       "      <td>4.431173</td>\n",
       "      <td>84.554972</td>\n",
       "      <td>...</td>\n",
       "      <td>23.468091</td>\n",
       "      <td>25.609359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.099000</td>\n",
       "      <td>69.141353</td>\n",
       "      <td>38.704130</td>\n",
       "      <td>50.697492</td>\n",
       "      <td>102.583333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9888</th>\n",
       "      <td>24726</td>\n",
       "      <td>246.422865</td>\n",
       "      <td>4.036581</td>\n",
       "      <td>2.816709</td>\n",
       "      <td>2.816709</td>\n",
       "      <td>1.875634</td>\n",
       "      <td>1.875634</td>\n",
       "      <td>1.235986</td>\n",
       "      <td>0.362743</td>\n",
       "      <td>24.146543</td>\n",
       "      <td>...</td>\n",
       "      <td>11.938611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.938611</td>\n",
       "      <td>12.207933</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9889</th>\n",
       "      <td>24727</td>\n",
       "      <td>591.069706</td>\n",
       "      <td>8.770857</td>\n",
       "      <td>5.682461</td>\n",
       "      <td>5.682461</td>\n",
       "      <td>4.050440</td>\n",
       "      <td>4.050440</td>\n",
       "      <td>2.167855</td>\n",
       "      <td>1.770579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.199101</td>\n",
       "      <td>37.107112</td>\n",
       "      <td>17.696186</td>\n",
       "      <td>10.969244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9890</th>\n",
       "      <td>24728</td>\n",
       "      <td>378.113435</td>\n",
       "      <td>6.310349</td>\n",
       "      <td>3.402334</td>\n",
       "      <td>4.317724</td>\n",
       "      <td>2.817428</td>\n",
       "      <td>4.071978</td>\n",
       "      <td>1.970236</td>\n",
       "      <td>1.165747</td>\n",
       "      <td>36.705949</td>\n",
       "      <td>...</td>\n",
       "      <td>7.822697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.822697</td>\n",
       "      <td>24.099010</td>\n",
       "      <td>4.736863</td>\n",
       "      <td>50.652870</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9891</th>\n",
       "      <td>24729</td>\n",
       "      <td>737.653518</td>\n",
       "      <td>9.949161</td>\n",
       "      <td>7.337949</td>\n",
       "      <td>7.337949</td>\n",
       "      <td>4.428511</td>\n",
       "      <td>5.948361</td>\n",
       "      <td>3.972459</td>\n",
       "      <td>2.160881</td>\n",
       "      <td>36.992053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.196844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.462662</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>50.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9892</th>\n",
       "      <td>24730</td>\n",
       "      <td>785.394062</td>\n",
       "      <td>12.170505</td>\n",
       "      <td>7.565385</td>\n",
       "      <td>9.651755</td>\n",
       "      <td>5.842572</td>\n",
       "      <td>8.229500</td>\n",
       "      <td>5.664696</td>\n",
       "      <td>2.587586</td>\n",
       "      <td>49.458581</td>\n",
       "      <td>...</td>\n",
       "      <td>7.822697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.872230</td>\n",
       "      <td>24.539800</td>\n",
       "      <td>13.825658</td>\n",
       "      <td>69.130957</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9893 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id      BertzCT       Chi1      Chi1n      Chi1v      Chi2n  \\\n",
       "0     14838   344.632371   7.283603   4.473966   5.834958   3.412257   \n",
       "1     14839  1432.410201  10.663869   7.079026   8.065215   5.297097   \n",
       "2     14840    83.352608   3.931852   1.774215   1.774215   1.073446   \n",
       "3     14841   150.255712   5.912790   3.548812   3.548812   2.595128   \n",
       "4     14842  1817.276351  24.910940  15.540529  20.047314  12.535886   \n",
       "...     ...          ...        ...        ...        ...        ...   \n",
       "9888  24726   246.422865   4.036581   2.816709   2.816709   1.875634   \n",
       "9889  24727   591.069706   8.770857   5.682461   5.682461   4.050440   \n",
       "9890  24728   378.113435   6.310349   3.402334   4.317724   2.817428   \n",
       "9891  24729   737.653518   9.949161   7.337949   7.337949   4.428511   \n",
       "9892  24730   785.394062  12.170505   7.565385   9.651755   5.842572   \n",
       "\n",
       "          Chi2v      Chi3v     Chi4n  EState_VSA1  ...  PEOE_VSA14  PEOE_VSA6  \\\n",
       "0      4.651530   2.096558  1.116433    49.458581  ...   13.512441   0.000000   \n",
       "1      5.297097   3.924155  2.569694     0.000000  ...    0.000000  34.947374   \n",
       "2      1.073446   0.467830  0.170838     5.969305  ...    5.969305   0.000000   \n",
       "3      2.595128   1.642813  0.694113     0.000000  ...   59.935299   0.000000   \n",
       "4     17.730988  11.979618  4.431173    84.554972  ...   23.468091  25.609359   \n",
       "...         ...        ...       ...          ...  ...         ...        ...   \n",
       "9888   1.875634   1.235986  0.362743    24.146543  ...   11.938611   0.000000   \n",
       "9889   4.050440   2.167855  1.770579     0.000000  ...    0.000000  18.199101   \n",
       "9890   4.071978   1.970236  1.165747    36.705949  ...    7.822697   0.000000   \n",
       "9891   5.948361   3.972459  2.160881    36.992053  ...    0.000000   0.000000   \n",
       "9892   8.229500   5.664696  2.587586    49.458581  ...    7.822697   0.000000   \n",
       "\n",
       "      PEOE_VSA7  PEOE_VSA8  SMR_VSA10   SMR_VSA5  SlogP_VSA3  VSA_EState9  \\\n",
       "0      0.000000   0.000000  26.809272  24.539800    4.794537    47.304082   \n",
       "1     98.323987   9.606882   0.000000  53.378235    0.000000    43.166667   \n",
       "2      0.000000   6.420822  11.752550  13.344559    9.589074    24.666667   \n",
       "3      0.000000   0.000000  17.744066  32.290168    4.794537    26.778866   \n",
       "4      0.000000  37.099000  69.141353  38.704130   50.697492   102.583333   \n",
       "...         ...        ...        ...        ...         ...          ...   \n",
       "9888   0.000000   0.000000  11.938611  12.207933    9.589074    30.000000   \n",
       "9889  37.107112  17.696186  10.969244   0.000000    0.000000    53.166667   \n",
       "9890   0.000000   0.000000   7.822697  24.099010    4.736863    50.652870   \n",
       "9891   0.000000   6.196844   0.000000  12.462662    9.589074    50.250000   \n",
       "9892   0.000000   0.000000  18.872230  24.539800   13.825658    69.130957   \n",
       "\n",
       "      fr_COO  fr_COO2  \n",
       "0          1        1  \n",
       "1          0        0  \n",
       "2          1        1  \n",
       "3          0        0  \n",
       "4          0        0  \n",
       "...      ...      ...  \n",
       "9888       2        2  \n",
       "9889       0        0  \n",
       "9890       0        0  \n",
       "9891       0        0  \n",
       "9892       0        0  \n",
       "\n",
       "[9893 rows x 32 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "401346f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'BertzCT', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3v',\n",
       "       'Chi4n', 'EState_VSA1', 'EState_VSA2', 'ExactMolWt', 'FpDensityMorgan1',\n",
       "       'FpDensityMorgan2', 'FpDensityMorgan3', 'HallKierAlpha',\n",
       "       'HeavyAtomMolWt', 'Kappa3', 'MaxAbsEStateIndex', 'MinEStateIndex',\n",
       "       'NumHeteroatoms', 'PEOE_VSA10', 'PEOE_VSA14', 'PEOE_VSA6', 'PEOE_VSA7',\n",
       "       'PEOE_VSA8', 'SMR_VSA10', 'SMR_VSA5', 'SlogP_VSA3', 'VSA_EState9',\n",
       "       'fr_COO', 'fr_COO2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "837b74cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'BertzCT', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3v',\n",
       "       'Chi4n', 'EState_VSA1', 'EState_VSA2', 'ExactMolWt', 'FpDensityMorgan1',\n",
       "       'FpDensityMorgan2', 'FpDensityMorgan3', 'HallKierAlpha',\n",
       "       'HeavyAtomMolWt', 'Kappa3', 'MaxAbsEStateIndex', 'MinEStateIndex',\n",
       "       'NumHeteroatoms', 'PEOE_VSA10', 'PEOE_VSA14', 'PEOE_VSA6', 'PEOE_VSA7',\n",
       "       'PEOE_VSA8', 'SMR_VSA10', 'SMR_VSA5', 'SlogP_VSA3', 'VSA_EState9',\n",
       "       'fr_COO', 'fr_COO2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns[:-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7d188b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7bdb294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ec1 = rfc.predict_proba(X_test)[0][:,1]\n",
    "ec2 = rfc.predict_proba(X_test)[1][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ba96da37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>EC2</th>\n",
       "      <th>EC1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14838</td>\n",
       "      <td>0.747632</td>\n",
       "      <td>0.424838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14839</td>\n",
       "      <td>0.707694</td>\n",
       "      <td>0.750496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14840</td>\n",
       "      <td>0.658456</td>\n",
       "      <td>0.753520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14841</td>\n",
       "      <td>0.712387</td>\n",
       "      <td>0.696345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14842</td>\n",
       "      <td>0.658913</td>\n",
       "      <td>0.768397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9888</th>\n",
       "      <td>24726</td>\n",
       "      <td>0.651815</td>\n",
       "      <td>0.615984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9889</th>\n",
       "      <td>24727</td>\n",
       "      <td>0.768612</td>\n",
       "      <td>0.738692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9890</th>\n",
       "      <td>24728</td>\n",
       "      <td>0.775342</td>\n",
       "      <td>0.387256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9891</th>\n",
       "      <td>24729</td>\n",
       "      <td>0.797754</td>\n",
       "      <td>0.383882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9892</th>\n",
       "      <td>24730</td>\n",
       "      <td>0.789840</td>\n",
       "      <td>0.355888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9893 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id       EC2       EC1\n",
       "0     14838  0.747632  0.424838\n",
       "1     14839  0.707694  0.750496\n",
       "2     14840  0.658456  0.753520\n",
       "3     14841  0.712387  0.696345\n",
       "4     14842  0.658913  0.768397\n",
       "...     ...       ...       ...\n",
       "9888  24726  0.651815  0.615984\n",
       "9889  24727  0.768612  0.738692\n",
       "9890  24728  0.775342  0.387256\n",
       "9891  24729  0.797754  0.383882\n",
       "9892  24730  0.789840  0.355888\n",
       "\n",
       "[9893 rows x 3 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_base = pd.DataFrame(zip(ec1, ec2) ,columns=['EC1', 'EC2'])\n",
    "rfc_base['id']=test_data['id']\n",
    "rfc_base = rfc_base[rfc_base.columns[::-1]]\n",
    "rfc_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "86794b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_base.to_csv('rfc_base.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "e6080600",
   "metadata": {},
   "outputs": [],
   "source": [
    "ec1 = model1.predict(X_test)\n",
    "ec2 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "c28ab704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>EC1</th>\n",
       "      <th>EC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14838</td>\n",
       "      <td>0.436758</td>\n",
       "      <td>0.768616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14839</td>\n",
       "      <td>0.811926</td>\n",
       "      <td>0.806311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14840</td>\n",
       "      <td>0.781455</td>\n",
       "      <td>0.745568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14841</td>\n",
       "      <td>0.712642</td>\n",
       "      <td>0.817455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14842</td>\n",
       "      <td>0.771032</td>\n",
       "      <td>0.795308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9888</th>\n",
       "      <td>24726</td>\n",
       "      <td>0.623808</td>\n",
       "      <td>0.745568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9889</th>\n",
       "      <td>24727</td>\n",
       "      <td>0.747591</td>\n",
       "      <td>0.821561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9890</th>\n",
       "      <td>24728</td>\n",
       "      <td>0.368690</td>\n",
       "      <td>0.840144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9891</th>\n",
       "      <td>24729</td>\n",
       "      <td>0.430987</td>\n",
       "      <td>0.845336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9892</th>\n",
       "      <td>24730</td>\n",
       "      <td>0.399012</td>\n",
       "      <td>0.835570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9893 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id       EC1       EC2\n",
       "0     14838  0.436758  0.768616\n",
       "1     14839  0.811926  0.806311\n",
       "2     14840  0.781455  0.745568\n",
       "3     14841  0.712642  0.817455\n",
       "4     14842  0.771032  0.795308\n",
       "...     ...       ...       ...\n",
       "9888  24726  0.623808  0.745568\n",
       "9889  24727  0.747591  0.821561\n",
       "9890  24728  0.368690  0.840144\n",
       "9891  24729  0.430987  0.845336\n",
       "9892  24730  0.399012  0.835570\n",
       "\n",
       "[9893 rows x 3 columns]"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_binary = pd.DataFrame(zip(ec1, ec2), columns=['EC1', 'EC2'])\n",
    "lgbm_binary['id'] = test_data['id']\n",
    "lgbm_binary = lgbm_binary[lgbm_binary.columns[-1:].to_list()+lgbm_binary.columns[:2].to_list()]\n",
    "lgbm_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "e7281275",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_binary.to_csv('lgbm_binary2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9f02ec",
   "metadata": {},
   "source": [
    "### Using EC1 as predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "a66c6b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hatEC1 = (model1.predict(X_test)>=0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "da4f7daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "87ac3e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>BertzCT</th>\n",
       "      <th>Chi1</th>\n",
       "      <th>Chi1n</th>\n",
       "      <th>Chi1v</th>\n",
       "      <th>Chi2n</th>\n",
       "      <th>Chi2v</th>\n",
       "      <th>Chi3v</th>\n",
       "      <th>Chi4n</th>\n",
       "      <th>EState_VSA1</th>\n",
       "      <th>...</th>\n",
       "      <th>PEOE_VSA6</th>\n",
       "      <th>PEOE_VSA7</th>\n",
       "      <th>PEOE_VSA8</th>\n",
       "      <th>SMR_VSA10</th>\n",
       "      <th>SMR_VSA5</th>\n",
       "      <th>SlogP_VSA3</th>\n",
       "      <th>VSA_EState9</th>\n",
       "      <th>fr_COO</th>\n",
       "      <th>fr_COO2</th>\n",
       "      <th>EC1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14838</td>\n",
       "      <td>344.632371</td>\n",
       "      <td>7.283603</td>\n",
       "      <td>4.473966</td>\n",
       "      <td>5.834958</td>\n",
       "      <td>3.412257</td>\n",
       "      <td>4.651530</td>\n",
       "      <td>2.096558</td>\n",
       "      <td>1.116433</td>\n",
       "      <td>49.458581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.809272</td>\n",
       "      <td>24.539800</td>\n",
       "      <td>4.794537</td>\n",
       "      <td>47.304082</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14839</td>\n",
       "      <td>1432.410201</td>\n",
       "      <td>10.663869</td>\n",
       "      <td>7.079026</td>\n",
       "      <td>8.065215</td>\n",
       "      <td>5.297097</td>\n",
       "      <td>5.297097</td>\n",
       "      <td>3.924155</td>\n",
       "      <td>2.569694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>34.947374</td>\n",
       "      <td>98.323987</td>\n",
       "      <td>9.606882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.378235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14840</td>\n",
       "      <td>83.352608</td>\n",
       "      <td>3.931852</td>\n",
       "      <td>1.774215</td>\n",
       "      <td>1.774215</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>0.467830</td>\n",
       "      <td>0.170838</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.420822</td>\n",
       "      <td>11.752550</td>\n",
       "      <td>13.344559</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>24.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14841</td>\n",
       "      <td>150.255712</td>\n",
       "      <td>5.912790</td>\n",
       "      <td>3.548812</td>\n",
       "      <td>3.548812</td>\n",
       "      <td>2.595128</td>\n",
       "      <td>2.595128</td>\n",
       "      <td>1.642813</td>\n",
       "      <td>0.694113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.744066</td>\n",
       "      <td>32.290168</td>\n",
       "      <td>4.794537</td>\n",
       "      <td>26.778866</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14842</td>\n",
       "      <td>1817.276351</td>\n",
       "      <td>24.910940</td>\n",
       "      <td>15.540529</td>\n",
       "      <td>20.047314</td>\n",
       "      <td>12.535886</td>\n",
       "      <td>17.730988</td>\n",
       "      <td>11.979618</td>\n",
       "      <td>4.431173</td>\n",
       "      <td>84.554972</td>\n",
       "      <td>...</td>\n",
       "      <td>25.609359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.099000</td>\n",
       "      <td>69.141353</td>\n",
       "      <td>38.704130</td>\n",
       "      <td>50.697492</td>\n",
       "      <td>102.583333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9888</th>\n",
       "      <td>24726</td>\n",
       "      <td>246.422865</td>\n",
       "      <td>4.036581</td>\n",
       "      <td>2.816709</td>\n",
       "      <td>2.816709</td>\n",
       "      <td>1.875634</td>\n",
       "      <td>1.875634</td>\n",
       "      <td>1.235986</td>\n",
       "      <td>0.362743</td>\n",
       "      <td>24.146543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.938611</td>\n",
       "      <td>12.207933</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9889</th>\n",
       "      <td>24727</td>\n",
       "      <td>591.069706</td>\n",
       "      <td>8.770857</td>\n",
       "      <td>5.682461</td>\n",
       "      <td>5.682461</td>\n",
       "      <td>4.050440</td>\n",
       "      <td>4.050440</td>\n",
       "      <td>2.167855</td>\n",
       "      <td>1.770579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.199101</td>\n",
       "      <td>37.107112</td>\n",
       "      <td>17.696186</td>\n",
       "      <td>10.969244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9890</th>\n",
       "      <td>24728</td>\n",
       "      <td>378.113435</td>\n",
       "      <td>6.310349</td>\n",
       "      <td>3.402334</td>\n",
       "      <td>4.317724</td>\n",
       "      <td>2.817428</td>\n",
       "      <td>4.071978</td>\n",
       "      <td>1.970236</td>\n",
       "      <td>1.165747</td>\n",
       "      <td>36.705949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.822697</td>\n",
       "      <td>24.099010</td>\n",
       "      <td>4.736863</td>\n",
       "      <td>50.652870</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9891</th>\n",
       "      <td>24729</td>\n",
       "      <td>737.653518</td>\n",
       "      <td>9.949161</td>\n",
       "      <td>7.337949</td>\n",
       "      <td>7.337949</td>\n",
       "      <td>4.428511</td>\n",
       "      <td>5.948361</td>\n",
       "      <td>3.972459</td>\n",
       "      <td>2.160881</td>\n",
       "      <td>36.992053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.196844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.462662</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>50.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9892</th>\n",
       "      <td>24730</td>\n",
       "      <td>785.394062</td>\n",
       "      <td>12.170505</td>\n",
       "      <td>7.565385</td>\n",
       "      <td>9.651755</td>\n",
       "      <td>5.842572</td>\n",
       "      <td>8.229500</td>\n",
       "      <td>5.664696</td>\n",
       "      <td>2.587586</td>\n",
       "      <td>49.458581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.872230</td>\n",
       "      <td>24.539800</td>\n",
       "      <td>13.825658</td>\n",
       "      <td>69.130957</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9893 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id      BertzCT       Chi1      Chi1n      Chi1v      Chi2n  \\\n",
       "0     14838   344.632371   7.283603   4.473966   5.834958   3.412257   \n",
       "1     14839  1432.410201  10.663869   7.079026   8.065215   5.297097   \n",
       "2     14840    83.352608   3.931852   1.774215   1.774215   1.073446   \n",
       "3     14841   150.255712   5.912790   3.548812   3.548812   2.595128   \n",
       "4     14842  1817.276351  24.910940  15.540529  20.047314  12.535886   \n",
       "...     ...          ...        ...        ...        ...        ...   \n",
       "9888  24726   246.422865   4.036581   2.816709   2.816709   1.875634   \n",
       "9889  24727   591.069706   8.770857   5.682461   5.682461   4.050440   \n",
       "9890  24728   378.113435   6.310349   3.402334   4.317724   2.817428   \n",
       "9891  24729   737.653518   9.949161   7.337949   7.337949   4.428511   \n",
       "9892  24730   785.394062  12.170505   7.565385   9.651755   5.842572   \n",
       "\n",
       "          Chi2v      Chi3v     Chi4n  EState_VSA1  ...  PEOE_VSA6  PEOE_VSA7  \\\n",
       "0      4.651530   2.096558  1.116433    49.458581  ...   0.000000   0.000000   \n",
       "1      5.297097   3.924155  2.569694     0.000000  ...  34.947374  98.323987   \n",
       "2      1.073446   0.467830  0.170838     5.969305  ...   0.000000   0.000000   \n",
       "3      2.595128   1.642813  0.694113     0.000000  ...   0.000000   0.000000   \n",
       "4     17.730988  11.979618  4.431173    84.554972  ...  25.609359   0.000000   \n",
       "...         ...        ...       ...          ...  ...        ...        ...   \n",
       "9888   1.875634   1.235986  0.362743    24.146543  ...   0.000000   0.000000   \n",
       "9889   4.050440   2.167855  1.770579     0.000000  ...  18.199101  37.107112   \n",
       "9890   4.071978   1.970236  1.165747    36.705949  ...   0.000000   0.000000   \n",
       "9891   5.948361   3.972459  2.160881    36.992053  ...   0.000000   0.000000   \n",
       "9892   8.229500   5.664696  2.587586    49.458581  ...   0.000000   0.000000   \n",
       "\n",
       "      PEOE_VSA8  SMR_VSA10   SMR_VSA5  SlogP_VSA3  VSA_EState9  fr_COO  \\\n",
       "0      0.000000  26.809272  24.539800    4.794537    47.304082       1   \n",
       "1      9.606882   0.000000  53.378235    0.000000    43.166667       0   \n",
       "2      6.420822  11.752550  13.344559    9.589074    24.666667       1   \n",
       "3      0.000000  17.744066  32.290168    4.794537    26.778866       0   \n",
       "4     37.099000  69.141353  38.704130   50.697492   102.583333       0   \n",
       "...         ...        ...        ...         ...          ...     ...   \n",
       "9888   0.000000  11.938611  12.207933    9.589074    30.000000       2   \n",
       "9889  17.696186  10.969244   0.000000    0.000000    53.166667       0   \n",
       "9890   0.000000   7.822697  24.099010    4.736863    50.652870       0   \n",
       "9891   6.196844   0.000000  12.462662    9.589074    50.250000       0   \n",
       "9892   0.000000  18.872230  24.539800   13.825658    69.130957       0   \n",
       "\n",
       "      fr_COO2  EC1  \n",
       "0           1    0  \n",
       "1           0    1  \n",
       "2           1    1  \n",
       "3           0    1  \n",
       "4           0    1  \n",
       "...       ...  ...  \n",
       "9888        2    1  \n",
       "9889        0    1  \n",
       "9890        0    0  \n",
       "9891        0    0  \n",
       "9892        0    0  \n",
       "\n",
       "[9893 rows x 33 columns]"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['EC1'] = y_hatEC1\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "a450758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "812d6ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hatEC2 = lgbm2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "44734ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>BertzCT</th>\n",
       "      <th>Chi1</th>\n",
       "      <th>Chi1n</th>\n",
       "      <th>Chi1v</th>\n",
       "      <th>Chi2n</th>\n",
       "      <th>Chi2v</th>\n",
       "      <th>Chi3v</th>\n",
       "      <th>Chi4n</th>\n",
       "      <th>EState_VSA1</th>\n",
       "      <th>...</th>\n",
       "      <th>PEOE_VSA7</th>\n",
       "      <th>PEOE_VSA8</th>\n",
       "      <th>SMR_VSA10</th>\n",
       "      <th>SMR_VSA5</th>\n",
       "      <th>SlogP_VSA3</th>\n",
       "      <th>VSA_EState9</th>\n",
       "      <th>fr_COO</th>\n",
       "      <th>fr_COO2</th>\n",
       "      <th>EC1</th>\n",
       "      <th>EC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14838</td>\n",
       "      <td>344.632371</td>\n",
       "      <td>7.283603</td>\n",
       "      <td>4.473966</td>\n",
       "      <td>5.834958</td>\n",
       "      <td>3.412257</td>\n",
       "      <td>4.651530</td>\n",
       "      <td>2.096558</td>\n",
       "      <td>1.116433</td>\n",
       "      <td>49.458581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.809272</td>\n",
       "      <td>24.539800</td>\n",
       "      <td>4.794537</td>\n",
       "      <td>47.304082</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.436758</td>\n",
       "      <td>0.835999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14839</td>\n",
       "      <td>1432.410201</td>\n",
       "      <td>10.663869</td>\n",
       "      <td>7.079026</td>\n",
       "      <td>8.065215</td>\n",
       "      <td>5.297097</td>\n",
       "      <td>5.297097</td>\n",
       "      <td>3.924155</td>\n",
       "      <td>2.569694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>98.323987</td>\n",
       "      <td>9.606882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.378235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.811926</td>\n",
       "      <td>0.780156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14840</td>\n",
       "      <td>83.352608</td>\n",
       "      <td>3.931852</td>\n",
       "      <td>1.774215</td>\n",
       "      <td>1.774215</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>0.467830</td>\n",
       "      <td>0.170838</td>\n",
       "      <td>5.969305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.420822</td>\n",
       "      <td>11.752550</td>\n",
       "      <td>13.344559</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>24.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.781455</td>\n",
       "      <td>0.710728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14841</td>\n",
       "      <td>150.255712</td>\n",
       "      <td>5.912790</td>\n",
       "      <td>3.548812</td>\n",
       "      <td>3.548812</td>\n",
       "      <td>2.595128</td>\n",
       "      <td>2.595128</td>\n",
       "      <td>1.642813</td>\n",
       "      <td>0.694113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.744066</td>\n",
       "      <td>32.290168</td>\n",
       "      <td>4.794537</td>\n",
       "      <td>26.778866</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.712642</td>\n",
       "      <td>0.780374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14842</td>\n",
       "      <td>1817.276351</td>\n",
       "      <td>24.910940</td>\n",
       "      <td>15.540529</td>\n",
       "      <td>20.047314</td>\n",
       "      <td>12.535886</td>\n",
       "      <td>17.730988</td>\n",
       "      <td>11.979618</td>\n",
       "      <td>4.431173</td>\n",
       "      <td>84.554972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.099000</td>\n",
       "      <td>69.141353</td>\n",
       "      <td>38.704130</td>\n",
       "      <td>50.697492</td>\n",
       "      <td>102.583333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.771032</td>\n",
       "      <td>0.772533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9888</th>\n",
       "      <td>24726</td>\n",
       "      <td>246.422865</td>\n",
       "      <td>4.036581</td>\n",
       "      <td>2.816709</td>\n",
       "      <td>2.816709</td>\n",
       "      <td>1.875634</td>\n",
       "      <td>1.875634</td>\n",
       "      <td>1.235986</td>\n",
       "      <td>0.362743</td>\n",
       "      <td>24.146543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.938611</td>\n",
       "      <td>12.207933</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.623808</td>\n",
       "      <td>0.732661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9889</th>\n",
       "      <td>24727</td>\n",
       "      <td>591.069706</td>\n",
       "      <td>8.770857</td>\n",
       "      <td>5.682461</td>\n",
       "      <td>5.682461</td>\n",
       "      <td>4.050440</td>\n",
       "      <td>4.050440</td>\n",
       "      <td>2.167855</td>\n",
       "      <td>1.770579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>37.107112</td>\n",
       "      <td>17.696186</td>\n",
       "      <td>10.969244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.747591</td>\n",
       "      <td>0.819741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9890</th>\n",
       "      <td>24728</td>\n",
       "      <td>378.113435</td>\n",
       "      <td>6.310349</td>\n",
       "      <td>3.402334</td>\n",
       "      <td>4.317724</td>\n",
       "      <td>2.817428</td>\n",
       "      <td>4.071978</td>\n",
       "      <td>1.970236</td>\n",
       "      <td>1.165747</td>\n",
       "      <td>36.705949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.822697</td>\n",
       "      <td>24.099010</td>\n",
       "      <td>4.736863</td>\n",
       "      <td>50.652870</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.368690</td>\n",
       "      <td>0.864607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9891</th>\n",
       "      <td>24729</td>\n",
       "      <td>737.653518</td>\n",
       "      <td>9.949161</td>\n",
       "      <td>7.337949</td>\n",
       "      <td>7.337949</td>\n",
       "      <td>4.428511</td>\n",
       "      <td>5.948361</td>\n",
       "      <td>3.972459</td>\n",
       "      <td>2.160881</td>\n",
       "      <td>36.992053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.196844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.462662</td>\n",
       "      <td>9.589074</td>\n",
       "      <td>50.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.430987</td>\n",
       "      <td>0.879144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9892</th>\n",
       "      <td>24730</td>\n",
       "      <td>785.394062</td>\n",
       "      <td>12.170505</td>\n",
       "      <td>7.565385</td>\n",
       "      <td>9.651755</td>\n",
       "      <td>5.842572</td>\n",
       "      <td>8.229500</td>\n",
       "      <td>5.664696</td>\n",
       "      <td>2.587586</td>\n",
       "      <td>49.458581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.872230</td>\n",
       "      <td>24.539800</td>\n",
       "      <td>13.825658</td>\n",
       "      <td>69.130957</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399012</td>\n",
       "      <td>0.879144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9893 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id      BertzCT       Chi1      Chi1n      Chi1v      Chi2n  \\\n",
       "0     14838   344.632371   7.283603   4.473966   5.834958   3.412257   \n",
       "1     14839  1432.410201  10.663869   7.079026   8.065215   5.297097   \n",
       "2     14840    83.352608   3.931852   1.774215   1.774215   1.073446   \n",
       "3     14841   150.255712   5.912790   3.548812   3.548812   2.595128   \n",
       "4     14842  1817.276351  24.910940  15.540529  20.047314  12.535886   \n",
       "...     ...          ...        ...        ...        ...        ...   \n",
       "9888  24726   246.422865   4.036581   2.816709   2.816709   1.875634   \n",
       "9889  24727   591.069706   8.770857   5.682461   5.682461   4.050440   \n",
       "9890  24728   378.113435   6.310349   3.402334   4.317724   2.817428   \n",
       "9891  24729   737.653518   9.949161   7.337949   7.337949   4.428511   \n",
       "9892  24730   785.394062  12.170505   7.565385   9.651755   5.842572   \n",
       "\n",
       "          Chi2v      Chi3v     Chi4n  EState_VSA1  ...  PEOE_VSA7  PEOE_VSA8  \\\n",
       "0      4.651530   2.096558  1.116433    49.458581  ...   0.000000   0.000000   \n",
       "1      5.297097   3.924155  2.569694     0.000000  ...  98.323987   9.606882   \n",
       "2      1.073446   0.467830  0.170838     5.969305  ...   0.000000   6.420822   \n",
       "3      2.595128   1.642813  0.694113     0.000000  ...   0.000000   0.000000   \n",
       "4     17.730988  11.979618  4.431173    84.554972  ...   0.000000  37.099000   \n",
       "...         ...        ...       ...          ...  ...        ...        ...   \n",
       "9888   1.875634   1.235986  0.362743    24.146543  ...   0.000000   0.000000   \n",
       "9889   4.050440   2.167855  1.770579     0.000000  ...  37.107112  17.696186   \n",
       "9890   4.071978   1.970236  1.165747    36.705949  ...   0.000000   0.000000   \n",
       "9891   5.948361   3.972459  2.160881    36.992053  ...   0.000000   6.196844   \n",
       "9892   8.229500   5.664696  2.587586    49.458581  ...   0.000000   0.000000   \n",
       "\n",
       "      SMR_VSA10   SMR_VSA5  SlogP_VSA3  VSA_EState9  fr_COO  fr_COO2  \\\n",
       "0     26.809272  24.539800    4.794537    47.304082       1        1   \n",
       "1      0.000000  53.378235    0.000000    43.166667       0        0   \n",
       "2     11.752550  13.344559    9.589074    24.666667       1        1   \n",
       "3     17.744066  32.290168    4.794537    26.778866       0        0   \n",
       "4     69.141353  38.704130   50.697492   102.583333       0        0   \n",
       "...         ...        ...         ...          ...     ...      ...   \n",
       "9888  11.938611  12.207933    9.589074    30.000000       2        2   \n",
       "9889  10.969244   0.000000    0.000000    53.166667       0        0   \n",
       "9890   7.822697  24.099010    4.736863    50.652870       0        0   \n",
       "9891   0.000000  12.462662    9.589074    50.250000       0        0   \n",
       "9892  18.872230  24.539800   13.825658    69.130957       0        0   \n",
       "\n",
       "           EC1       EC2  \n",
       "0     0.436758  0.835999  \n",
       "1     0.811926  0.780156  \n",
       "2     0.781455  0.710728  \n",
       "3     0.712642  0.780374  \n",
       "4     0.771032  0.772533  \n",
       "...        ...       ...  \n",
       "9888  0.623808  0.732661  \n",
       "9889  0.747591  0.819741  \n",
       "9890  0.368690  0.864607  \n",
       "9891  0.430987  0.879144  \n",
       "9892  0.399012  0.879144  \n",
       "\n",
       "[9893 rows x 34 columns]"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['EC2'] = y_hatEC2\n",
    "test['EC1'] = model1.predict(X_test.drop('EC1',axis=1))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "26551aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>EC1</th>\n",
       "      <th>EC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14838</td>\n",
       "      <td>0.436758</td>\n",
       "      <td>0.835999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14839</td>\n",
       "      <td>0.811926</td>\n",
       "      <td>0.780156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14840</td>\n",
       "      <td>0.781455</td>\n",
       "      <td>0.710728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14841</td>\n",
       "      <td>0.712642</td>\n",
       "      <td>0.780374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14842</td>\n",
       "      <td>0.771032</td>\n",
       "      <td>0.772533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9888</th>\n",
       "      <td>24726</td>\n",
       "      <td>0.623808</td>\n",
       "      <td>0.732661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9889</th>\n",
       "      <td>24727</td>\n",
       "      <td>0.747591</td>\n",
       "      <td>0.819741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9890</th>\n",
       "      <td>24728</td>\n",
       "      <td>0.368690</td>\n",
       "      <td>0.864607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9891</th>\n",
       "      <td>24729</td>\n",
       "      <td>0.430987</td>\n",
       "      <td>0.879144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9892</th>\n",
       "      <td>24730</td>\n",
       "      <td>0.399012</td>\n",
       "      <td>0.879144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9893 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id       EC1       EC2\n",
       "0     14838  0.436758  0.835999\n",
       "1     14839  0.811926  0.780156\n",
       "2     14840  0.781455  0.710728\n",
       "3     14841  0.712642  0.780374\n",
       "4     14842  0.771032  0.772533\n",
       "...     ...       ...       ...\n",
       "9888  24726  0.623808  0.732661\n",
       "9889  24727  0.747591  0.819741\n",
       "9890  24728  0.368690  0.864607\n",
       "9891  24729  0.430987  0.879144\n",
       "9892  24730  0.399012  0.879144\n",
       "\n",
       "[9893 rows x 3 columns]"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_ec1 = test[test.columns[:1].to_list()+test.columns[-2:].to_list()]\n",
    "use_ec1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "9e109cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_ec1.to_csv('use_ec1(2).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ca8152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
